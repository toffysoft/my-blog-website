<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>ลองเล่น Local LLM ด้วย Ollama &#43; Python | Toffysoft&#39;s Blog</title>
<meta name="keywords" content="AI, LLM, Python, Ollama, Local Development">
<meta name="description" content="มาเรียนรู้การใช้งาน Local LLM ผ่าน Ollama ร่วมกับ Python เพื่อสร้าง AI Application แบบ Privacy-First">
<meta name="author" content="Apiwat Ruangkanjanapaisarn">
<link rel="canonical" href="http://localhost:1313/posts/ollama-python/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.2d6240e602c0dc461084f6be8e56c708e5e1efe1df0e71e2e8d12c0b5b8047a9.css" integrity="sha256-LWJA5gLA3EYQhPa&#43;jlbHCOXh7&#43;HfDnHi6NEsC1uAR6k=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/ollama-python/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:url" content="http://localhost:1313/posts/ollama-python/">
  <meta property="og:site_name" content="Toffysoft&#39;s Blog">
  <meta property="og:title" content="ลองเล่น Local LLM ด้วย Ollama &#43; Python">
  <meta property="og:description" content="มาเรียนรู้การใช้งาน Local LLM ผ่าน Ollama ร่วมกับ Python เพื่อสร้าง AI Application แบบ Privacy-First">
  <meta property="og:locale" content="th-th">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-02-02T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-02-02T00:00:00+00:00">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="Python">
    <meta property="article:tag" content="Ollama">
    <meta property="article:tag" content="Local Development">
    <meta property="og:image" content="https://ollama.com/public/blog/embedding-models.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://ollama.com/public/blog/embedding-models.png">
<meta name="twitter:title" content="ลองเล่น Local LLM ด้วย Ollama &#43; Python">
<meta name="twitter:description" content="มาเรียนรู้การใช้งาน Local LLM ผ่าน Ollama ร่วมกับ Python เพื่อสร้าง AI Application แบบ Privacy-First">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "ลองเล่น Local LLM ด้วย Ollama + Python",
      "item": "http://localhost:1313/posts/ollama-python/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "ลองเล่น Local LLM ด้วย Ollama + Python",
  "name": "ลองเล่น Local LLM ด้วย Ollama \u002b Python",
  "description": "มาเรียนรู้การใช้งาน Local LLM ผ่าน Ollama ร่วมกับ Python เพื่อสร้าง AI Application แบบ Privacy-First",
  "keywords": [
    "AI", "LLM", "Python", "Ollama", "Local Development"
  ],
  "articleBody": "ลองเล่น Local LLM ด้วย Ollama + Python บทความนี้จะพาทุกคนมาลองใช้งาน LLM บนเครื่องคอมพิวเตอร์ส่วนตัวผ่าน Ollama และ Python เหมาะสำหรับผู้ที่อยากทดลองเล่น AI แต่กังวลเรื่องความเป็นส่วนตัวของข้อมูล หรือต้องการระบบที่ทำงานได้แม้ไม่มีอินเทอร์เน็ต\nที่มาของ Large Language Model (LLM) ในช่วงไม่กี่ปีที่ผ่านมา เราได้เห็นการเติบโตอย่างก้าวกระโดดของ AI โดยเฉพาะในด้านการประมวลผลภาษาธรรมชาติ จุดเปลี่ยนสำคัญเกิดขึ้นเมื่อนักวิจัยพบว่า การสร้างโมเดลขนาดใหญ่และฝึกฝนด้วยข้อมูลมหาศาล ทำให้ AI สามารถเข้าใจและตอบโต้กับมนุษย์ได้อย่างน่าทึ่ง\nปัจจุบันมีบริการ LLM มากมายให้เลือกใช้ เช่น ChatGPT, Claude, Gemini แต่หลายคนอาจกังวลเรื่องความเป็นส่วนตัวของข้อมูล หรือต้องการระบบที่ทำงานได้แม้ไม่มีอินเทอร์เน็ต นั่นคือที่มาของ Local LLM\nรู้จักกับ Ollama Ollama เป็นเครื่องมือที่ช่วยให้เราสามารถรัน LLM บนเครื่องคอมพิวเตอร์ส่วนตัวได้อย่างง่ายดาย รองรับโมเดลหลากหลาย เช่น Llama 3, Mistral, CodeLlama โดยมีจุดเด่นคือ:\nติดตั้งง่าย รองรับทั้ง Windows, macOS และ Linux มี API ที่ใช้งานสะดวก ประสิทธิภาพดี ใช้ทรัพยากรเครื่องน้อย รองรับการปรับแต่งโมเดลได้ตามต้องการ การติดตั้ง 1. ติดตั้ง Ollama สำหรับ macOS:\nbrew install ollama สำหรับ Linux:\ncurl -fsSL https://ollama.com/install.sh | sh สำหรับ Windows สามารถดาวน์โหลดได้จาก เว็บไซต์ Ollama\n2. ติดตั้ง Python Package pip install ollama เริ่มต้นใช้งาน 1. ดาวน์โหลดโมเดล เริ่มจากเปิด Terminal แล้วรันคำสั่ง:\nollama pull llama3.1 2. ทดสอบด้วย Python สร้างไฟล์ test_ollama.py:\nimport ollama def simple_chat(): response = ollama.chat(model='llama3.1', messages=[ {'role': 'user', 'content': 'สวัสดี คุณทำอะไรได้บ้าง?'} ]) print(response['message']['content']) # ทดสอบเรียกใช้งาน if __name__ == '__main__': simple_chat() ลองรันทดสอบ:\npython test_ollama.py Output:\nสวัสดีค่ะ ฉันสามารถตอบคำถามของคุณได้ เช่น การเรียนรู้ภาษา คำนวณเลขคณิต ช่วยหาข้อมูลเกี่ยวกับประเทศหรือเมือง ขอข้อมูลเกี่ยวกับต่างๆ อีกมากมายค่ะ การใช้งานขั้นสูงขึ้น การสร้าง Chat Assistant สร้างไฟล์ assistant.py:\nimport ollama from typing import List, Dict class ChatAssistant: def __init__(self, model_name: str = 'llama3.1'): self.model = model_name self.conversation_history: List[Dict[str, str]] = [] def chat(self, message: str) -\u003e str: self.conversation_history.append({ 'role': 'user', 'content': message }) response = ollama.chat( model=self.model, messages=self.conversation_history ) self.conversation_history.append({ 'role': 'assistant', 'content': response['message']['content'] }) return response['message']['content'] def clear_history(self): self.conversation_history = [] ตัวอย่างการใช้งาน Chat Assistant สร้างไฟล์ chat.py:\nfrom assistant import ChatAssistant assistant = ChatAssistant() questions = [ \"Python คืออะไร?\", \"ยกตัวอย่างการใช้งาน list comprehension\", \"แล้ว dictionary comprehension ล่ะ?\" ] for question in questions: print(f\"\\nคำถาม: {question}\") print(f\"คำตอบ: {assistant.chat(question)}\") ลองรันทดสอบ:\npython chat.py Output:\nคำถาม: Python คืออะไร? คำตอบ: ภาษาเชิงสคริปต์ (Scripting language) ที่ใช้ในการเขียนโปรแกรมคอมพิวเตอร์ โดยมีลักษณะเฉพาะคือความสามารถในการนำโค้ดไปใช้งานได้ทันทีโดยไม่ต้องบันทึกลงไปในไฟล์ใดๆ คำถาม: ยกตัวอย่างการใช้งาน list comprehension คำตอบ: **List Comprehension ในภาษา Python** List comprehension เป็นฟังก์ชันพิเศษในภาษา Python ที่สามารถสร้างรายการ (list) ได้อย่างรวดเร็วและง่ายดาย โดยไม่ต้องใช้ loop หรือการเขียนโค้ดซ้ำๆ ตัวอย่างการใช้งาน list comprehension: **1. สร้างรายการที่มีขนาดเฉพาะ** `python numbers = [i for i in range(10)] print(numbers) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] ` **2. ฟิลเตอร์รายการ** `python numbers = [i for i in range(10) if i % 2 == 0] print(numbers) # [0, 2, 4, 6, 8] ` **3. ทำการปฏิบัติการบนรายการ** `python numbers = [i ** 2 for i in range(5)] print(numbers) # [0, 1, 4, 9, 16] ` **4. รวมสองรายการเข้าด้วยกัน** `python names = ['John', 'Alice', 'Bob'] ages = [25, 30, 35] people = [{name: age} for name, age in zip(names, ages)] print(people) # [{'John': 25}, {'Alice': 30}, {'Bob': 35}] ` นี่คือตัวอย่างการใช้งาน list comprehension ในภาษา Python มีหลายกรณีที่สามารถใช้ได้ และมันช่วยให้คุณเขียนโค้ดที่กระชับและง่ายดายมากขึ้น! คำถาม: แล้ว dictionary comprehension ล่ะ? คำตอบ: **Dictionary Comprehension ในภาษา Python** Dictionary comprehension เป็นฟังก์ชันพิเศษในภาษา Python ที่สามารถสร้าง辞านวารี (dictionary) ได้อย่างรวดเร็วและง่ายดาย โดยไม่ต้องใช้ loop หรือการเขียนโค้ดซ้ำๆ ตัวอย่างการใช้งาน dictionary comprehension: **1. สร้าง辞านวารีที่มีขนาดเฉพาะ** `python numbers = {i: i * 2 for i in range(5)} print(numbers) # {0: 0, 1: 2, 2: 4, 3: 6, 4: 8} ` **2. ฟิลเตอร์รายการ** `python numbers = {i: i * 2 for i in range(10) if i % 2 == 0} print(numbers) # {0: 0, 2: 4, 4: 8, 6: 12, 8: 16} ` **3. ทำการปฏิบัติการบนรายการ** `python numbers = {i: i ** 2 for i in range(5)} print(numbers) # {0: 0, 1: 1, 2: 4, 3: 9, 4: 16} ` **4. รวมสองรายการเข้าด้วยกัน** `python names = ['John', 'Alice', 'Bob'] ages = [25, 30, 35] people = {name: age for name, age in zip(names, ages)} print(people) # {'John': 25, 'Alice': 30, 'Bob': 35} ` นี่คือตัวอย่างการใช้งาน dictionary comprehension ในภาษา Python มีหลายกรณีที่สามารถใช้ได้ และมันช่วยให้คุณเขียนโค้ดที่กระชับและง่ายดายมากขึ้น! ความแตกต่างระหว่าง list comprehension และ dictionary comprehension คือ: * List comprehension สร้างรายการ (list) ขณะที่ dictionary comprehension สร้าง辞านวารี (dictionary) * ใน list comprehension เราสามารถใช้คำสั่ง `for` ได้ทั้งสองฝ่าย (left-hand side และ right-hand side) ในขณะที่ใน dictionary comprehension เราสามารถใช้คำสั่ง `for` ได้เพียงฝ่ายหนึ่งเท่านั้น การปรับแต่งพารามิเตอร์ เราสามารถปรับแต่งการทำงานของ LLM ได้ผ่านพารามิเตอร์ต่างๆ:\nสร้างไฟล์ advanced_chat.py:\nimport ollama def advanced_chat(prompt: str): response = ollama.chat( model='llama3.1', messages=[{'role': 'user', 'content': prompt}], options={ 'temperature': 0.7, # ควบคุมความสร้างสรรค์ (0.0 - 1.0) 'top_p': 0.9, # ควบคุมความหลากหลายของคำตอบ 'top_k': 40, # จำนวนโทเค็นที่พิจารณา 'num_predict': 4069 # ความยาวสูงสุดของคำตอบ } ) return response['message']['content'] # ทดสอบเรียกใช้งาน if __name__ == '__main__': prompt = \"เล่าเรื่องตลกให้ฟังหน่อยสิ\" print(advanced_chat(prompt)) ลองรันทดสอบ:\npython advanced_chat.py Output:\nมีชายคนหนึ่งซื้อหมูจากตลาดกลับบ้านเพื่อให้ทานเย็น แต่เมื่อลูกสาวของเขาเห็นหมู เธอก็บอกพ่อว่า \"พ่อ ฉันอยากจะเลี้ยงหมูตัวนั้นก่อน\" ชายคนนั้นพยายามที่จะทำให้ลูกสาวตกใจและบอกเธอว่า \"หมูนี้เป็นหมูที่มีชื่อเสียงมาก มันสามารถปรุงแต่งอาหารได้ทุกชนิด แต่สิ่งที่สำคัญที่สุดคือมันไม่ต้องการเงิน\" หญิงสาวตอบว่า \"นั่นก็ทำให้ฉันประหลาดใจจริงๆ ที่เราสามารถจ่ายค่าตอบแทนทางเงินให้มันได้!\" การใช้งานกับ Stream Ollama รองรับการ stream ข้อความตอบกลับแบบ real-time:\nimport ollama def stream_chat(prompt: str): stream = ollama.chat( model='llama3.1', messages=[{'role': 'user', 'content': prompt}], stream=True ) # พิมพ์ข้อความทีละส่วนตามที่ได้รับ for chunk in stream: if chunk['message']['content']: print(chunk['message']['content'], end='', flush=True) การจัดการกับข้อผิดพลาด import ollama def safe_chat(prompt: str) -\u003e str: try: response = ollama.chat( model='llama3.1', messages=[{'role': 'user', 'content': prompt}] ) return response['message']['content'] except Exception as e: return f\"เกิดข้อผิดพลาด: {str(e)}\" ข้อควรระวังและข้อจำกัด ทรัพยากรเครื่อง\nต้องการ RAM อย่างน้อย 8GB ควรมี GPU สำหรับประสิทธิภาพที่ดี พื้นที่ดิสก์สำหรับเก็บโมเดล (ประมาณ 4-8GB ต่อโมเดล) ความแม่นยำ\nLocal LLM อาจมีความแม่นยำน้อยกว่าโมเดลออนไลน์ ควรตรวจสอบผลลัพธ์เสมอ โดยเฉพาะในงานสำคัญ การอัพเดท\nติดตามการอัพเดทของ Ollama และโมเดลอยู่เสมอ อาจต้อง pull โมเดลใหม่เมื่อมีเวอร์ชันอัพเดท สรุป การใช้ Local LLM ผ่าน Ollama เป็นทางเลือกที่น่าสนใจสำหรับผู้ที่ต้องการความเป็นส่วนตัวหรือต้องการระบบที่ทำงานได้แบบ offline ถึงแม้จะมีข้อจำกัดบางประการ แต่ก็สามารถนำไปประยุกต์ใช้ได้หลากหลาย ตั้งแต่การสร้าง chatbot ไปจนถึงการประมวลผลเอกสาร\nแหล่งข้อมูลเพิ่มเติม GitHub Repo Ollama Official Documentation Ollama GitHub Repository Python Package Documentation บทความนี้อัพเดทล่าสุด: กุมภาพันธ์ 2025\nNote: ตัวอย่างโค้ดทั้งหมดทดสอบบน Python 3.10+\nCover image by Ollama\nปล. บทความนี้เขียนด้วย AI (^ . ^)\n",
  "wordCount" : "756",
  "inLanguage": "en",
  "image":"https://ollama.com/public/blog/embedding-models.png","datePublished": "2025-02-02T00:00:00Z",
  "dateModified": "2025-02-02T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Apiwat Ruangkanjanapaisarn"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/ollama-python/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Toffysoft's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Toffysoft (Alt + H)">
                        
                    <img src="http://localhost:1313/images/toffysoft_hu_7003f3165263a7ac.jpeg" alt="" aria-label="logo"
                        height="35">Toffysoft</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      ลองเล่น Local LLM ด้วย Ollama &#43; Python
    </h1>
    <div class="post-description">
      มาเรียนรู้การใช้งาน Local LLM ผ่าน Ollama ร่วมกับ Python เพื่อสร้าง AI Application แบบ Privacy-First
    </div>
    <div class="post-meta"><span title='2025-02-02 00:00:00 +0000 UTC'>February 2, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Apiwat Ruangkanjanapaisarn

</div>
  </header> 
<figure class="entry-cover"><img loading="eager" src="https://ollama.com/public/blog/embedding-models.png" alt="Image from (https://ollama.com/blog/embedding-models)">
        <p>Image from (<a href="https://ollama.com/blog/embedding-models">https://ollama.com/blog/embedding-models</a>)</p>
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e0%b8%a5%e0%b8%ad%e0%b8%87%e0%b9%80%e0%b8%a5%e0%b8%99-local-llm-%e0%b8%94%e0%b8%a7%e0%b8%a2-ollama--python" aria-label="ลองเล่น Local LLM ด้วย Ollama &#43; Python">ลองเล่น Local LLM ด้วย Ollama + Python</a><ul>
                        
                <li>
                    <a href="#%e0%b8%97%e0%b8%a1%e0%b8%b2%e0%b8%82%e0%b8%ad%e0%b8%87-large-language-model-llm" aria-label="ที่มาของ Large Language Model (LLM)">ที่มาของ Large Language Model (LLM)</a></li>
                <li>
                    <a href="#%e0%b8%a3%e0%b8%88%e0%b8%81%e0%b8%81%e0%b8%9a-ollama" aria-label="รู้จักกับ Ollama">รู้จักกับ Ollama</a></li>
                <li>
                    <a href="#%e0%b8%81%e0%b8%b2%e0%b8%a3%e0%b8%95%e0%b8%94%e0%b8%95%e0%b8%87" aria-label="การติดตั้ง">การติดตั้ง</a><ul>
                        
                <li>
                    <a href="#1-%e0%b8%95%e0%b8%94%e0%b8%95%e0%b8%87-ollama" aria-label="1. ติดตั้ง Ollama">1. ติดตั้ง Ollama</a></li>
                <li>
                    <a href="#2-%e0%b8%95%e0%b8%94%e0%b8%95%e0%b8%87-python-package" aria-label="2. ติดตั้ง Python Package">2. ติดตั้ง Python Package</a></li></ul>
                </li>
                <li>
                    <a href="#%e0%b9%80%e0%b8%a3%e0%b8%a1%e0%b8%95%e0%b8%99%e0%b9%83%e0%b8%8a%e0%b8%87%e0%b8%b2%e0%b8%99" aria-label="เริ่มต้นใช้งาน">เริ่มต้นใช้งาน</a><ul>
                        
                <li>
                    <a href="#1-%e0%b8%94%e0%b8%b2%e0%b8%a7%e0%b8%99%e0%b9%82%e0%b8%ab%e0%b8%a5%e0%b8%94%e0%b9%82%e0%b8%a1%e0%b9%80%e0%b8%94%e0%b8%a5" aria-label="1. ดาวน์โหลดโมเดล">1. ดาวน์โหลดโมเดล</a></li>
                <li>
                    <a href="#2-%e0%b8%97%e0%b8%94%e0%b8%aa%e0%b8%ad%e0%b8%9a%e0%b8%94%e0%b8%a7%e0%b8%a2-python" aria-label="2. ทดสอบด้วย Python">2. ทดสอบด้วย Python</a></li></ul>
                </li>
                <li>
                    <a href="#%e0%b8%81%e0%b8%b2%e0%b8%a3%e0%b9%83%e0%b8%8a%e0%b8%87%e0%b8%b2%e0%b8%99%e0%b8%82%e0%b8%99%e0%b8%aa%e0%b8%87%e0%b8%82%e0%b8%99" aria-label="การใช้งานขั้นสูงขึ้น">การใช้งานขั้นสูงขึ้น</a><ul>
                        
                <li>
                    <a href="#%e0%b8%81%e0%b8%b2%e0%b8%a3%e0%b8%aa%e0%b8%a3%e0%b8%b2%e0%b8%87-chat-assistant" aria-label="การสร้าง Chat Assistant">การสร้าง Chat Assistant</a></li>
                <li>
                    <a href="#%e0%b8%95%e0%b8%a7%e0%b8%ad%e0%b8%a2%e0%b8%b2%e0%b8%87%e0%b8%81%e0%b8%b2%e0%b8%a3%e0%b9%83%e0%b8%8a%e0%b8%87%e0%b8%b2%e0%b8%99-chat-assistant" aria-label="ตัวอย่างการใช้งาน Chat Assistant">ตัวอย่างการใช้งาน Chat Assistant</a></li></ul>
                </li>
                <li>
                    <a href="#%e0%b8%81%e0%b8%b2%e0%b8%a3%e0%b8%9b%e0%b8%a3%e0%b8%9a%e0%b9%81%e0%b8%95%e0%b8%87%e0%b8%9e%e0%b8%b2%e0%b8%a3%e0%b8%b2%e0%b8%a1%e0%b9%80%e0%b8%95%e0%b8%ad%e0%b8%a3" aria-label="การปรับแต่งพารามิเตอร์">การปรับแต่งพารามิเตอร์</a></li>
                <li>
                    <a href="#%e0%b8%81%e0%b8%b2%e0%b8%a3%e0%b9%83%e0%b8%8a%e0%b8%87%e0%b8%b2%e0%b8%99%e0%b8%81%e0%b8%9a-stream" aria-label="การใช้งานกับ Stream">การใช้งานกับ Stream</a></li>
                <li>
                    <a href="#%e0%b8%81%e0%b8%b2%e0%b8%a3%e0%b8%88%e0%b8%94%e0%b8%81%e0%b8%b2%e0%b8%a3%e0%b8%81%e0%b8%9a%e0%b8%82%e0%b8%ad%e0%b8%9c%e0%b8%94%e0%b8%9e%e0%b8%a5%e0%b8%b2%e0%b8%94" aria-label="การจัดการกับข้อผิดพลาด">การจัดการกับข้อผิดพลาด</a></li>
                <li>
                    <a href="#%e0%b8%82%e0%b8%ad%e0%b8%84%e0%b8%a7%e0%b8%a3%e0%b8%a3%e0%b8%b0%e0%b8%a7%e0%b8%87%e0%b9%81%e0%b8%a5%e0%b8%b0%e0%b8%82%e0%b8%ad%e0%b8%88%e0%b8%b3%e0%b8%81%e0%b8%94" aria-label="ข้อควรระวังและข้อจำกัด">ข้อควรระวังและข้อจำกัด</a></li>
                <li>
                    <a href="#%e0%b8%aa%e0%b8%a3%e0%b8%9b" aria-label="สรุป">สรุป</a></li>
                <li>
                    <a href="#%e0%b9%81%e0%b8%ab%e0%b8%a5%e0%b8%87%e0%b8%82%e0%b8%ad%e0%b8%a1%e0%b8%a5%e0%b9%80%e0%b8%9e%e0%b8%a1%e0%b9%80%e0%b8%95%e0%b8%a1" aria-label="แหล่งข้อมูลเพิ่มเติม">แหล่งข้อมูลเพิ่มเติม</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="ลองเลน-local-llm-ดวย-ollama--python">ลองเล่น Local LLM ด้วย Ollama + Python<a hidden class="anchor" aria-hidden="true" href="#ลองเลน-local-llm-ดวย-ollama--python">#</a></h1>
<p><em>บทความนี้จะพาทุกคนมาลองใช้งาน LLM บนเครื่องคอมพิวเตอร์ส่วนตัวผ่าน Ollama และ Python เหมาะสำหรับผู้ที่อยากทดลองเล่น AI แต่กังวลเรื่องความเป็นส่วนตัวของข้อมูล หรือต้องการระบบที่ทำงานได้แม้ไม่มีอินเทอร์เน็ต</em></p>
<h2 id="ทมาของ-large-language-model-llm">ที่มาของ Large Language Model (LLM)<a hidden class="anchor" aria-hidden="true" href="#ทมาของ-large-language-model-llm">#</a></h2>
<p>ในช่วงไม่กี่ปีที่ผ่านมา เราได้เห็นการเติบโตอย่างก้าวกระโดดของ AI โดยเฉพาะในด้านการประมวลผลภาษาธรรมชาติ จุดเปลี่ยนสำคัญเกิดขึ้นเมื่อนักวิจัยพบว่า การสร้างโมเดลขนาดใหญ่และฝึกฝนด้วยข้อมูลมหาศาล ทำให้ AI สามารถเข้าใจและตอบโต้กับมนุษย์ได้อย่างน่าทึ่ง</p>
<p>ปัจจุบันมีบริการ LLM มากมายให้เลือกใช้ เช่น ChatGPT, Claude, Gemini แต่หลายคนอาจกังวลเรื่องความเป็นส่วนตัวของข้อมูล หรือต้องการระบบที่ทำงานได้แม้ไม่มีอินเทอร์เน็ต นั่นคือที่มาของ Local LLM</p>
<h2 id="รจกกบ-ollama">รู้จักกับ Ollama<a hidden class="anchor" aria-hidden="true" href="#รจกกบ-ollama">#</a></h2>
<p>Ollama เป็นเครื่องมือที่ช่วยให้เราสามารถรัน LLM บนเครื่องคอมพิวเตอร์ส่วนตัวได้อย่างง่ายดาย รองรับโมเดลหลากหลาย เช่น Llama 3, Mistral, CodeLlama โดยมีจุดเด่นคือ:</p>
<ul>
<li>ติดตั้งง่าย รองรับทั้ง Windows, macOS และ Linux</li>
<li>มี API ที่ใช้งานสะดวก</li>
<li>ประสิทธิภาพดี ใช้ทรัพยากรเครื่องน้อย</li>
<li>รองรับการปรับแต่งโมเดลได้ตามต้องการ</li>
</ul>
<h2 id="การตดตง">การติดตั้ง<a hidden class="anchor" aria-hidden="true" href="#การตดตง">#</a></h2>
<h3 id="1-ตดตง-ollama">1. ติดตั้ง Ollama<a hidden class="anchor" aria-hidden="true" href="#1-ตดตง-ollama">#</a></h3>
<p>สำหรับ macOS:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">brew install ollama
</span></span></code></pre></div><p>สำหรับ Linux:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">curl -fsSL https://ollama.com/install.sh <span class="p">|</span> sh
</span></span></code></pre></div><p>สำหรับ Windows สามารถดาวน์โหลดได้จาก <a href="https://ollama.com">เว็บไซต์ Ollama</a></p>
<h3 id="2-ตดตง-python-package">2. ติดตั้ง Python Package<a hidden class="anchor" aria-hidden="true" href="#2-ตดตง-python-package">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">pip install ollama
</span></span></code></pre></div><h2 id="เรมตนใชงาน">เริ่มต้นใช้งาน<a hidden class="anchor" aria-hidden="true" href="#เรมตนใชงาน">#</a></h2>
<h3 id="1-ดาวนโหลดโมเดล">1. ดาวน์โหลดโมเดล<a hidden class="anchor" aria-hidden="true" href="#1-ดาวนโหลดโมเดล">#</a></h3>
<p>เริ่มจากเปิด Terminal แล้วรันคำสั่ง:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ollama pull llama3.1
</span></span></code></pre></div><h3 id="2-ทดสอบดวย-python">2. ทดสอบด้วย Python<a hidden class="anchor" aria-hidden="true" href="#2-ทดสอบดวย-python">#</a></h3>
<p>สร้างไฟล์ <code>test_ollama.py</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">ollama</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">simple_chat</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3.1&#39;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                          <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">                              <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                               <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;สวัสดี คุณทำอะไรได้บ้าง?&#39;</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">                          <span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ทดสอบเรียกใช้งาน</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">simple_chat</span><span class="p">()</span>
</span></span></code></pre></div><p>ลองรันทดสอบ:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">python test_ollama.py
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>สวัสดีค่ะ ฉันสามารถตอบคำถามของคุณได้ เช่น การเรียนรู้ภาษา คำนวณเลขคณิต ช่วยหาข้อมูลเกี่ยวกับประเทศหรือเมือง ขอข้อมูลเกี่ยวกับต่างๆ อีกมากมายค่ะ
</code></pre><h2 id="การใชงานขนสงขน">การใช้งานขั้นสูงขึ้น<a hidden class="anchor" aria-hidden="true" href="#การใชงานขนสงขน">#</a></h2>
<h3 id="การสราง-chat-assistant">การสร้าง Chat Assistant<a hidden class="anchor" aria-hidden="true" href="#การสราง-chat-assistant">#</a></h3>
<p>สร้างไฟล์ <code>assistant.py</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">ollama</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">ChatAssistant</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;llama3.1&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_name</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">conversation_history</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">chat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">message</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">conversation_history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">message</span>
</span></span><span class="line"><span class="cl">        <span class="p">})</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">messages</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conversation_history</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">conversation_history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;assistant&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="p">})</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">clear_history</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">conversation_history</span> <span class="o">=</span> <span class="p">[]</span>
</span></span></code></pre></div><h3 id="ตวอยางการใชงาน-chat-assistant">ตัวอย่างการใช้งาน Chat Assistant<a hidden class="anchor" aria-hidden="true" href="#ตวอยางการใชงาน-chat-assistant">#</a></h3>
<p>สร้างไฟล์ <code>chat.py</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">assistant</span> <span class="kn">import</span> <span class="n">ChatAssistant</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">assistant</span> <span class="o">=</span> <span class="n">ChatAssistant</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">questions</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;Python คืออะไร?&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;ยกตัวอย่างการใช้งาน list comprehension&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;แล้ว dictionary comprehension ล่ะ?&#34;</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">questions</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">คำถาม: </span><span class="si">{</span><span class="n">question</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;คำตอบ: </span><span class="si">{</span><span class="n">assistant</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">question</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>ลองรันทดสอบ:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">python chat.py
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>คำถาม: Python คืออะไร?
คำตอบ: ภาษาเชิงสคริปต์ (Scripting language) ที่ใช้ในการเขียนโปรแกรมคอมพิวเตอร์ โดยมีลักษณะเฉพาะคือความสามารถในการนำโค้ดไปใช้งานได้ทันทีโดยไม่ต้องบันทึกลงไปในไฟล์ใดๆ

คำถาม: ยกตัวอย่างการใช้งาน list comprehension
คำตอบ: **List Comprehension ในภาษา Python**

List comprehension เป็นฟังก์ชันพิเศษในภาษา Python ที่สามารถสร้างรายการ (list) ได้อย่างรวดเร็วและง่ายดาย โดยไม่ต้องใช้ loop หรือการเขียนโค้ดซ้ำๆ

ตัวอย่างการใช้งาน list comprehension:

**1. สร้างรายการที่มีขนาดเฉพาะ**

`python
numbers = [i for i in range(10)]
print(numbers)  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
`

**2. ฟิลเตอร์รายการ**

`python
numbers = [i for i in range(10) if i % 2 == 0]
print(numbers)  # [0, 2, 4, 6, 8]
`

**3. ทำการปฏิบัติการบนรายการ**

`python
numbers = [i ** 2 for i in range(5)]
print(numbers)  # [0, 1, 4, 9, 16]
`

**4. รวมสองรายการเข้าด้วยกัน**

`python
names = [&#39;John&#39;, &#39;Alice&#39;, &#39;Bob&#39;]
ages = [25, 30, 35]

people = [{name: age} for name, age in zip(names, ages)]
print(people)  
# [{&#39;John&#39;: 25}, {&#39;Alice&#39;: 30}, {&#39;Bob&#39;: 35}]
`

นี่คือตัวอย่างการใช้งาน list comprehension ในภาษา Python มีหลายกรณีที่สามารถใช้ได้ และมันช่วยให้คุณเขียนโค้ดที่กระชับและง่ายดายมากขึ้น!

คำถาม: แล้ว dictionary comprehension ล่ะ?
คำตอบ: **Dictionary Comprehension ในภาษา Python**

 Dictionary comprehension เป็นฟังก์ชันพิเศษในภาษา Python ที่สามารถสร้าง辞านวารี (dictionary) ได้อย่างรวดเร็วและง่ายดาย โดยไม่ต้องใช้ loop หรือการเขียนโค้ดซ้ำๆ

ตัวอย่างการใช้งาน dictionary comprehension:

**1. สร้าง辞านวารีที่มีขนาดเฉพาะ**

`python
numbers = {i: i * 2 for i in range(5)}
print(numbers)  
# {0: 0, 1: 2, 2: 4, 3: 6, 4: 8}
`

**2. ฟิลเตอร์รายการ**

`python
numbers = {i: i * 2 for i in range(10) if i % 2 == 0}
print(numbers)  
# {0: 0, 2: 4, 4: 8, 6: 12, 8: 16}
`

**3. ทำการปฏิบัติการบนรายการ**

`python
numbers = {i: i ** 2 for i in range(5)}
print(numbers)  
# {0: 0, 1: 1, 2: 4, 3: 9, 4: 16}
`

**4. รวมสองรายการเข้าด้วยกัน**

`python
names = [&#39;John&#39;, &#39;Alice&#39;, &#39;Bob&#39;]
ages = [25, 30, 35]

people = {name: age for name, age in zip(names, ages)}
print(people)  
# {&#39;John&#39;: 25, &#39;Alice&#39;: 30, &#39;Bob&#39;: 35}
`

นี่คือตัวอย่างการใช้งาน dictionary comprehension ในภาษา Python มีหลายกรณีที่สามารถใช้ได้ และมันช่วยให้คุณเขียนโค้ดที่กระชับและง่ายดายมากขึ้น!

ความแตกต่างระหว่าง list comprehension และ dictionary comprehension คือ:

* List comprehension สร้างรายการ (list) ขณะที่ dictionary comprehension สร้าง辞านวารี (dictionary)
* ใน list comprehension เราสามารถใช้คำสั่ง `for` ได้ทั้งสองฝ่าย (left-hand side และ right-hand side) ในขณะที่ใน dictionary comprehension เราสามารถใช้คำสั่ง `for` ได้เพียงฝ่ายหนึ่งเท่านั้น
</code></pre><h2 id="การปรบแตงพารามเตอร">การปรับแต่งพารามิเตอร์<a hidden class="anchor" aria-hidden="true" href="#การปรบแตงพารามเตอร">#</a></h2>
<p>เราสามารถปรับแต่งการทำงานของ LLM ได้ผ่านพารามิเตอร์ต่างๆ:</p>
<p>สร้างไฟล์ <code>advanced_chat.py</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">ollama</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">advanced_chat</span><span class="p">(</span><span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3.1&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
</span></span><span class="line"><span class="cl">        <span class="n">options</span><span class="o">=</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;temperature&#39;</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">,</span>  <span class="c1"># ควบคุมความสร้างสรรค์ (0.0 - 1.0)</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;top_p&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>       <span class="c1"># ควบคุมความหลากหลายของคำตอบ</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;top_k&#39;</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span>        <span class="c1"># จำนวนโทเค็นที่พิจารณา</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;num_predict&#39;</span><span class="p">:</span> <span class="mi">4069</span>  <span class="c1"># ความยาวสูงสุดของคำตอบ</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ทดสอบเรียกใช้งาน</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">prompt</span> <span class="o">=</span> <span class="s2">&#34;เล่าเรื่องตลกให้ฟังหน่อยสิ&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">advanced_chat</span><span class="p">(</span><span class="n">prompt</span><span class="p">))</span>
</span></span></code></pre></div><p>ลองรันทดสอบ:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">python advanced_chat.py
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>มีชายคนหนึ่งซื้อหมูจากตลาดกลับบ้านเพื่อให้ทานเย็น แต่เมื่อลูกสาวของเขาเห็นหมู เธอก็บอกพ่อว่า &#34;พ่อ ฉันอยากจะเลี้ยงหมูตัวนั้นก่อน&#34;

ชายคนนั้นพยายามที่จะทำให้ลูกสาวตกใจและบอกเธอว่า &#34;หมูนี้เป็นหมูที่มีชื่อเสียงมาก มันสามารถปรุงแต่งอาหารได้ทุกชนิด แต่สิ่งที่สำคัญที่สุดคือมันไม่ต้องการเงิน&#34;

หญิงสาวตอบว่า &#34;นั่นก็ทำให้ฉันประหลาดใจจริงๆ ที่เราสามารถจ่ายค่าตอบแทนทางเงินให้มันได้!&#34;
</code></pre><h2 id="การใชงานกบ-stream">การใช้งานกับ Stream<a hidden class="anchor" aria-hidden="true" href="#การใชงานกบ-stream">#</a></h2>
<p>Ollama รองรับการ stream ข้อความตอบกลับแบบ real-time:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">ollama</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">stream_chat</span><span class="p">(</span><span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">stream</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3.1&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
</span></span><span class="line"><span class="cl">        <span class="n">stream</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># พิมพ์ข้อความทีละส่วนตามที่ได้รับ</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">chunk</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="การจดการกบขอผดพลาด">การจัดการกับข้อผิดพลาด<a hidden class="anchor" aria-hidden="true" href="#การจดการกบขอผดพลาด">#</a></h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">ollama</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">safe_chat</span><span class="p">(</span><span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama3.1&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}]</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="sa">f</span><span class="s2">&#34;เกิดข้อผิดพลาด: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span></code></pre></div><h2 id="ขอควรระวงและขอจำกด">ข้อควรระวังและข้อจำกัด<a hidden class="anchor" aria-hidden="true" href="#ขอควรระวงและขอจำกด">#</a></h2>
<ol>
<li>
<p>ทรัพยากรเครื่อง</p>
<ul>
<li>ต้องการ RAM อย่างน้อย 8GB</li>
<li>ควรมี GPU สำหรับประสิทธิภาพที่ดี</li>
<li>พื้นที่ดิสก์สำหรับเก็บโมเดล (ประมาณ 4-8GB ต่อโมเดล)</li>
</ul>
</li>
<li>
<p>ความแม่นยำ</p>
<ul>
<li>Local LLM อาจมีความแม่นยำน้อยกว่าโมเดลออนไลน์</li>
<li>ควรตรวจสอบผลลัพธ์เสมอ โดยเฉพาะในงานสำคัญ</li>
</ul>
</li>
<li>
<p>การอัพเดท</p>
<ul>
<li>ติดตามการอัพเดทของ Ollama และโมเดลอยู่เสมอ</li>
<li>อาจต้อง pull โมเดลใหม่เมื่อมีเวอร์ชันอัพเดท</li>
</ul>
</li>
</ol>
<h2 id="สรป">สรุป<a hidden class="anchor" aria-hidden="true" href="#สรป">#</a></h2>
<p>การใช้ Local LLM ผ่าน Ollama เป็นทางเลือกที่น่าสนใจสำหรับผู้ที่ต้องการความเป็นส่วนตัวหรือต้องการระบบที่ทำงานได้แบบ offline ถึงแม้จะมีข้อจำกัดบางประการ แต่ก็สามารถนำไปประยุกต์ใช้ได้หลากหลาย ตั้งแต่การสร้าง chatbot ไปจนถึงการประมวลผลเอกสาร</p>
<h2 id="แหลงขอมลเพมเตม">แหล่งข้อมูลเพิ่มเติม<a hidden class="anchor" aria-hidden="true" href="#แหลงขอมลเพมเตม">#</a></h2>
<ul>
<li><a href="https://github.com/toffysoft/ollama-python-example">GitHub Repo</a></li>
<li><a href="https://ollama.com/docs">Ollama Official Documentation</a></li>
<li><a href="https://github.com/ollama/ollama">Ollama GitHub Repository</a></li>
<li><a href="https://github.com/ollama/ollama-python">Python Package Documentation</a></li>
</ul>
<hr>
<p><em>บทความนี้อัพเดทล่าสุด: กุมภาพันธ์ 2025</em></p>
<p><em>Note: ตัวอย่างโค้ดทั้งหมดทดสอบบน Python 3.10+</em></p>
<p><em>Cover image by <a href="https://ollama.com">Ollama</a></em></p>
<p><em>ปล. บทความนี้เขียนด้วย AI  (^ . ^)</em></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/ai/">AI</a></li>
      <li><a href="http://localhost:1313/tags/llm/">LLM</a></li>
      <li><a href="http://localhost:1313/tags/python/">Python</a></li>
      <li><a href="http://localhost:1313/tags/ollama/">Ollama</a></li>
      <li><a href="http://localhost:1313/tags/local-development/">Local Development</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/posts/agent-example/">
    <span class="title">« Prev</span>
    <br>
    <span>ลองเล่น Deepseek-R1 และสร้าง AI Agent ด้วย Langgraph</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ลองเล่น Local LLM ด้วย Ollama &#43; Python on x"
            href="https://x.com/intent/tweet/?text=%e0%b8%a5%e0%b8%ad%e0%b8%87%e0%b9%80%e0%b8%a5%e0%b9%88%e0%b8%99%20Local%20LLM%20%e0%b8%94%e0%b9%89%e0%b8%a7%e0%b8%a2%20Ollama%20%2b%20Python&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2follama-python%2f&amp;hashtags=AI%2cLLM%2cPython%2cOllama%2cLocalDevelopment">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ลองเล่น Local LLM ด้วย Ollama &#43; Python on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2follama-python%2f&amp;title=%e0%b8%a5%e0%b8%ad%e0%b8%87%e0%b9%80%e0%b8%a5%e0%b9%88%e0%b8%99%20Local%20LLM%20%e0%b8%94%e0%b9%89%e0%b8%a7%e0%b8%a2%20Ollama%20%2b%20Python&amp;summary=%e0%b8%a5%e0%b8%ad%e0%b8%87%e0%b9%80%e0%b8%a5%e0%b9%88%e0%b8%99%20Local%20LLM%20%e0%b8%94%e0%b9%89%e0%b8%a7%e0%b8%a2%20Ollama%20%2b%20Python&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2follama-python%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ลองเล่น Local LLM ด้วย Ollama &#43; Python on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2follama-python%2f&title=%e0%b8%a5%e0%b8%ad%e0%b8%87%e0%b9%80%e0%b8%a5%e0%b9%88%e0%b8%99%20Local%20LLM%20%e0%b8%94%e0%b9%89%e0%b8%a7%e0%b8%a2%20Ollama%20%2b%20Python">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ลองเล่น Local LLM ด้วย Ollama &#43; Python on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2follama-python%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ลองเล่น Local LLM ด้วย Ollama &#43; Python on whatsapp"
            href="https://api.whatsapp.com/send?text=%e0%b8%a5%e0%b8%ad%e0%b8%87%e0%b9%80%e0%b8%a5%e0%b9%88%e0%b8%99%20Local%20LLM%20%e0%b8%94%e0%b9%89%e0%b8%a7%e0%b8%a2%20Ollama%20%2b%20Python%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2follama-python%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ลองเล่น Local LLM ด้วย Ollama &#43; Python on telegram"
            href="https://telegram.me/share/url?text=%e0%b8%a5%e0%b8%ad%e0%b8%87%e0%b9%80%e0%b8%a5%e0%b9%88%e0%b8%99%20Local%20LLM%20%e0%b8%94%e0%b9%89%e0%b8%a7%e0%b8%a2%20Ollama%20%2b%20Python&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2follama-python%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ลองเล่น Local LLM ด้วย Ollama &#43; Python on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=%e0%b8%a5%e0%b8%ad%e0%b8%87%e0%b9%80%e0%b8%a5%e0%b9%88%e0%b8%99%20Local%20LLM%20%e0%b8%94%e0%b9%89%e0%b8%a7%e0%b8%a2%20Ollama%20%2b%20Python&u=http%3a%2f%2flocalhost%3a1313%2fposts%2follama-python%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Toffysoft&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
