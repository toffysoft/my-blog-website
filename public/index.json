[{"content":"AI Agent คืออะไร? ในโลกของปัญญาประดิษฐ์ AI Agent คือระบบอัจฉริยะที่ถูกออกแบบมาให้สามารถรับรู้สภาพแวดล้อม วิเคราะห์ข้อมูล และตัดสินใจดำเนินการเพื่อบรรลุเป้าหมายที่กำหนดไว้ AI Agent อาจอยู่ในรูปแบบของซอฟต์แวร์ หรือในบางกรณีอาจเป็นระบบที่มีร่างกาย เช่น หุ่นยนต์ หรือรถยนต์ไร้คนขับ\nคุณลักษณะสำคัญของ AI Agent ความเป็นอิสระในการทำงาน (Autonomy) AI Agent สามารถทำงานได้โดยไม่ต้องพึ่งพาการควบคุมจากมนุษย์โดยตรง เมื่อได้รับการตั้งค่าหรือคำสั่งเริ่มต้นแล้ว จะสามารถตัดสินใจและดำเนินการได้ด้วยตัวเอง\nความสามารถในการรับรู้ (Perception) AI Agent สามารถรวบรวมข้อมูลจากแหล่งต่างๆ ไม่ว่าจะเป็น:\nข้อมูลจากเซนเซอร์ ฐานข้อมูลที่มีโครงสร้าง ข้อความภาษาธรรมชาติ รูปภาพและเสียง การป้อนข้อมูลจากผู้ใช้ การสร้างโมเดลสถานะ (State Modeling) ระบบจะเก็บรักษาข้อมูลสภาพแวดล้อมภายในไว้ ซึ่งอาจรวมถึง:\nสภาวะปัจจุบัน ข้อมูลที่ได้เรียนรู้ ความสัมพันธ์ที่วิเคราะห์ได้ โมเดลนี้ช่วยให้ AI Agent เข้าใจบริบท คาดการณ์สถานะในอนาคต และพิจารณาผลลัพธ์ที่อาจเกิดขึ้นจากการกระทำของตน การตัดสินใจและการให้เหตุผล (Decision Making) AI Agent ใช้ฟังก์ชันการคิดวิเคราะห์ตั้งแต่:\nตรรกะแบบง่ายที่ใช้กฎ ไปจนถึงโมเดลการเรียนรู้ของเครื่องที่ซับซ้อน บาง Agent ใช้กลไกการอนุมานที่กำหนดไว้ล่วงหน้า ในขณะที่บางตัวใช้เทคนิคขั้นสูงเช่น Reinforcement Learning หรือ Deep Learning ตัวอย่างการทำงานของ AI Agent ลองมาดูตัวอย่างการทำงานของ AI Agent ในการจัดการอีเมลแบบอัตโนมัติ:\nกระบวนการทำงาน การเริ่มต้นจากผู้ใช้ เมื่อผู้ใช้ส่งคำขอ เช่น \u0026ldquo;กรองอีเมลตามความสำคัญและแจ้งเตือนอีเมลที่สำคัญที่สุด 3 ฉบับ\u0026rdquo; AI Agent จะเริ่มทำงาน\nการตีความโดย LLM ระบบ Large Language Model จะทำความเข้าใจคำขอและวางแผนขั้นตอนที่จำเป็น\nการเข้าถึงข้อมูลภายนอก AI Agent จะเชื่อมต่อกับ API ของอีเมลและดึงข้อมูลที่จำเป็น\nการประมวลผลและจัดอันดับ ระบบจะวิเคราะห์ความสำคัญของอีเมลโดยพิจารณาจาก:\nความสำคัญของผู้ส่ง การตรวจจับคำสำคัญ การใช้โมเดล Machine Learning ที่เรียนรู้จากพฤติกรรมของผู้ใช้ การสรุปและรายงาน AI Agent จะสร้างสรุปกระชับและส่งการแจ้งเตือนไปยังผู้ใช้\nความแตกต่างระหว่าง AI Agent และระบบตอบคำถามทั่วไป ระบบตอบคำถามทั่วไป (Simple Query Bot) ทำงานแบบขั้นตอนเดียว: รับคำถาม-ให้คำตอบ มีความฉลาดจำกัด: เพียงจับคู่คำขอกับหมวดหมู่ที่กำหนดไว้ ใช้เครื่องมือแบบจำกัด: เรียกใช้ API เดียวและส่งคืนผลลัพธ์ AI Agent การคิดวิเคราะห์หลายขั้นตอน\nแยกงานซับซ้อนเป็นงานย่อย วางแผนและจัดลำดับการทำงาน การใช้เครื่องมือหลากหลาย\nสามารถเรียกใช้ API หลายตัว บูรณาการผลลัพธ์จากแหล่งต่างๆ ความจำ\nจดจำขั้นตอนระหว่างทาง เก็บข้อมูลความชอบของผู้ใช้ การตัดสินใจแบบวนซ้ำ\nปรับเปลี่ยนกลยุทธ์ตามผลลัพธ์ ทำซ้ำจนกว่าจะบรรลุเป้าหมาย AI Agent ในโลกแห่งความเป็นจริง หุ่นยนต์มนุษย์ (Humanoid Robots) หุ่นยนต์มนุษย์จะถือเป็น AI Agent ก็ต่อเมื่อมีระบบควบคุมที่ฉลาด หุ่นยนต์มนุษย์ขั้นสูงใช้เทคโนโลยีหลายอย่าง เช่น:\nการประมวลผลภาษาธรรมชาติ การมองเห็นด้วยคอมพิวเตอร์ การเรียนรู้ของเครื่อง เพื่อทำความเข้าใจสภาพแวดล้อม สื่อสารกับมนุษย์ และโต้ตอบแบบไดนามิก รถยนต์ไร้คนขับ (Autonomous Cars) รถยนต์ไร้คนขับเป็นตัวอย่างที่ดีของ AI Agent ที่ใช้งานจริง โดยใช้:\nเซนเซอร์หลากหลาย (กล้อง, ไลดาร์, เรดาร์, GPS) อัลกอริทึมการรับรู้ขั้นสูง โมเดลการคาดการณ์ ระบบตัดสินใจ เพื่อนำทางบนถนนอย่างปลอดภัย หุ่นยนต์ประเภทอื่นๆ หุ่นยนต์จะถือเป็น AI Agent เมื่อมีความสามารถในการ:\nรับรู้สภาพแวดล้อม ตัดสินใจอย่างอิสระ ดำเนินการเพื่อบรรลุเป้าหมาย ตัวอย่างเช่น หุ่นยนต์บริการในโรงแรม หุ่นยนต์ในคลังสินค้า หรือโดรน ที่ใช้ระบบ AI ในการนำทางและตัดสินใจ\nบทสรุป AI Agent เป็นมากกว่าระบบตอบคำถามทั่วไป โดยรวมความสามารถหลายด้านเข้าด้วยกัน:\nการให้เหตุผล การใช้เครื่องมือ ความจำ การตัดสินใจ ทำให้ AI Agent มีประสิทธิภาพในการจัดการงานที่ซับซ้อน เช่น:\nการวางแผนการเดินทาง การจัดการโครงการ การจัดการกิจกรรม และงานอื่นๆ ที่ต้องการมากกว่าการตอบคำถามเพียงขั้นตอนเดียว ในอนาคต AI Agent จะมีบทบาทสำคัญมากขึ้นในการช่วยเหลือมนุษย์ ทั้งในรูปแบบของซอฟต์แวร์และระบบที่มีร่างกาย การเข้าใจพื้นฐานและความสามารถของ AI Agent จึงเป็นสิ่งสำคัญสำหรับการเตรียมพร้อมรับมือกับเทคโนโลยีที่กำลังพัฒนาอย่างรวดเร็วนี้\nแหล่งข้อมูลเพิ่มเติม Defining AI Agents - Software, Robots, Autonomous Cars, and Humanoids Cover image by viscovery\nปล. บทความนี้เขียนด้วย AI (^ . ^)\n","permalink":"http://localhost:1313/posts/agentic-ai/understanding-ai-agents/","summary":"\u003ch2 id=\"ai-agent-คออะไร\"\u003eAI Agent คืออะไร?\u003c/h2\u003e\n\u003cp\u003eในโลกของปัญญาประดิษฐ์ AI Agent คือระบบอัจฉริยะที่ถูกออกแบบมาให้สามารถรับรู้สภาพแวดล้อม วิเคราะห์ข้อมูล และตัดสินใจดำเนินการเพื่อบรรลุเป้าหมายที่กำหนดไว้ AI Agent อาจอยู่ในรูปแบบของซอฟต์แวร์ หรือในบางกรณีอาจเป็นระบบที่มีร่างกาย เช่น หุ่นยนต์ หรือรถยนต์ไร้คนขับ\u003c/p\u003e\n\u003ch3 id=\"คณลกษณะสำคญของ-ai-agent\"\u003eคุณลักษณะสำคัญของ AI Agent\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eความเป็นอิสระในการทำงาน (Autonomy)\u003c/strong\u003e\nAI Agent สามารถทำงานได้โดยไม่ต้องพึ่งพาการควบคุมจากมนุษย์โดยตรง เมื่อได้รับการตั้งค่าหรือคำสั่งเริ่มต้นแล้ว จะสามารถตัดสินใจและดำเนินการได้ด้วยตัวเอง\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eความสามารถในการรับรู้ (Perception)\u003c/strong\u003e\nAI Agent สามารถรวบรวมข้อมูลจากแหล่งต่างๆ ไม่ว่าจะเป็น:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eข้อมูลจากเซนเซอร์\u003c/li\u003e\n\u003cli\u003eฐานข้อมูลที่มีโครงสร้าง\u003c/li\u003e\n\u003cli\u003eข้อความภาษาธรรมชาติ\u003c/li\u003e\n\u003cli\u003eรูปภาพและเสียง\u003c/li\u003e\n\u003cli\u003eการป้อนข้อมูลจากผู้ใช้\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eการสร้างโมเดลสถานะ (State Modeling)\u003c/strong\u003e\nระบบจะเก็บรักษาข้อมูลสภาพแวดล้อมภายในไว้ ซึ่งอาจรวมถึง:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eสภาวะปัจจุบัน\u003c/li\u003e\n\u003cli\u003eข้อมูลที่ได้เรียนรู้\u003c/li\u003e\n\u003cli\u003eความสัมพันธ์ที่วิเคราะห์ได้\nโมเดลนี้ช่วยให้ AI Agent เข้าใจบริบท คาดการณ์สถานะในอนาคต และพิจารณาผลลัพธ์ที่อาจเกิดขึ้นจากการกระทำของตน\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eการตัดสินใจและการให้เหตุผล (Decision Making)\u003c/strong\u003e\nAI Agent ใช้ฟังก์ชันการคิดวิเคราะห์ตั้งแต่:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eตรรกะแบบง่ายที่ใช้กฎ\u003c/li\u003e\n\u003cli\u003eไปจนถึงโมเดลการเรียนรู้ของเครื่องที่ซับซ้อน\nบาง Agent ใช้กลไกการอนุมานที่กำหนดไว้ล่วงหน้า ในขณะที่บางตัวใช้เทคนิคขั้นสูงเช่น Reinforcement Learning หรือ Deep Learning\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"ตวอยางการทำงานของ-ai-agent\"\u003eตัวอย่างการทำงานของ AI Agent\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"ai_agent\" loading=\"lazy\" src=\"https://raw.githubusercontent.com/panaversity/learn-agentic-ai/refs/heads/main/05_ai_agents_intro/00_defining_ai_agents/ai_agent.jpg\"\u003e\u003c/p\u003e","title":"เข้าใจ AI Agent: จากซอฟต์แวร์สู่หุ่นยนต์มนุษย์"},{"content":"AI Agent กับการปฏิวัติวงการ SaaS: เมื่อซอฟต์แวร์กลายเป็นผู้ช่วยอัจฉริยะ ในยุคที่เทคโนโลยี AI กำลังก้าวหน้าอย่างรวดเร็ว เราจะได้เห็นการเปลี่ยนแปลงครั้งใหญ่ในวงการซอฟต์แวร์แบบ SaaS (Software-as-a-Service) ที่จะถูกขับเคลื่อนด้วย AI Agent หรือตัวแทนอัจฉริยะ บทความนี้จะพาคุณไปทำความเข้าใจว่า AI Agent จะเข้ามาเปลี่ยนแปลงการใช้งานซอฟต์แวร์ของเราอย่างไรบ้าง\nการปรับแต่งประสบการณ์ผู้ใช้แบบเฉพาะบุคคลขั้นสูง ลองนึกภาพว่าซอฟต์แวร์ของคุณสามารถปรับเปลี่ยนตัวเองให้เข้ากับการทำงานของคุณได้โดยอัตโนมัติ ไม่ใช่แค่หน้าจอเดิมๆ ที่ทุกคนเห็นเหมือนกัน แต่เป็นระบบที่เข้าใจพฤติกรรม บทบาท และความชอบของคุณ\nตัวอย่างเช่น ในซอฟต์แวร์จัดการโครงการ ระบบจะแสดงรายการงานที่เกี่ยวข้องกับโครงการล่าสุดของคุณ พร้อมแนะนำทรัพยากรที่เหมาะสม และสร้างทางลัดที่สอดคล้องกับรูปแบบการทำงานของคุณ นอกจากนี้ ระบบยังสามารถเตือนให้คุณทำงานที่ค้างอยู่ให้เสร็จ ชี้ให้เห็นความผิดปกติในรายงานการเงิน หรือแนะนำพารามิเตอร์ที่เหมาะสมสำหรับแคมเปญการตลาด โดยที่คุณไม่ต้องถามเลย\nการทำงานอัตโนมัติที่ชาญฉลาด AI Agent ไม่ได้แค่ให้คำแนะนำ แต่สามารถดำเนินการแทนคุณได้ด้วย สมมติว่าคุณใช้ซอฟต์แวร์สำหรับงานบริการลูกค้า แทนที่จะแค่แนะนำเทมเพลตอีเมล ระบบสามารถ:\nเขียนอีเมลตอบกลับที่ปรับแต่งให้เหมาะกับแต่ละลูกค้า จัดการนัดหมายโดยอัตโนมัติ เริ่มขั้นตอนการแก้ไขปัญหาเบื้องต้นได้เอง ที่สำคัญคือ AI Agent สามารถเรียนรู้จากข้อมูลในอดีตและการตอบสนองของผู้ใช้ เมื่อพบรูปแบบการทำงานที่เกิดขึ้นซ้ำๆ เช่น การตอบกลับติกเก็ตสนับสนุนประเภทหนึ่งที่ต้องใช้คำตอบแบบเดียวกันเสมอ ระบบจะสามารถเสนอหรือสร้างระบบอัตโนมัติใหม่ได้เอง โดยที่คุณไม่ต้องตั้งค่าอะไรเพิ่มเติม\nการวิเคราะห์ข้อมูลและสร้างข้อมูลเชิงลึกขั้นสูง ลืมเรื่องการเขียนคำสั่ง SQL หรือการเรียนรู้ภาษาสำหรับสืบค้นข้อมูลที่ซับซ้อนไปได้เลย ด้วย AI Agent คุณสามารถถามคำถามด้วยภาษาธรรมชาติได้ เช่น \u0026ldquo;แคมเปญการตลาดไหนที่มีอัตราการเปลี่ยนเป็นลูกค้าสูงที่สุดในไตรมาสที่แล้ว?\u0026rdquo; แล้วระบบจะให้ข้อมูลเชิงลึกที่มีความหมายกลับมา\nนอกจากนี้ AI Agent ยังสามารถแจ้งเตือนเชิงรุกเกี่ยวกับ:\nแนวโน้มที่สำคัญ ความผิดปกติที่ตรวจพบ คำแนะนำในการปรับเปลี่ยนกลยุทธ์ ตัวอย่างเช่น ซอฟต์แวร์จัดการรายได้อาจแจ้งผู้นำฝ่ายขายว่า \u0026ldquo;อัตราการเปลี่ยนเป็นลูกค้าลดลง 10% เมื่อเทียบกับเดือนที่แล้ว โดยเฉพาะในบัญชีลูกค้าองค์กรสองราย คุณต้องการเริ่มแคมเปญติดต่อลูกค้าแบบเฉพาะเจาะจงหรือไม่?\u0026rdquo;\nการเรียนรู้อย่างต่อเนื่องและการพัฒนาโมเดล AI Agent ไม่ได้หยุดนิ่งอยู่กับที่ แต่จะเรียนรู้และพัฒนาตัวเองอย่างต่อเนื่อง:\nอัปเดตโมเดลแบบอัตโนมัติตามข้อมูลใหม่ที่เข้ามา ปรับปรุงการแนะนำและการทำนาย พัฒนาระบบอัตโนมัติให้ดีขึ้นแบบเรียลไทม์ ที่น่าสนใจคือการใช้เทคนิค Federated Learning ที่ช่วยให้โมเดล AI สามารถเรียนรู้จากข้อมูลของผู้ใช้จำนวนมาก โดยที่ยังรักษาความปลอดภัยของข้อมูลบริษัทแต่ละแห่ง ทำให้ผู้ใช้ทุกคนได้รับประโยชน์จากความฉลาดที่เพิ่มขึ้นของระบบ โดยไม่ต้องกังวลเรื่องการรั่วไหลของข้อมูล\nAI Agent เฉพาะทางและการทำงานข้ามโดเมน เราจะได้เห็น AI Agent ที่เชี่ยวชาญเฉพาะด้านมากขึ้น เช่น:\nในซอฟต์แวร์สำหรับการดูแลสุขภาพ อาจมี AI Agent ที่เชี่ยวชาญเรื่องกฎระเบียบทางการแพทย์และรหัสการเบิกประกัน ในระบบจัดการซัพพลายเชน อาจมีโมดูล AI ที่ทำนายปัญหาคอขวดในการขนส่งและแนะนำเส้นทางที่เหมาะสมที่สุด นอกจากนี้ AI Agent ยังสามารถทำงานข้ามระบบต่างๆ ได้ ไม่ว่าจะเป็น CRM, ERP หรือ HRM โดยสามารถดึงและสังเคราะห์ข้อมูลที่เกี่ยวข้องจากแต่ละระบบ ผู้บริหารสามารถถามคำถามง่ายๆ เช่น \u0026ldquo;สรุปภาพรวมสุขภาพองค์กรในไตรมาสนี้\u0026rdquo; แล้ว AI Agent จะรวบรวมข้อมูลจากการพยากรณ์การขาย ตารางการผลิต และรายงานด้านบุคลากร มาสร้างเป็นสรุปที่ครอบคลุมและเข้าใจง่าย\nการลดภาระทางความคิดและเพิ่มความสามารถในการเข้าถึง ซอฟต์แวร์องค์กรสมัยใหม่มักมีฟีเจอร์หลายร้อยอย่างที่ผู้ใช้ไม่ได้ใช้งาน เพราะรู้สึกว่ามากเกินไปหรือไม่แน่ใจว่าจะใช้อย่างไร AI Agent จะช่วย:\nแสดงฟีเจอร์ที่เกี่ยวข้องในเวลาที่เหมาะสม ลดความซับซ้อนสำหรับผู้ใช้ใหม่ เพิ่มฟีเจอร์ให้เห็นตามระดับความชำนาญที่เพิ่มขึ้น ยกตัวอย่างเช่น CFO ที่ต้องการวิเคราะห์การเงินเฉพาะด้าน แต่ไม่มีเวลามาเรียนรู้การใช้แดชบอร์ด BI ที่ซับซ้อน AI Agent สามารถแปลงคำขอที่เป็นภาษาธรรมชาติให้เป็นคำสั่งฐานข้อมูลที่จำเป็น และสร้างผลลัพธ์ที่เข้าใจง่ายพร้อมการแสดงผลที่เหมาะสม\nวิวัฒนาการของโมเดลธุรกิจ SaaS AI Agent จะกลายเป็นปัจจัยสำคัญในการแข่งขันของผู้ให้บริการ SaaS:\nการแข่งขันจะไม่ได้อยู่ที่จำนวนฟีเจอร์เพียงอย่างเดียว แต่รวมถึงความฉลาด ความสามารถในการปรับตัว และความเป็นอิสระของ AI รูปแบบการคิดค่าบริการอาจเปลี่ยนไป เช่น คิดตามการใช้งาน AI แพ็คเกจความฉลาดพิเศษ หรือแม้แต่การคิดค่าบริการตามผลลัพธ์ที่ได้ ความสัมพันธ์ระหว่างผู้ให้บริการและลูกค้าจะเปลี่ยนจากการขายซอฟต์แวร์รายเดือน เป็นการให้บริการพาร์ทเนอร์ที่เรียนรู้และพัฒนาอย่างต่อเนื่อง อาจมีบริการเพิ่มเติมเช่น:\nการปรับแต่งโมเดล AI ให้เหมาะกับธุรกิจ การเชื่อมต่อระบบแบบเฉพาะทาง บริการผู้เชี่ยวชาญด้าน AI ที่คอยให้คำปรึกษา ในอนาคต SaaS จะกลายเป็นระบบนิเวศที่ผู้ให้บริการและลูกค้าร่วมกันสร้างคุณค่า มากกว่าการเป็นแค่เครื่องมือซอฟต์แวร์ธรรมดา\nอนาคตของ SaaS กับ AI Agent เมื่อ AI Agent เข้ามามีบทบาทมากขึ้น เราจะเห็นการเปลี่ยนแปลงครั้งใหญ่ในวงการ SaaS ที่จะส่งผลกระทบต่อทั้งผู้ให้บริการและผู้ใช้งาน:\nสำหรับผู้ให้บริการ SaaS การแข่งขันจะไม่ใช่แค่เรื่องฟีเจอร์อีกต่อไป แต่จะเป็นเรื่องของความสามารถในการสร้างประสบการณ์ที่ชาญฉลาดและเป็นส่วนตัว ผู้ให้บริการจะต้องลงทุนในการพัฒนา:\nโมเดล AI ที่เชี่ยวชาญเฉพาะอุตสาหกรรม ระบบการเรียนรู้ที่ปลอดภัยและมีประสิทธิภาพ การบูรณาการข้ามแพลตฟอร์มที่ราบรื่น ความสามารถในการปรับแต่งระบบตามความต้องการของลูกค้า สำหรับผู้ใช้งาน ประสบการณ์การใช้งานซอฟต์แวร์จะเปลี่ยนไปอย่างสิ้นเชิง เสมือนมีผู้ช่วยที่ชาญฉลาดคอยทำงานร่วมกับคุณ:\nลดเวลาในการเรียนรู้ระบบใหม่ เพิ่มประสิทธิภาพในการทำงานผ่านระบบอัตโนมัติที่ชาญฉลาด ได้รับข้อมูลเชิงลึกที่เป็นประโยชน์โดยไม่ต้องเสียเวลาวิเคราะห์ มีระบบที่เข้าใจและปรับตัวตามความต้องการของคุณ บทสรุป: อนาคตของ SaaS ที่ขับเคลื่อนด้วย AI AI Agent จะเปลี่ยนโฉมหน้าของวงการ SaaS อย่างสิ้นเชิง ทำให้เกิดระบบที่:\nเข้าใจบริบทและความต้องการของผู้ใช้ เรียนรู้จากทุกการโต้ตอบเพื่อพัฒนาตัวเอง คาดการณ์และแก้ปัญหาได้ล่วงหน้า ให้ข้อมูลเชิงลึกและระบบอัตโนมัติที่ลึกซึ้งกว่าที่เคยมีมา ผู้ใช้จะสามารถโต้ตอบกับซอฟต์แวร์ได้อย่างเป็นธรรมชาติมากขึ้น ราวกับกำลังคุยกับเพื่อนร่วมงานที่เชี่ยวชาญและเข้าใจธุรกิจของคุณอย่างลึกซึ้ง ในระยะยาว สิ่งนี้จะยกระดับมาตรฐานของการให้บริการ SaaS โดยทำให้ความฉลาด ความสามารถในการปรับตัว และระบบอัตโนมัติที่เป็นส่วนตัว กลายเป็นส่วนสำคัญของโซลูชันดิจิทัลสมัยใหม่ทุกระบบ\nไม่ว่าคุณจะเป็นผู้ให้บริการหรือผู้ใช้งาน SaaS การเข้าใจและเตรียมพร้อมสำหรับการเปลี่ยนแปลงนี้จะเป็นกุญแจสำคัญสู่ความสำเร็จในยุคดิจิทัลที่กำลังจะมาถึง เพราะ AI Agent ไม่ใช่แค่เทรนด์ชั่วคราว แต่เป็นการเปลี่ยนแปลงพื้นฐานที่จะกำหนดอนาคตของการใช้งานซอฟต์แวร์ในองค์กร\nแหล่งข้อมูลเพิ่มเติม AI Agents will Transform SaaS ปล. บทความนี้เขียนด้วย AI (^ . ^)\n","permalink":"http://localhost:1313/posts/agentic-ai/agents-transform-saas/","summary":"\u003ch1 id=\"ai-agent-กบการปฏวตวงการ-saas-เมอซอฟตแวรกลายเปนผชวยอจฉรยะ\"\u003eAI Agent กับการปฏิวัติวงการ SaaS: เมื่อซอฟต์แวร์กลายเป็นผู้ช่วยอัจฉริยะ\u003c/h1\u003e\n\u003cp\u003eในยุคที่เทคโนโลยี AI กำลังก้าวหน้าอย่างรวดเร็ว เราจะได้เห็นการเปลี่ยนแปลงครั้งใหญ่ในวงการซอฟต์แวร์แบบ SaaS (Software-as-a-Service) ที่จะถูกขับเคลื่อนด้วย AI Agent หรือตัวแทนอัจฉริยะ บทความนี้จะพาคุณไปทำความเข้าใจว่า AI Agent จะเข้ามาเปลี่ยนแปลงการใช้งานซอฟต์แวร์ของเราอย่างไรบ้าง\u003c/p\u003e\n\u003ch2 id=\"การปรบแตงประสบการณผใชแบบเฉพาะบคคลขนสง\"\u003eการปรับแต่งประสบการณ์ผู้ใช้แบบเฉพาะบุคคลขั้นสูง\u003c/h2\u003e\n\u003cp\u003eลองนึกภาพว่าซอฟต์แวร์ของคุณสามารถปรับเปลี่ยนตัวเองให้เข้ากับการทำงานของคุณได้โดยอัตโนมัติ ไม่ใช่แค่หน้าจอเดิมๆ ที่ทุกคนเห็นเหมือนกัน แต่เป็นระบบที่เข้าใจพฤติกรรม บทบาท และความชอบของคุณ\u003c/p\u003e\n\u003cp\u003eตัวอย่างเช่น ในซอฟต์แวร์จัดการโครงการ ระบบจะแสดงรายการงานที่เกี่ยวข้องกับโครงการล่าสุดของคุณ พร้อมแนะนำทรัพยากรที่เหมาะสม และสร้างทางลัดที่สอดคล้องกับรูปแบบการทำงานของคุณ นอกจากนี้ ระบบยังสามารถเตือนให้คุณทำงานที่ค้างอยู่ให้เสร็จ ชี้ให้เห็นความผิดปกติในรายงานการเงิน หรือแนะนำพารามิเตอร์ที่เหมาะสมสำหรับแคมเปญการตลาด โดยที่คุณไม่ต้องถามเลย\u003c/p\u003e\n\u003ch2 id=\"การทำงานอตโนมตทชาญฉลาด\"\u003eการทำงานอัตโนมัติที่ชาญฉลาด\u003c/h2\u003e\n\u003cp\u003eAI Agent ไม่ได้แค่ให้คำแนะนำ แต่สามารถดำเนินการแทนคุณได้ด้วย สมมติว่าคุณใช้ซอฟต์แวร์สำหรับงานบริการลูกค้า แทนที่จะแค่แนะนำเทมเพลตอีเมล ระบบสามารถ:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eเขียนอีเมลตอบกลับที่ปรับแต่งให้เหมาะกับแต่ละลูกค้า\u003c/li\u003e\n\u003cli\u003eจัดการนัดหมายโดยอัตโนมัติ\u003c/li\u003e\n\u003cli\u003eเริ่มขั้นตอนการแก้ไขปัญหาเบื้องต้นได้เอง\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eที่สำคัญคือ AI Agent สามารถเรียนรู้จากข้อมูลในอดีตและการตอบสนองของผู้ใช้ เมื่อพบรูปแบบการทำงานที่เกิดขึ้นซ้ำๆ เช่น การตอบกลับติกเก็ตสนับสนุนประเภทหนึ่งที่ต้องใช้คำตอบแบบเดียวกันเสมอ ระบบจะสามารถเสนอหรือสร้างระบบอัตโนมัติใหม่ได้เอง โดยที่คุณไม่ต้องตั้งค่าอะไรเพิ่มเติม\u003c/p\u003e\n\u003ch2 id=\"การวเคราะหขอมลและสรางขอมลเชงลกขนสง\"\u003eการวิเคราะห์ข้อมูลและสร้างข้อมูลเชิงลึกขั้นสูง\u003c/h2\u003e\n\u003cp\u003eลืมเรื่องการเขียนคำสั่ง SQL หรือการเรียนรู้ภาษาสำหรับสืบค้นข้อมูลที่ซับซ้อนไปได้เลย ด้วย AI Agent คุณสามารถถามคำถามด้วยภาษาธรรมชาติได้ เช่น \u0026ldquo;แคมเปญการตลาดไหนที่มีอัตราการเปลี่ยนเป็นลูกค้าสูงที่สุดในไตรมาสที่แล้ว?\u0026rdquo; แล้วระบบจะให้ข้อมูลเชิงลึกที่มีความหมายกลับมา\u003c/p\u003e\n\u003cp\u003eนอกจากนี้ AI Agent ยังสามารถแจ้งเตือนเชิงรุกเกี่ยวกับ:\u003c/p\u003e","title":"AI Agent กับการเปลี่ยนแปลงวงการ SaaS: เมื่อซอฟต์แวร์กลายเป็นผู้ช่วยอัจฉริยะ"},{"content":"ทำความรู้จักกับระบบ Multi-Agent ในโลกของปัญญาประดิษฐ์ที่กำลังก้าวหน้าอย่างรวดเร็ว ระบบ Multi-Agent Systems (MAS) กำลังเป็นเทคโนโลยีที่น่าจับตามอง แต่ระบบนี้คืออะไร? และทำไมมันถึงสำคัญ? มาทำความเข้าใจกันแบบง่ายๆ\nระบบ Multi-Agent คือการรวมตัวกันของ AI หลายๆ ตัว (เราเรียกแต่ละตัวว่า \u0026ldquo;Agent\u0026rdquo;) ที่มีความเชี่ยวชาญเฉพาะด้าน มาทำงานร่วมกันเพื่อแก้ปัญหาที่ซับซ้อน เปรียบเสมือนทีมงานมืออาชีพที่แต่ละคนมีความเชี่ยวชาญต่างกัน มารวมตัวกันทำงานให้สำเร็จ\nทำไมต้องใช้หลาย Agent? คุณอาจสงสัยว่าทำไมไม่ใช้ AI ตัวเดียวที่เก่งๆ? คำตอบคือ:\nแบ่งงานได้ดีกว่า: เหมือนการทำงานในบริษัท ที่แต่ละแผนกรับผิดชอบงานที่ตัวเองถนัด เชี่ยวชาญเฉพาะทาง: แต่ละ Agent มีความเชี่ยวชาญเฉพาะด้าน ทำให้ได้ผลลัพธ์ที่ดีกว่า ทำงานพร้อมกันได้: หลาย Agent สามารถทำงานไปพร้อมๆ กัน ทำให้เสร็จเร็วขึ้น ปรับขยายได้ง่าย: เพิ่มหรือลด Agent ได้ตามความต้องการ ตัวอย่างที่เห็นภาพ: ระบบพัฒนาโค้ด ลองมาดูตัวอย่างที่เข้าใจง่าย เป็นระบบที่ใช้ Multi-Agent ในการพัฒนาโค้ด Python:\nAgent หลักในระบบ Controller Agent (ผู้จัดการโครงการ)\nทำหน้าที่เป็นผู้ประสานงานหลัก คอยสั่งงานและจัดการการทำงานของ Agent อื่นๆ สามารถรันโค้ด Python เพื่อทดสอบได้ Coder Agent (นักพัฒนา)\nเชี่ยวชาญในการเขียนโค้ด รับคำสั่งจาก Controller แล้วสร้างโค้ดตามที่ต้องการ Tester Agent (นักทดสอบ)\nเชี่ยวชาญในการเขียนและรันเทสต์ ตรวจสอบว่าโค้ดทำงานถูกต้องหรือไม่ ขั้นตอนการทำงาน ผู้ใช้ส่งคำขอ เช่น \u0026ldquo;ช่วยเขียนฟังก์ชันคำนวณแฟคทอเรียลให้หน่อย\u0026rdquo; Controller รับงานและส่งต่อให้ Coder Coder เขียนโค้ดและส่งกลับมา Controller ส่งโค้ดให้ Tester ตรวจสอบ ถ้ามีปัญหา จะวนกลับไปให้ Coder แก้ไข ทำซ้ำจนกว่าโค้ดจะผ่านการทดสอบทั้งหมด การประยุกต์ใช้ในโลกจริง 1. ระบบวิเคราะห์ตลาด ลองดูตัวอย่างระบบที่ช่วยวิเคราะห์ตลาดสำหรับสินค้าใหม่:\nAgent ติดต่อผู้ใช้: คุยกับทีมผลิตภัณฑ์เพื่อเข้าใจความต้องการ Agent เก็บข้อมูล: ดึงข้อมูลราคาคู่แข่ง แนวโน้มตลาด Agent วิเคราะห์: ประมวลผลข้อมูล หาเทรนด์ ทำสถิติ Agent ทำรายงาน: จัดทำรายงานสรุปที่อ่านเข้าใจง่าย 2. ระบบซัพพอร์ตลูกค้า ระบบที่ช่วยแก้ปัญหาให้ลูกค้าแบบอัตโนมัติ:\nAgent รับเรื่อง: คุยกับลูกค้า เก็บรายละเอียดปัญหา Agent ค้นคู่มือ: หาวิธีแก้ปัญหาจากฐานความรู้ Agent วินิจฉัย: ตรวจสอบระบบ ดูล็อกการใช้งาน Agent แก้ปัญหา: เสนอวิธีแก้ไขหรือจัดการบัญชีลูกค้า Agent สื่อสาร: เขียนคำตอบที่เข้าใจง่าย เป็นมิตร การทำงานแบบอิสระและแบบมีคนควบคุม ระบบ Multi-Agent สามารถทำงานได้สองแบบ:\nแบบอัตโนมัติ Agent ตัดสินใจเองได้ตามกฎที่วางไว้ เรียนรู้และปรับตัวได้จากประสบการณ์ ขยายระบบได้ง่าย ไม่ต้องพึ่งคน แบบมีคนควบคุม รอการอนุมัติจากคนในบางขั้นตอน ปรับพฤติกรรมตามคำแนะนำของคน เหมาะกับงานที่ต้องการความแม่นยำสูง อนาคตของระบบ Multi-Agent เมื่อ AI พัฒนาขึ้นเรื่อยๆ ระบบ Multi-Agent จะยิ่งมีบทบาทสำคัญ เราอาจเห็น:\nAgent ที่ปรับบทบาทได้ตามสถานการณ์ ตลาดที่ Agent หลายๆ ตัวแข่งกันรับงาน ระบบที่ Agent เรียนรู้และพัฒนาตัวเองได้ สรุป ระบบ Multi-Agent เป็นก้าวสำคัญของวงการ AI ที่ช่วยให้เราแก้ปัญหาซับซ้อนได้ดีขึ้น ด้วยการแบ่งงานให้ Agent ที่เชี่ยวชาญเฉพาะด้าน และการประสานงานที่มีประสิทธิภาพ ทำให้ได้ผลลัพธ์ที่ดีกว่าการใช้ AI ตัวเดียว\nในอนาคต เราจะเห็นระบบเหล่านี้ถูกนำไปใช้ในหลากหลายอุตสาหกรรมมากขึ้น และพัฒนาความสามารถให้ฉลาดขึ้นเรื่อยๆ นับเป็นเทคโนโลยีที่น่าจับตามองอย่างยิ่ง\nแหล่งข้อมูลเพิ่มเติม Multi-Agent Systems ปล. บทความนี้เขียนด้วย AI (^ . ^)\n","permalink":"http://localhost:1313/posts/agentic-ai/multi-agent-systems/","summary":"\u003ch2 id=\"ทำความรจกกบระบบ-multi-agent\"\u003eทำความรู้จักกับระบบ Multi-Agent\u003c/h2\u003e\n\u003cp\u003eในโลกของปัญญาประดิษฐ์ที่กำลังก้าวหน้าอย่างรวดเร็ว ระบบ Multi-Agent Systems (MAS) กำลังเป็นเทคโนโลยีที่น่าจับตามอง แต่ระบบนี้คืออะไร? และทำไมมันถึงสำคัญ? มาทำความเข้าใจกันแบบง่ายๆ\u003c/p\u003e\n\u003cp\u003eระบบ Multi-Agent คือการรวมตัวกันของ AI หลายๆ ตัว (เราเรียกแต่ละตัวว่า \u0026ldquo;Agent\u0026rdquo;) ที่มีความเชี่ยวชาญเฉพาะด้าน มาทำงานร่วมกันเพื่อแก้ปัญหาที่ซับซ้อน เปรียบเสมือนทีมงานมืออาชีพที่แต่ละคนมีความเชี่ยวชาญต่างกัน มารวมตัวกันทำงานให้สำเร็จ\u003c/p\u003e\n\u003ch2 id=\"ทำไมตองใชหลาย-agent\"\u003eทำไมต้องใช้หลาย Agent?\u003c/h2\u003e\n\u003cp\u003eคุณอาจสงสัยว่าทำไมไม่ใช้ AI ตัวเดียวที่เก่งๆ? คำตอบคือ:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eแบ่งงานได้ดีกว่า\u003c/strong\u003e: เหมือนการทำงานในบริษัท ที่แต่ละแผนกรับผิดชอบงานที่ตัวเองถนัด\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eเชี่ยวชาญเฉพาะทาง\u003c/strong\u003e: แต่ละ Agent มีความเชี่ยวชาญเฉพาะด้าน ทำให้ได้ผลลัพธ์ที่ดีกว่า\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eทำงานพร้อมกันได้\u003c/strong\u003e: หลาย Agent สามารถทำงานไปพร้อมๆ กัน ทำให้เสร็จเร็วขึ้น\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eปรับขยายได้ง่าย\u003c/strong\u003e: เพิ่มหรือลด Agent ได้ตามความต้องการ\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"ตวอยางทเหนภาพ-ระบบพฒนาโคด\"\u003eตัวอย่างที่เห็นภาพ: ระบบพัฒนาโค้ด\u003c/h2\u003e\n\u003cp\u003eลองมาดูตัวอย่างที่เข้าใจง่าย เป็นระบบที่ใช้ Multi-Agent ในการพัฒนาโค้ด Python:\u003c/p\u003e\n\u003ch3 id=\"agent-หลกในระบบ\"\u003eAgent หลักในระบบ\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eController Agent (ผู้จัดการโครงการ)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eทำหน้าที่เป็นผู้ประสานงานหลัก\u003c/li\u003e\n\u003cli\u003eคอยสั่งงานและจัดการการทำงานของ Agent อื่นๆ\u003c/li\u003e\n\u003cli\u003eสามารถรันโค้ด Python เพื่อทดสอบได้\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eCoder Agent (นักพัฒนา)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eเชี่ยวชาญในการเขียนโค้ด\u003c/li\u003e\n\u003cli\u003eรับคำสั่งจาก Controller แล้วสร้างโค้ดตามที่ต้องการ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eTester Agent (นักทดสอบ)\u003c/strong\u003e\u003c/p\u003e","title":"Multi-Agent Systems: เข้าใจอนาคตของการทำงานร่วมกันของ AI"},{"content":"ในยุคที่ AI กำลังเข้ามามีบทบาทสำคัญในชีวิตประจำวัน การทำความเข้าใจเกี่ยวกับ AI Agent จึงเป็นเรื่องที่น่าสนใจอย่างยิ่ง บทความนี้จะพาคุณเจาะลึกถึงองค์ประกอบสำคัญของ AI Agent ตั้งแต่พื้นฐานไปจนถึงการนำไปใช้งานจริง\nทำความรู้จักกับ AI Agent AI Agent ไม่ใช่แค่โมเดลภาษาที่ตอบคำถามผู้ใช้เท่านั้น แต่เป็นระบบอัจฉริยะที่ถูกออกแบบมาให้ทำงานได้โดยอัตโนมัติหรือกึ่งอัตโนมัติ เพื่อช่วยทำงานต่างๆ ให้สำเร็จลุล่วง การที่ AI Agent จะทำงานได้อย่างมีประสิทธิภาพนั้น จำเป็นต้องมีองค์ประกอบหลายส่วนทำงานร่วมกัน\nหัวใจสำคัญ: ตัวตนและบุคลิกภาพ ตัวตนและบุคลิกภาพของ AI Agent ถูกกำหนดผ่าน \u0026ldquo;System Prompt\u0026rdquo; หรือชุดคำสั่งพื้นฐานที่ทำหน้าที่เสมือนเป็น DNA ของ Agent นั้นๆ ซึ่งจะกำหนด:\nจุดประสงค์การทำงาน: เช่น เป็นผู้ช่วยเขียนโค้ด ที่ปรึกษาด้านการเงิน หรือติวเตอร์ รูปแบบการสื่อสาร: ทั้งแบบทางการ ไม่เป็นทางการ หรือแบบเป็นมิตร ข้อจำกัดในการทำงาน: เช่น ไม่ให้สร้างเนื้อหาที่ไม่เหมาะสม หรือต้องถามคำถามเพิ่มเติมเมื่อไม่แน่ใจ หลักจริยธรรม: การปฏิบัติตามกฎหมายและจริยธรรมที่เกี่ยวข้อง ระบบเสริมที่ทำให้ Agent ฉลาดขึ้น 1. ระบบความจำและการจัดการบริบท AI Agent ต้องมีความสามารถในการจดจำข้อมูล ซึ่งแบ่งได้เป็น:\nความจำระยะสั้น: เก็บในส่วนของ Context Window ซึ่งมีข้อจำกัดตามขนาดของโมเดล ความจำระยะยาว: ใช้ฐานข้อมูลหรือ Vector Store เพื่อเก็บข้อมูลที่สำคัญไว้ใช้ในอนาคต หน่วยความจำขณะทำงาน: ใช้เก็บผลลัพธ์ระหว่างการประมวลผล 2. การเชื่อมต่อกับเครื่องมือภายนอก เพื่อเพิ่มความสามารถให้กับ AI Agent สามารถเชื่อมต่อกับเครื่องมือภายนอกได้ผ่าน:\nFunction Catalog: รายการ API ที่ Agent สามารถเรียกใช้ได้ การเรียกใช้งานตามบริบท: Agent จะตัดสินใจเลือกใช้เครื่องมือที่เหมาะสมตามสถานการณ์ การผสานผลลัพธ์: นำผลลัพธ์จากเครื่องมือภายนอกมาใช้ในการตอบคำถาม 3. ระบบการคิดและวางแผน สำหรับงานที่ซับซ้อน Agent ต้องมีความสามารถในการคิดและวางแผน:\nChain-of-Thought: สร้างลำดับการคิดก่อนให้คำตอบสุดท้าย การวางแผนเชิงเมตา: แบ่งงานใหญ่เป็นงานย่อยๆ และจัดลำดับการทำงาน State Machine: ติดตามสถานะของงานที่กำลังดำเนินการ 4. ระบบการเรียนรู้และปรับปรุง Agent สามารถพัฒนาตัวเองได้ผ่าน:\nFeedback จากผู้ใช้: นำคำติชมมาปรับปรุงพฤติกรรมในอนาคต การเรียนรู้แบบเสริมแรง: ใช้ RLHF เพื่อปรับปรุงการตัดสินใจ ระบบตรวจสอบคุณภาพ: ตรวจสอบผลลัพธ์ก่อนส่งให้ผู้ใช้ 5. สภาพแวดล้อมและอินเตอร์เฟซ การทำงานของ Agent ยังขึ้นอยู่กับ:\nUser Interface: รูปแบบการโต้ตอบกับผู้ใช้ เช่น แชท หรือเสียง การเชื่อมต่อกับระบบที่มีอยู่: เช่น CRM, เว็บไซต์, หรืออุปกรณ์ IoT ตัวอย่างการนำไปใช้งานจริง: LibraryGuide ลองมาดูตัวอย่างของ AI Agent ที่ชื่อ \u0026ldquo;LibraryGuide\u0026rdquo; ที่ถูกออกแบบมาเป็นผู้ช่วยห้องสมุด:\nบุคลิกภาพ:\nเป็นผู้ช่วยที่มีความรู้และเป็นมิตร พูดจาสุภาพ ให้ข้อมูลที่ถูกต้องและน่าเชื่อถือ ถามคำถามเพิ่มเติมเมื่อไม่แน่ใจ ความสามารถ:\nจดจำประวัติการยืมหนังสือและความชอบของผู้ใช้ ค้นหาหนังสือผ่าน Book Database API วิเคราะห์รูปแบบการอ่านเพื่อแนะนำหนังสือที่เหมาะสม เรียนรู้จาก Feedback เพื่อปรับปรุงการแนะนำ ทำงานผ่านเว็บแชทที่ฝังอยู่ในเว็บไซต์ห้องสมุด สรุป AI Agent เป็นระบบที่ซับซ้อนที่ประกอบด้วยหลายส่วนทำงานร่วมกัน:\nบุคลิกภาพที่กำหนดผ่าน System Prompt ระบบความจำที่ช่วยจดจำบริบทและข้อมูลสำคัญ การเชื่อมต่อกับเครื่องมือภายนอกเพื่อเพิ่มความสามารถ ระบบการคิดและวางแผนสำหรับงานที่ซับซ้อน ระบบการเรียนรู้เพื่อพัฒนาตัวเองอย่างต่อเนื่อง สภาพแวดล้อมที่เหมาะสมกับการใช้งาน การออกแบบ AI Agent ที่ดีต้องคำนึงถึงองค์ประกอบทั้งหมดนี้ เพื่อสร้างระบบที่ไม่เพียงแต่ฉลาดและมีความสามารถ แต่ยังต้องสอดคล้องกับจุดประสงค์การใช้งาน ความคาดหวังของผู้ใช้ และหลักจริยธรรมที่เกี่ยวข้องด้วย\nแหล่งข้อมูลเพิ่มเติม Main Components of an AI agent. ปล. บทความนี้เขียนด้วย AI (^ . ^)\n","permalink":"http://localhost:1313/posts/agentic-ai/components-of-agents/","summary":"\u003cp\u003eในยุคที่ AI กำลังเข้ามามีบทบาทสำคัญในชีวิตประจำวัน การทำความเข้าใจเกี่ยวกับ AI Agent จึงเป็นเรื่องที่น่าสนใจอย่างยิ่ง บทความนี้จะพาคุณเจาะลึกถึงองค์ประกอบสำคัญของ AI Agent ตั้งแต่พื้นฐานไปจนถึงการนำไปใช้งานจริง\u003c/p\u003e\n\u003ch2 id=\"ทำความรจกกบ-ai-agent\"\u003eทำความรู้จักกับ AI Agent\u003c/h2\u003e\n\u003cp\u003eAI Agent ไม่ใช่แค่โมเดลภาษาที่ตอบคำถามผู้ใช้เท่านั้น แต่เป็นระบบอัจฉริยะที่ถูกออกแบบมาให้ทำงานได้โดยอัตโนมัติหรือกึ่งอัตโนมัติ เพื่อช่วยทำงานต่างๆ ให้สำเร็จลุล่วง การที่ AI Agent จะทำงานได้อย่างมีประสิทธิภาพนั้น จำเป็นต้องมีองค์ประกอบหลายส่วนทำงานร่วมกัน\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"components\" loading=\"lazy\" src=\"https://raw.githubusercontent.com/panaversity/learn-agentic-ai/main/05_ai_agents_intro/06_components_of_agents/components.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"หวใจสำคญ-ตวตนและบคลกภาพ\"\u003eหัวใจสำคัญ: ตัวตนและบุคลิกภาพ\u003c/h2\u003e\n\u003cp\u003eตัวตนและบุคลิกภาพของ AI Agent ถูกกำหนดผ่าน \u0026ldquo;System Prompt\u0026rdquo; หรือชุดคำสั่งพื้นฐานที่ทำหน้าที่เสมือนเป็น DNA ของ Agent นั้นๆ ซึ่งจะกำหนด:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eจุดประสงค์การทำงาน\u003c/strong\u003e: เช่น เป็นผู้ช่วยเขียนโค้ด ที่ปรึกษาด้านการเงิน หรือติวเตอร์\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eรูปแบบการสื่อสาร\u003c/strong\u003e: ทั้งแบบทางการ ไม่เป็นทางการ หรือแบบเป็นมิตร\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eข้อจำกัดในการทำงาน\u003c/strong\u003e: เช่น ไม่ให้สร้างเนื้อหาที่ไม่เหมาะสม หรือต้องถามคำถามเพิ่มเติมเมื่อไม่แน่ใจ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eหลักจริยธรรม\u003c/strong\u003e: การปฏิบัติตามกฎหมายและจริยธรรมที่เกี่ยวข้อง\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"ระบบเสรมททำให-agent-ฉลาดขน\"\u003eระบบเสริมที่ทำให้ Agent ฉลาดขึ้น\u003c/h2\u003e\n\u003ch3 id=\"1-ระบบความจำและการจดการบรบท\"\u003e1. ระบบความจำและการจัดการบริบท\u003c/h3\u003e\n\u003cp\u003eAI Agent ต้องมีความสามารถในการจดจำข้อมูล ซึ่งแบ่งได้เป็น:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eความจำระยะสั้น\u003c/strong\u003e: เก็บในส่วนของ Context Window ซึ่งมีข้อจำกัดตามขนาดของโมเดล\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eความจำระยะยาว\u003c/strong\u003e: ใช้ฐานข้อมูลหรือ Vector Store เพื่อเก็บข้อมูลที่สำคัญไว้ใช้ในอนาคต\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eหน่วยความจำขณะทำงาน\u003c/strong\u003e: ใช้เก็บผลลัพธ์ระหว่างการประมวลผล\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"2-การเชอมตอกบเครองมอภายนอก\"\u003e2. การเชื่อมต่อกับเครื่องมือภายนอก\u003c/h3\u003e\n\u003cp\u003eเพื่อเพิ่มความสามารถให้กับ AI Agent สามารถเชื่อมต่อกับเครื่องมือภายนอกได้ผ่าน:\u003c/p\u003e","title":"เข้าใจองค์ประกอบหลักของ AI Agent: จากพื้นฐานสู่การประยุกต์ใช้งาน"},{"content":"บทนำ ลองนึกภาพว่าคุณสามารถคุยกับคอมพิวเตอร์ได้เหมือนคุยกับเพื่อน แทนที่จะต้องเรียนรู้การใช้งานโปรแกรมที่ซับซ้อน หรือเขียนคำสั่งด้วยภาษาโปรแกรมมิ่ง นี่ไม่ใช่เรื่องในนิยายวิทยาศาสตร์อีกต่อไป แต่กำลังกลายเป็นความจริงผ่านการพัฒนาของ AI Agent รุ่นใหม่\nในบทความนี้ เราจะพาคุณไปทำความรู้จักกับการเปลี่ยนแปลงครั้งสำคัญในวงการเทคโนโลยี ที่กำลังจะเปลี่ยนวิธีการที่เราใช้งานและพัฒนาซอฟต์แวร์ไปอย่างสิ้นเชิง\nจากอดีตถึงปัจจุบัน: การเปลี่ยนแปลงที่กำลังเกิดขึ้น รูปแบบดั้งเดิม ในอดีตจนถึงปัจจุบัน การใช้งานซอฟต์แวร์มักจะเป็นไปในรูปแบบนี้:\nผู้ใช้ต้องเรียนรู้การใช้งานหน้าจอโปรแกรม เมนู และปุ่มกดต่างๆ นักพัฒนาต้องเขียนโค้ดด้วยภาษาโปรแกรมมิ่งที่ซับซ้อน การเข้าถึงข้อมูลต้องใช้ภาษาคิวรี่เฉพาะทาง เช่น SQL รูปแบบใหม่ด้วย AI Agent แต่ในอนาคตอันใกล้ ทุกอย่างจะเปลี่ยนไป:\nพูดคุยกับโปรแกรมด้วยภาษาธรรมชาติ เหมือนคุยกับเพื่อน AI Agent จะเป็นตัวกลางในการแปลความต้องการของเราไปเป็นคำสั่งต่างๆ ไม่จำเป็นต้องรู้วิธีการใช้งานที่ซับซ้อนอีกต่อไป AI Agent ทำงานอย่างไร? การทำงานแบบอัตโนมัติ ลองดูตัวอย่างง่ายๆ เช่น เมื่อคุณต้องการรายงานยอดขายปีที่แล้ว:\nคุณเพียงบอกว่า \u0026ldquo;ช่วยสร้างรายงานยอดขายของปีที่แล้วให้หน่อย\u0026rdquo; AI Agent จะ: วิเคราะห์ว่าต้องการข้อมูลอะไรบ้าง ค้นหาข้อมูลจากฐานข้อมูล จัดการข้อมูลให้อยู่ในรูปแบบที่เข้าใจง่าย สร้างกราฟหรือแผนภูมิที่เหมาะสม นำเสนอผลลัพธ์ในรูปแบบที่สวยงาม การทำงานร่วมกันของ AI Agents ที่น่าสนใจคือ AI Agent ไม่ได้ทำงานเพียงตัวเดียว แต่สามารถทำงานร่วมกันได้:\nAgent ตัวหนึ่งอาจทำหน้าที่ดึงข้อมูล อีกตัวอาจวิเคราะห์แนวโน้มและทำนายอนาคต อีกตัวอาจเชี่ยวชาญด้านการสร้างภาพและการนำเสนอ ทั้งหมดนี้ทำงานประสานกันโดยใช้ภาษาธรรมชาติในการสื่อสาร\nผลกระทบต่อการพัฒนาซอฟต์แวร์ การเปลี่ยนแปลงในการออกแบบ การพัฒนาซอฟต์แวร์จะเปลี่ยนไปอย่างมาก:\nการจัดการข้อมูล\nข้อมูลต้องมีการอธิบายความหมายที่ชัดเจน AI ต้องเข้าใจความสัมพันธ์ของข้อมูลต่างๆ ต้องรองรับการค้นหาและเข้าถึงแบบยืดหยุ่น การพัฒนาเครื่องมือ\nเครื่องมือต่างๆ ต้องมีคำอธิบายที่ชัดเจน ต้องรองรับการทำงานผ่านคำสั่งภาษาธรรมชาติ ต้องสามารถปรับตัวตามสถานการณ์ได้ ประโยชน์ที่จะได้รับ การเปลี่ยนแปลงนี้จะนำมาซึ่งประโยชน์มากมาย:\nผู้ใช้ทั่วไปสามารถใช้งานระบบซับซ้อนได้ง่ายขึ้น ลดเวลาในการพัฒนาและปรับปรุงซอฟต์แวร์ ระบบมีความยืดหยุ่นและปรับตัวได้ดีขึ้น การทำงานร่วมกันระหว่างระบบต่างๆ ทำได้ง่ายขึ้น ความท้าทายและข้อควรระวัง ความท้าทายด้านเทคนิค แม้จะมีประโยชน์มาก แต่ก็มีความท้าทายที่ต้องจัดการ:\nความถูกต้องและความน่าเชื่อถือ\nต้องมั่นใจว่า AI เข้าใจคำสั่งอย่างถูกต้อง ต้องมีระบบตรวจสอบความผิดพลาด ต้องรักษาความปลอดภัยของข้อมูล การพัฒนาและดูแลระบบ\nต้องมีวิธีการใหม่ในการทดสอบระบบ ต้องสามารถแก้ไขปัญหาเมื่อ AI เข้าใจผิด ต้องมีการอัพเดทความสามารถอย่างต่อเนื่อง มองไปข้างหน้า: อนาคตของการพัฒนาซอฟต์แวร์ การมาถึงของ AI Agent ไม่ได้หมายความว่าโปรแกรมเมอร์จะหายไป แต่บทบาทจะเปลี่ยนไป:\nจากการเขียนโค้ดโดยตรง เป็นการออกแบบระบบในระดับที่สูงขึ้น จากการแก้บั๊กในโค้ด เป็นการสอนให้ AI เข้าใจและแก้ปัญหาได้ดีขึ้น จากการเขียนคู่มือการใช้งาน เป็นการพัฒนาความสามารถในการสื่อสารของ AI สรุป การปฏิวัติด้วย AI Agent กำลังจะเปลี่ยนโลกของการพัฒนาและใช้งานซอฟต์แวร์ไปอย่างสิ้นเชิง จากที่เคยต้องเรียนรู้การใช้งานที่ซับซ้อน จะกลายเป็นการพูดคุยกับคอมพิวเตอร์อย่างเป็นธรรมชาติ\nแม้ว่าจะยังมีความท้าทายอีกมาก แต่อนาคตที่ซอฟต์แวร์จะเข้าใจและตอบสนองความต้องการของเราได้ดีขึ้น กำลังจะมาถึง เราทุกคนควรเตรียมพร้อมสำหรับการเปลี่ยนแปลงครั้งใหญ่นี้\nแหล่งข้อมูลเพิ่มเติม Understanding the Next-Generation AI Agent Architecture: A Tutorial on Natural Language-Driven Software Interaction ปล. บทความนี้เขียนด้วย AI (^ . ^)\n","permalink":"http://localhost:1313/posts/agentic-ai/next-generation-architecture/","summary":"\u003ch2 id=\"บทนำ\"\u003eบทนำ\u003c/h2\u003e\n\u003cp\u003eลองนึกภาพว่าคุณสามารถคุยกับคอมพิวเตอร์ได้เหมือนคุยกับเพื่อน แทนที่จะต้องเรียนรู้การใช้งานโปรแกรมที่ซับซ้อน หรือเขียนคำสั่งด้วยภาษาโปรแกรมมิ่ง นี่ไม่ใช่เรื่องในนิยายวิทยาศาสตร์อีกต่อไป แต่กำลังกลายเป็นความจริงผ่านการพัฒนาของ AI Agent รุ่นใหม่\u003c/p\u003e\n\u003cp\u003eในบทความนี้ เราจะพาคุณไปทำความรู้จักกับการเปลี่ยนแปลงครั้งสำคัญในวงการเทคโนโลยี ที่กำลังจะเปลี่ยนวิธีการที่เราใช้งานและพัฒนาซอฟต์แวร์ไปอย่างสิ้นเชิง\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"diagram\" loading=\"lazy\" src=\"https://raw.githubusercontent.com/panaversity/learn-agentic-ai/main/05_ai_agents_intro/07_next_generation_architecture/diagram.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"จากอดตถงปจจบน-การเปลยนแปลงทกำลงเกดขน\"\u003eจากอดีตถึงปัจจุบัน: การเปลี่ยนแปลงที่กำลังเกิดขึ้น\u003c/h2\u003e\n\u003ch3 id=\"รปแบบดงเดม\"\u003eรูปแบบดั้งเดิม\u003c/h3\u003e\n\u003cp\u003eในอดีตจนถึงปัจจุบัน การใช้งานซอฟต์แวร์มักจะเป็นไปในรูปแบบนี้:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eผู้ใช้ต้องเรียนรู้การใช้งานหน้าจอโปรแกรม เมนู และปุ่มกดต่างๆ\u003c/li\u003e\n\u003cli\u003eนักพัฒนาต้องเขียนโค้ดด้วยภาษาโปรแกรมมิ่งที่ซับซ้อน\u003c/li\u003e\n\u003cli\u003eการเข้าถึงข้อมูลต้องใช้ภาษาคิวรี่เฉพาะทาง เช่น SQL\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"รปแบบใหมดวย-ai-agent\"\u003eรูปแบบใหม่ด้วย AI Agent\u003c/h3\u003e\n\u003cp\u003eแต่ในอนาคตอันใกล้ ทุกอย่างจะเปลี่ยนไป:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eพูดคุยกับโปรแกรมด้วยภาษาธรรมชาติ เหมือนคุยกับเพื่อน\u003c/li\u003e\n\u003cli\u003eAI Agent จะเป็นตัวกลางในการแปลความต้องการของเราไปเป็นคำสั่งต่างๆ\u003c/li\u003e\n\u003cli\u003eไม่จำเป็นต้องรู้วิธีการใช้งานที่ซับซ้อนอีกต่อไป\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"ai-agent-ทำงานอยางไร\"\u003eAI Agent ทำงานอย่างไร?\u003c/h2\u003e\n\u003ch3 id=\"การทำงานแบบอตโนมต\"\u003eการทำงานแบบอัตโนมัติ\u003c/h3\u003e\n\u003cp\u003eลองดูตัวอย่างง่ายๆ เช่น เมื่อคุณต้องการรายงานยอดขายปีที่แล้ว:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eคุณเพียงบอกว่า \u0026ldquo;ช่วยสร้างรายงานยอดขายของปีที่แล้วให้หน่อย\u0026rdquo;\u003c/li\u003e\n\u003cli\u003eAI Agent จะ:\n\u003cul\u003e\n\u003cli\u003eวิเคราะห์ว่าต้องการข้อมูลอะไรบ้าง\u003c/li\u003e\n\u003cli\u003eค้นหาข้อมูลจากฐานข้อมูล\u003c/li\u003e\n\u003cli\u003eจัดการข้อมูลให้อยู่ในรูปแบบที่เข้าใจง่าย\u003c/li\u003e\n\u003cli\u003eสร้างกราฟหรือแผนภูมิที่เหมาะสม\u003c/li\u003e\n\u003cli\u003eนำเสนอผลลัพธ์ในรูปแบบที่สวยงาม\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"การทำงานรวมกนของ-ai-agents\"\u003eการทำงานร่วมกันของ AI Agents\u003c/h3\u003e\n\u003cp\u003eที่น่าสนใจคือ AI Agent ไม่ได้ทำงานเพียงตัวเดียว แต่สามารถทำงานร่วมกันได้:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAgent ตัวหนึ่งอาจทำหน้าที่ดึงข้อมูล\u003c/li\u003e\n\u003cli\u003eอีกตัวอาจวิเคราะห์แนวโน้มและทำนายอนาคต\u003c/li\u003e\n\u003cli\u003eอีกตัวอาจเชี่ยวชาญด้านการสร้างภาพและการนำเสนอ\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eทั้งหมดนี้ทำงานประสานกันโดยใช้ภาษาธรรมชาติในการสื่อสาร\u003c/p\u003e\n\u003ch2 id=\"ผลกระทบตอการพฒนาซอฟตแวร\"\u003eผลกระทบต่อการพัฒนาซอฟต์แวร์\u003c/h2\u003e\n\u003ch3 id=\"การเปลยนแปลงในการออกแบบ\"\u003eการเปลี่ยนแปลงในการออกแบบ\u003c/h3\u003e\n\u003cp\u003eการพัฒนาซอฟต์แวร์จะเปลี่ยนไปอย่างมาก:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eการจัดการข้อมูล\u003c/strong\u003e\u003c/p\u003e","title":"การเปลี่ยนแปลงครั้งใหญ่: สถาปัตยกรรม AI Agent รุ่นใหม่และการปฏิวัติการทำงานของซอฟต์แวร์"},{"content":"ในยุคที่ AI กำลังเข้ามามีบทบาทสำคัญในชีวิตประจำวันของเรามากขึ้น การออกแบบระบบ AI ให้สามารถทำงานได้อย่างชาญฉลาดและมีประสิทธิภาพจึงเป็นเรื่องที่สำคัญมาก หนึ่งในแนวคิดที่น่าสนใจคือ \u0026ldquo;Agentic Design Patterns\u0026rdquo; หรือรูปแบบการออกแบบที่ช่วยให้ระบบ AI สามารถคิด ตัดสินใจ และทำงานได้อย่างอิสระ มาทำความรู้จักกับแนวคิดนี้กันให้ลึกซึ้งยิ่งขึ้น\nAgentic Design Patterns คืออะไร? Agentic Design Patterns เป็นแนวทางการออกแบบที่ใช้ในการสร้างระบบ AI ที่สามารถทำงานได้อย่างอิสระ (Autonomous) โดยไม่ต้องพึ่งพาการควบคุมจากมนุษย์ตลอดเวลา รูปแบบการออกแบบเหล่านี้ช่วยกำหนดวิธีการที่ระบบ AI จะคิด ตัดสินใจ และมีปฏิสัมพันธ์กับสภาพแวดล้อม รวมถึงระบบอื่นๆ เพื่อให้บรรลุเป้าหมายที่ต้องการ\nรูปแบบการออกแบบที่น่าสนใจ 1. ReACT - การผสมผสานระหว่างการคิดและการกระทำ ReACT (Reasoning and Acting) เป็นรูปแบบที่น่าสนใจมาก เพราะจำลองการทำงานคล้ายกับวิธีที่มนุษย์เราคิดและตัดสินใจ โดยระบบจะ:\nวิเคราะห์สถานการณ์และคิดหาทางแก้ไข ลงมือทำตามแผนที่วางไว้ ประเมินผลลัพธ์และปรับปรุงการตัดสินใจในรอบถัดไป ตัวอย่างที่เห็นได้ชัดคือ ระบบวางแผนการเดินทาง ที่จะสลับไปมาระหว่างการค้นหาเที่ยวบิน (การคิด) และการจองตั๋ว (การกระทำ) โดยปรับเปลี่ยนแผนตามราคาและความพร้อมของเที่ยวบินที่พบ\nตัวอย่าง ReACT from typing import Dict, List, Tuple, TypedDict, Annotated from datetime import datetime, timedelta import json from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter import os # Define our state structure class AgentState(TypedDict): messages: List[str] current_plan: Dict flight_data: Dict booking_status: str next_action: str # Mock flight database MOCK_FLIGHTS = { \u0026#34;BKK-NRT\u0026#34;: [ {\u0026#34;flight\u0026#34;: \u0026#34;TG676\u0026#34;, \u0026#34;departure\u0026#34;: \u0026#34;10:30\u0026#34;, \u0026#34;arrival\u0026#34;: \u0026#34;18:45\u0026#34;, \u0026#34;price\u0026#34;: 15000}, {\u0026#34;flight\u0026#34;: \u0026#34;JL708\u0026#34;, \u0026#34;departure\u0026#34;: \u0026#34;08:00\u0026#34;, \u0026#34;arrival\u0026#34;: \u0026#34;15:30\u0026#34;, \u0026#34;price\u0026#34;: 18000}, ], \u0026#34;NRT-BKK\u0026#34;: [ {\u0026#34;flight\u0026#34;: \u0026#34;TG677\u0026#34;, \u0026#34;departure\u0026#34;: \u0026#34;19:30\u0026#34;, \u0026#34;arrival\u0026#34;: \u0026#34;00:45\u0026#34;, \u0026#34;price\u0026#34;: 16000}, {\u0026#34;flight\u0026#34;: \u0026#34;JL709\u0026#34;, \u0026#34;departure\u0026#34;: \u0026#34;16:30\u0026#34;, \u0026#34;arrival\u0026#34;: \u0026#34;22:00\u0026#34;, \u0026#34;price\u0026#34;: 17000}, ] } # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, # หรือใช้โมเดลอื่นที่ OpenRouter รองรับ temperature=0, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, # your website URL \u0026#34;X-Title\u0026#34;: \u0026#34;Flight Booking Assistant\u0026#34; # your app name } ) def reasoning_step(state: AgentState) -\u0026gt; AgentState: \u0026#34;\u0026#34;\u0026#34; Analyze the current situation and plan next steps \u0026#34;\u0026#34;\u0026#34; # Create a prompt for the LLM to analyze the situation messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Current situation: - Planning status: {state[\u0026#39;current_plan\u0026#39;]} - Available flight data: {state[\u0026#39;flight_data\u0026#39;]} - Booking status: {state[\u0026#39;booking_status\u0026#39;]} What should be the next action? Choose from: 1. SEARCH_FLIGHTS - If we need to look for flights 2. BOOK_FLIGHT - If we found a suitable flight and should book it 3. END - If we\u0026#39;ve completed the booking Provide your reasoning and the next action. \u0026#34;\u0026#34;\u0026#34;) ] # Get LLM response response = llm.invoke(messages) # Extract next action from response if \u0026#34;SEARCH_FLIGHTS\u0026#34; in response.content: state[\u0026#34;next_action\u0026#34;] = \u0026#34;SEARCH_FLIGHTS\u0026#34; elif \u0026#34;BOOK_FLIGHT\u0026#34; in response.content: state[\u0026#34;next_action\u0026#34;] = \u0026#34;BOOK_FLIGHT\u0026#34; elif \u0026#34;END\u0026#34; in response.content: state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; state[\u0026#34;messages\u0026#34;].append(f\u0026#34;Reasoning: {response.content}\u0026#34;) return state def search_flights(state: AgentState) -\u0026gt; AgentState: \u0026#34;\u0026#34;\u0026#34; Search for available flights based on the current plan \u0026#34;\u0026#34;\u0026#34; route = f\u0026#34;{state[\u0026#39;current_plan\u0026#39;][\u0026#39;origin\u0026#39;]}-{state[\u0026#39;current_plan\u0026#39;][\u0026#39;destination\u0026#39;]}\u0026#34; if route in MOCK_FLIGHTS: state[\u0026#34;flight_data\u0026#34;] = MOCK_FLIGHTS[route] state[\u0026#34;messages\u0026#34;].append(f\u0026#34;Found {len(MOCK_FLIGHTS[route])} flights for {route}\u0026#34;) else: state[\u0026#34;flight_data\u0026#34;] = {} state[\u0026#34;messages\u0026#34;].append(f\u0026#34;No flights found for {route}\u0026#34;) return state def book_flight(state: AgentState) -\u0026gt; AgentState: \u0026#34;\u0026#34;\u0026#34; Attempt to book the selected flight \u0026#34;\u0026#34;\u0026#34; if state[\u0026#34;flight_data\u0026#34;]: # Find the cheapest flight selected_flight = min(state[\u0026#34;flight_data\u0026#34;], key=lambda x: x[\u0026#34;price\u0026#34;]) state[\u0026#34;booking_status\u0026#34;] = \u0026#34;CONFIRMED\u0026#34; state[\u0026#34;messages\u0026#34;].append( f\u0026#34;Booked flight {selected_flight[\u0026#39;flight\u0026#39;]} for {selected_flight[\u0026#39;price\u0026#39;]} THB\u0026#34; ) else: state[\u0026#34;booking_status\u0026#34;] = \u0026#34;FAILED\u0026#34; state[\u0026#34;messages\u0026#34;].append(\u0026#34;Booking failed - no flights available\u0026#34;) return state def router(state: AgentState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; Route to the next step based on the reasoning outcome \u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(AgentState) # Add nodes workflow.add_node(\u0026#34;reasoning\u0026#34;, reasoning_step) workflow.add_node(\u0026#34;search_flights\u0026#34;, search_flights) workflow.add_node(\u0026#34;book_flight\u0026#34;, book_flight) # Add edges workflow.add_edge(\u0026#34;reasoning\u0026#34;, router) workflow.add_edge(\u0026#34;search_flights\u0026#34;, \u0026#34;reasoning\u0026#34;) workflow.add_edge(\u0026#34;book_flight\u0026#34;, \u0026#34;reasoning\u0026#34;) # Set entry point workflow.set_entry_point(\u0026#34;reasoning\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;reasoning\u0026#34;, router, { \u0026#34;SEARCH_FLIGHTS\u0026#34;: \u0026#34;search_flights\u0026#34;, \u0026#34;BOOK_FLIGHT\u0026#34;: \u0026#34;book_flight\u0026#34;, \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;current_plan\u0026#34;: { \u0026#34;origin\u0026#34;: \u0026#34;BKK\u0026#34;, \u0026#34;destination\u0026#34;: \u0026#34;NRT\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2025-02-15\u0026#34; }, \u0026#34;flight_data\u0026#34;: {}, \u0026#34;booking_status\u0026#34;: \u0026#34;NOT_STARTED\u0026#34;, \u0026#34;next_action\u0026#34;: \u0026#34;SEARCH_FLIGHTS\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 2. ระบบที่พัฒนาตัวเองได้ (Self-Improvement) ความน่าสนใจของรูปแบบนี้อยู่ที่ความสามารถในการเรียนรู้และพัฒนาตัวเองอย่างต่อเนื่อง เหมือนกับที่มนุษย์เราเรียนรู้จากประสบการณ์ ระบบจะ:\nประเมินผลการทำงานของตัวเอง เรียนรู้จากข้อมูลใหม่ๆ ปรับปรุงกระบวนการทำงานภายใน ตัวอย่างที่เห็นได้บ่อยคือ ผู้ช่วยเขียนโค้ด ที่จะปรับปรุงคำแนะนำให้ดีขึ้นจากการวิเคราะห์ผลตอบรับของผู้ใช้\nตัวอย่าง Self-Improvement from typing import Dict, List, TypedDict, Optional from datetime import datetime import json from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter import numpy as np from dataclasses import dataclass, asdict import os # Define our state and data structures @dataclass class CodeSuggestion: code: str explanation: str confidence: float timestamp: str feedback_score: Optional[float] = None class AssistantState(TypedDict): messages: List[str] current_query: str suggestions_history: List[Dict] feedback_history: List[Dict] improvement_metrics: Dict next_action: str current_suggestion: Optional[Dict] # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, # หรือโมเดลอื่นที่ OpenRouter รองรับ temperature=0.7, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, # your website URL \u0026#34;X-Title\u0026#34;: \u0026#34;Code Assistant\u0026#34; # your app name } ) # Knowledge base for code patterns (would be expanded in real implementation) CODE_PATTERNS_DB = { \u0026#34;error_handling\u0026#34;: { \u0026#34;weight\u0026#34;: 0.5, \u0026#34;examples\u0026#34;: [\u0026#34;try-except blocks\u0026#34;, \u0026#34;error logging\u0026#34;, \u0026#34;graceful degradation\u0026#34;] }, \u0026#34;code_style\u0026#34;: { \u0026#34;weight\u0026#34;: 0.3, \u0026#34;examples\u0026#34;: [\u0026#34;PEP8 compliance\u0026#34;, \u0026#34;meaningful variable names\u0026#34;, \u0026#34;proper indentation\u0026#34;] }, \u0026#34;performance\u0026#34;: { \u0026#34;weight\u0026#34;: 0.2, \u0026#34;examples\u0026#34;: [\u0026#34;algorithmic efficiency\u0026#34;, \u0026#34;memory usage\u0026#34;, \u0026#34;optimization techniques\u0026#34;] } } def generate_code_suggestion(state: AssistantState) -\u0026gt; AssistantState: \u0026#34;\u0026#34;\u0026#34; Generate code suggestions based on current knowledge and past feedback \u0026#34;\u0026#34;\u0026#34; messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Task: Generate Python code based on the following: Query: {state[\u0026#39;current_query\u0026#39;]} Consider past feedback patterns: {json.dumps(state[\u0026#39;improvement_metrics\u0026#39;], indent=2)} Provide: 1. Code suggestion (in ```python code blocks) 2. Explanation: 3. Confidence: (a number between 0-1) \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Parse LLM response (in real implementation, would use more robust parsing) suggestion = CodeSuggestion( code=response.content.split(\u0026#34;```python\u0026#34;)[1].split(\u0026#34;```\u0026#34;)[0].strip(), explanation=response.content.split(\u0026#34;Explanation:\u0026#34;)[1].split(\u0026#34;Confidence:\u0026#34;)[0].strip(), confidence=float(response.content.split(\u0026#34;Confidence:\u0026#34;)[1].strip()), timestamp=datetime.now().isoformat() ) state[\u0026#34;current_suggestion\u0026#34;] = asdict(suggestion) state[\u0026#34;suggestions_history\u0026#34;].append(asdict(suggestion)) state[\u0026#34;next_action\u0026#34;] = \u0026#34;EVALUATE\u0026#34; return state def evaluate_feedback(state: AssistantState) -\u0026gt; AssistantState: \u0026#34;\u0026#34;\u0026#34; Analyze user feedback and update improvement metrics \u0026#34;\u0026#34;\u0026#34; if not state[\u0026#34;feedback_history\u0026#34;]: state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state recent_feedback = state[\u0026#34;feedback_history\u0026#34;][-1] # Analyze feedback and update metrics feedback_score = recent_feedback.get(\u0026#34;score\u0026#34;, 0) feedback_comments = recent_feedback.get(\u0026#34;comments\u0026#34;, \u0026#34;\u0026#34;) # Update improvement metrics based on feedback messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze this feedback and identify which patterns need adjustment: Score: {feedback_score} Comments: {feedback_comments} Current metrics: {json.dumps(state[\u0026#39;improvement_metrics\u0026#39;], indent=2)} Analyze which patterns (error_handling, code_style, performance) are mentioned in the feedback and should be adjusted. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Update metrics (simplified version) for pattern in CODE_PATTERNS_DB: if pattern in response.content.lower(): state[\u0026#34;improvement_metrics\u0026#34;][pattern][\u0026#34;weight\u0026#34;] *= (1 + feedback_score * 0.1) # Normalize weights total_weight = sum(m[\u0026#34;weight\u0026#34;] for m in state[\u0026#34;improvement_metrics\u0026#34;].values()) for pattern in state[\u0026#34;improvement_metrics\u0026#34;]: state[\u0026#34;improvement_metrics\u0026#34;][pattern][\u0026#34;weight\u0026#34;] /= total_weight state[\u0026#34;next_action\u0026#34;] = \u0026#34;REFLECT\u0026#34; return state def self_reflection(state: AssistantState) -\u0026gt; AssistantState: \u0026#34;\u0026#34;\u0026#34; Periodic self-reflection to identify areas for improvement \u0026#34;\u0026#34;\u0026#34; if len(state[\u0026#34;suggestions_history\u0026#34;]) \u0026lt; 5: # Need more data for meaningful reflection state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state # Analyze recent performance recent_suggestions = state[\u0026#34;suggestions_history\u0026#34;][-5:] avg_confidence = np.mean([s[\u0026#34;confidence\u0026#34;] for s in recent_suggestions]) messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze recent performance and suggest improvements: Average confidence: {avg_confidence} Recent suggestions: {json.dumps(recent_suggestions, indent=2)} Current metrics: {json.dumps(state[\u0026#39;improvement_metrics\u0026#39;], indent=2)} Please provide specific suggestions for improving: 1. Code quality 2. Explanation clarity 3. Confidence estimation accuracy \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Update state with reflection insights state[\u0026#34;messages\u0026#34;].append(f\u0026#34;Self-reflection insights: {response.content}\u0026#34;) state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: AssistantState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; Route to the next step based on the current state \u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(AssistantState) # Add nodes workflow.add_node(\u0026#34;generate\u0026#34;, generate_code_suggestion) workflow.add_node(\u0026#34;evaluate\u0026#34;, evaluate_feedback) workflow.add_node(\u0026#34;reflect\u0026#34;, self_reflection) # Add edges workflow.add_edge(\u0026#34;generate\u0026#34;, router) workflow.add_edge(\u0026#34;evaluate\u0026#34;, router) workflow.add_edge(\u0026#34;reflect\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;generate\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;generate\u0026#34;, router, { \u0026#34;EVALUATE\u0026#34;: \u0026#34;evaluate\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;evaluate\u0026#34;, router, { \u0026#34;REFLECT\u0026#34;: \u0026#34;reflect\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;reflect\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;current_query\u0026#34;: \u0026#34;Write a function to find the nth Fibonacci number with memoization\u0026#34;, \u0026#34;suggestions_history\u0026#34;: [], \u0026#34;feedback_history\u0026#34;: [ { \u0026#34;score\u0026#34;: 0.8, \u0026#34;comments\u0026#34;: \u0026#34;Good use of memoization, but could improve error handling\u0026#34; } ], \u0026#34;improvement_metrics\u0026#34;: { \u0026#34;error_handling\u0026#34;: {\u0026#34;weight\u0026#34;: 0.3, \u0026#34;count\u0026#34;: 0}, \u0026#34;code_style\u0026#34;: {\u0026#34;weight\u0026#34;: 0.4, \u0026#34;count\u0026#34;: 0}, \u0026#34;performance\u0026#34;: {\u0026#34;weight\u0026#34;: 0.3, \u0026#34;count\u0026#34;: 0} }, \u0026#34;next_action\u0026#34;: \u0026#34;GENERATE\u0026#34;, \u0026#34;current_suggestion\u0026#34;: None } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 3. Agentic RAG - การผสมผสานการค้นหาและการสร้างเนื้อหา รูปแบบนี้น่าสนใจเพราะช่วยให้ระบบ AI สามารถใช้ข้อมูลจากแหล่งภายนอกมาประกอบการตัดสินใจได้ โดย:\nค้นหาข้อมูลที่เกี่ยวข้องจากฐานข้อมูล นำข้อมูลมาประมวลผลและสร้างเป็นคำตอบ ตรวจสอบความถูกต้องของข้อมูลก่อนนำไปใช้ ระบบแชทบอทให้บริการลูกค้าที่สามารถค้นหาข้อมูลจากเอกสารนโยบายและสร้างคำตอบที่เหมาะสมเป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Agentic RAG from typing import Dict, List, TypedDict, Optional import json from datetime import datetime from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter from langchain_community.vectorstores import FAISS from langchain_community.embeddings import OllamaEmbeddings from langchain.text_splitter import RecursiveCharacterTextSplitter from dataclasses import dataclass, asdict import os # Define data structures @dataclass class RetrievedDocument: content: str source: str relevance_score: float @dataclass class GeneratedResponse: response: str confidence: float sources: List[str] timestamp: str class ChatbotState(TypedDict): messages: List[str] current_query: str retrieved_docs: List[Dict] generated_response: Optional[Dict] verification_result: Optional[Dict] next_action: str # Mock policy database POLICY_DOCUMENTS = { \u0026#34;returns\u0026#34;: \u0026#34;\u0026#34;\u0026#34; Return Policy: - Items can be returned within 30 days of purchase - Must have original receipt - Items must be unused and in original packaging - Shipping costs are non-refundable - Store credit or refund will be issued within 7 business days \u0026#34;\u0026#34;\u0026#34;, \u0026#34;shipping\u0026#34;: \u0026#34;\u0026#34;\u0026#34; Shipping Policy: - Free shipping on orders over 1000 THB - Standard shipping: 3-5 business days - Express shipping: 1-2 business days (additional fee) - International shipping available to select countries - Tracking number provided for all shipments \u0026#34;\u0026#34;\u0026#34;, \u0026#34;warranty\u0026#34;: \u0026#34;\u0026#34;\u0026#34; Warranty Policy: - 1-year manufacturer warranty on all products - Covers defects in materials and workmanship - Does not cover damage from misuse or accidents - Warranty claims require proof of purchase - Replacement or repair decision at company discretion \u0026#34;\u0026#34;\u0026#34; } # Initialize components llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.7, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, \u0026#34;X-Title\u0026#34;: \u0026#34;Policy Assistant\u0026#34; } ) # Initialize Ollama embeddings embeddings = OllamaEmbeddings( model=\u0026#34;nomic-embed-text\u0026#34;, # หรือจะใช้โมเดลอื่นที่ Ollama รองรับ base_url=\u0026#34;http://localhost:11434\u0026#34; # ปรับ URL ตาม Ollama server ) text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) # Create vector store from policy documents def initialize_vector_store(): texts = [] metadatas = [] for policy_type, content in POLICY_DOCUMENTS.items(): chunks = text_splitter.split_text(content) texts.extend(chunks) metadatas.extend([{\u0026#34;source\u0026#34;: policy_type} for _ in chunks]) return FAISS.from_texts(texts, embeddings, metadatas=metadatas) vector_store = initialize_vector_store() def retrieve_relevant_docs(state: ChatbotState) -\u0026gt; ChatbotState: \u0026#34;\u0026#34;\u0026#34; Retrieve relevant documents based on the user query \u0026#34;\u0026#34;\u0026#34; # Search vector store docs = vector_store.similarity_search_with_score( state[\u0026#34;current_query\u0026#34;], k=3 ) # Process and store retrieved documents retrieved_docs = [ asdict(RetrievedDocument( content=doc[0].page_content, source=doc[0].metadata[\u0026#34;source\u0026#34;], relevance_score=float(doc[1]) )) for doc in docs ] state[\u0026#34;retrieved_docs\u0026#34;] = retrieved_docs state[\u0026#34;next_action\u0026#34;] = \u0026#34;GENERATE\u0026#34; return state def generate_response(state: ChatbotState) -\u0026gt; ChatbotState: \u0026#34;\u0026#34;\u0026#34; Generate response using retrieved documents \u0026#34;\u0026#34;\u0026#34; # Prepare context from retrieved documents context = \u0026#34;\\n\u0026#34;.join([ f\u0026#34;Document from {doc[\u0026#39;source\u0026#39;]}:\\n{doc[\u0026#39;content\u0026#39;]}\u0026#34; for doc in state[\u0026#34;retrieved_docs\u0026#34;] ]) messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Based on the following context and user query, generate a helpful response. Context: {context} User Query: {state[\u0026#39;current_query\u0026#39;]} Generate a response that: 1. Directly answers the user\u0026#39;s question 2. References specific policies when relevant 3. Is clear and easy to understand 4. Uses bullet points for important information \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) generated_response = GeneratedResponse( response=response.content, confidence=0.8, # In real implementation, would calculate based on relevance scores sources=[doc[\u0026#34;source\u0026#34;] for doc in state[\u0026#34;retrieved_docs\u0026#34;]], timestamp=datetime.now().isoformat() ) state[\u0026#34;generated_response\u0026#34;] = asdict(generated_response) state[\u0026#34;next_action\u0026#34;] = \u0026#34;VERIFY\u0026#34; return state def verify_response(state: ChatbotState) -\u0026gt; ChatbotState: \u0026#34;\u0026#34;\u0026#34; Verify the generated response against policy documents \u0026#34;\u0026#34;\u0026#34; response = state[\u0026#34;generated_response\u0026#34;][\u0026#34;response\u0026#34;] sources = state[\u0026#34;retrieved_docs\u0026#34;] messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Verify this response against the source documents for accuracy: Response: {response} Source Documents: {json.dumps(sources, indent=2)} Check for: 1. Factual accuracy 2. Completeness 3. Consistency with policies 4. Any missing important information Provide: 1. Verification result (verified/not verified) 2. Confidence score (0-1) 3. Detailed notes about any issues found \u0026#34;\u0026#34;\u0026#34;) ] verification = llm.invoke(messages) state[\u0026#34;verification_result\u0026#34;] = { \u0026#34;verified\u0026#34;: \u0026#34;incorrect information\u0026#34; not in verification.content.lower(), \u0026#34;confidence\u0026#34;: 0.9 if \u0026#34;high confidence\u0026#34; in verification.content.lower() else 0.7, \u0026#34;notes\u0026#34;: verification.content } state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; if state[\u0026#34;verification_result\u0026#34;][\u0026#34;verified\u0026#34;] else \u0026#34;GENERATE\u0026#34; return state def router(state: ChatbotState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; Route to the next step based on the current state \u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(ChatbotState) # Add nodes workflow.add_node(\u0026#34;retrieve\u0026#34;, retrieve_relevant_docs) workflow.add_node(\u0026#34;generate\u0026#34;, generate_response) workflow.add_node(\u0026#34;verify\u0026#34;, verify_response) # Add edges workflow.add_edge(\u0026#34;retrieve\u0026#34;, router) workflow.add_edge(\u0026#34;generate\u0026#34;, router) workflow.add_edge(\u0026#34;verify\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;retrieve\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;retrieve\u0026#34;, router, { \u0026#34;GENERATE\u0026#34;: \u0026#34;generate\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;generate\u0026#34;, router, { \u0026#34;VERIFY\u0026#34;: \u0026#34;verify\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;verify\u0026#34;, router, { \u0026#34;GENERATE\u0026#34;: \u0026#34;generate\u0026#34;, \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;current_query\u0026#34;: \u0026#34;What is your return policy for unused items?\u0026#34;, \u0026#34;retrieved_docs\u0026#34;: [], \u0026#34;generated_response\u0026#34;: None, \u0026#34;verification_result\u0026#34;: None, \u0026#34;next_action\u0026#34;: \u0026#34;RETRIEVE\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 4. Meta-Agent - ผู้จัดการระบบอัจฉริยะ เปรียบเสมือนผู้จัดการโครงการที่คอยประสานงานระหว่างทีมย่อยต่างๆ Meta-Agent จะ:\nแบ่งงานให้ระบบย่อยที่เชี่ยวชาญเฉพาะด้าน ประสานงานให้ทุกส่วนทำงานสอดคล้องกัน ติดตามและควบคุมคุณภาพของงาน ตัวอย่างเช่น ระบบบริหารโครงการที่แบ่งงานให้ระบบย่อยดูแลเรื่องการจัดตารางเวลา งบประมาณ และการรายงานผล\nตัวอย่าง Meta-Agent from typing import Dict, List, TypedDict, Optional from datetime import datetime, timedelta import json from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter from dataclasses import dataclass, asdict import os # Define data structures @dataclass class Task: id: str name: str description: str duration: int # in days dependencies: List[str] assigned_to: str status: str estimated_cost: float @dataclass class ScheduleReport: start_date: str end_date: str critical_path: List[str] milestone_dates: Dict[str, str] @dataclass class BudgetReport: total_cost: float cost_breakdown: Dict[str, float] budget_status: str warnings: List[str] class ProjectState(TypedDict): messages: List[str] tasks: List[Dict] schedule: Optional[Dict] budget: Optional[Dict] quality_metrics: Dict next_action: str current_request: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.2, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, # your website URL \u0026#34;X-Title\u0026#34;: \u0026#34;Project Management Assistant\u0026#34; # your app name } ) class SchedulingAgent: \u0026#34;\u0026#34;\u0026#34;Agent responsible for project scheduling\u0026#34;\u0026#34;\u0026#34; @staticmethod def create_schedule(tasks: List[Task]) -\u0026gt; ScheduleReport: # Create schedule based on task dependencies and durations today = datetime.now() schedule = {} scheduled_tasks = set() def can_schedule(task): return all(dep in scheduled_tasks for dep in task.dependencies) current_date = today while len(scheduled_tasks) \u0026lt; len(tasks): for task in tasks: if task.id not in scheduled_tasks and can_schedule(task): schedule[task.id] = { \u0026#39;start\u0026#39;: current_date.strftime(\u0026#39;%Y-%m-%d\u0026#39;), \u0026#39;end\u0026#39;: (current_date + timedelta(days=task.duration)).strftime(\u0026#39;%Y-%m-%d\u0026#39;) } scheduled_tasks.add(task.id) current_date += timedelta(days=1) return ScheduleReport( start_date=today.strftime(\u0026#39;%Y-%m-%d\u0026#39;), end_date=max(date[\u0026#39;end\u0026#39;] for date in schedule.values()), critical_path=list(schedule.keys()), # Simplified critical path milestone_dates=schedule ) class BudgetingAgent: \u0026#34;\u0026#34;\u0026#34;Agent responsible for budget management\u0026#34;\u0026#34;\u0026#34; @staticmethod def analyze_budget(tasks: List[Task], schedule: ScheduleReport) -\u0026gt; BudgetReport: total_cost = sum(task.estimated_cost for task in tasks) # Calculate cost breakdown by category cost_breakdown = {} for task in tasks: category = task.assigned_to cost_breakdown[category] = cost_breakdown.get(category, 0) + task.estimated_cost # Determine budget status and warnings warnings = [] if total_cost \u0026gt; 100000: # Example budget threshold warnings.append(\u0026#34;Project exceeds recommended budget\u0026#34;) status = \u0026#34;GREEN\u0026#34; if not warnings else \u0026#34;YELLOW\u0026#34; return BudgetReport( total_cost=total_cost, cost_breakdown=cost_breakdown, budget_status=status, warnings=warnings ) class QualityAgent: \u0026#34;\u0026#34;\u0026#34;Agent responsible for quality control\u0026#34;\u0026#34;\u0026#34; @staticmethod def assess_quality(state: ProjectState) -\u0026gt; Dict: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze the project quality and provide assessment: Schedule Information: {json.dumps(state[\u0026#39;schedule\u0026#39;], indent=2)} Budget Information: {json.dumps(state[\u0026#39;budget\u0026#39;], indent=2)} Task Information: {json.dumps(state[\u0026#39;tasks\u0026#39;], indent=2)} Please provide: 1. Quality score (0-100) 2. Risk level assessment (LOW/MEDIUM/HIGH) 3. Specific improvement recommendations 4. Areas of concern, if any Format your response with clear sections and bullet points. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Parse LLM response (simplified) quality_metrics = { \u0026#34;quality_score\u0026#34;: 85, # Would be parsed from response \u0026#34;risk_level\u0026#34;: \u0026#34;MEDIUM\u0026#34;, \u0026#34;recommendations\u0026#34;: response.content.split(\u0026#34;\\n\u0026#34;) } return quality_metrics def meta_agent_coordinator(state: ProjectState) -\u0026gt; ProjectState: \u0026#34;\u0026#34;\u0026#34; Main coordination function that delegates tasks to specialized agents \u0026#34;\u0026#34;\u0026#34; messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze this project management request and determine the next action: Current Request: {state[\u0026#39;current_request\u0026#39;]} Current State: {json.dumps(state, indent=2)} Available actions: 1. SCHEDULE - Create or update project schedule 2. BUDGET - Analyze project budget and costs 3. QUALITY - Assess project quality and risks 4. END - Complete the workflow Consider: - Dependencies between tasks - Resource allocation - Timeline constraints - Budget requirements Provide your reasoning and recommended next action. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Determine next action based on LLM response if \u0026#34;SCHEDULE\u0026#34; in response.content: state[\u0026#34;next_action\u0026#34;] = \u0026#34;SCHEDULE\u0026#34; elif \u0026#34;BUDGET\u0026#34; in response.content: state[\u0026#34;next_action\u0026#34;] = \u0026#34;BUDGET\u0026#34; elif \u0026#34;QUALITY\u0026#34; in response.content: state[\u0026#34;next_action\u0026#34;] = \u0026#34;QUALITY\u0026#34; else: state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def handle_scheduling(state: ProjectState) -\u0026gt; ProjectState: \u0026#34;\u0026#34;\u0026#34;Handle scheduling tasks\u0026#34;\u0026#34;\u0026#34; tasks = [Task(**task) for task in state[\u0026#34;tasks\u0026#34;]] schedule = SchedulingAgent.create_schedule(tasks) state[\u0026#34;schedule\u0026#34;] = asdict(schedule) state[\u0026#34;next_action\u0026#34;] = \u0026#34;BUDGET\u0026#34; return state def handle_budgeting(state: ProjectState) -\u0026gt; ProjectState: \u0026#34;\u0026#34;\u0026#34;Handle budget analysis\u0026#34;\u0026#34;\u0026#34; tasks = [Task(**task) for task in state[\u0026#34;tasks\u0026#34;]] budget = BudgetingAgent.analyze_budget(tasks, ScheduleReport(**state[\u0026#34;schedule\u0026#34;])) state[\u0026#34;budget\u0026#34;] = asdict(budget) state[\u0026#34;next_action\u0026#34;] = \u0026#34;QUALITY\u0026#34; return state def handle_quality(state: ProjectState) -\u0026gt; ProjectState: \u0026#34;\u0026#34;\u0026#34;Handle quality assessment\u0026#34;\u0026#34;\u0026#34; quality_metrics = QualityAgent.assess_quality(state) state[\u0026#34;quality_metrics\u0026#34;] = quality_metrics state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: ProjectState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Route to the next step based on the current state\u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(ProjectState) # Add nodes workflow.add_node(\u0026#34;coordinate\u0026#34;, meta_agent_coordinator) workflow.add_node(\u0026#34;schedule\u0026#34;, handle_scheduling) workflow.add_node(\u0026#34;budget\u0026#34;, handle_budgeting) workflow.add_node(\u0026#34;quality\u0026#34;, handle_quality) # Add edges workflow.add_edge(\u0026#34;coordinate\u0026#34;, router) workflow.add_edge(\u0026#34;schedule\u0026#34;, router) workflow.add_edge(\u0026#34;budget\u0026#34;, router) workflow.add_edge(\u0026#34;quality\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;coordinate\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;coordinate\u0026#34;, router, { \u0026#34;SCHEDULE\u0026#34;: \u0026#34;schedule\u0026#34;, \u0026#34;BUDGET\u0026#34;: \u0026#34;budget\u0026#34;, \u0026#34;QUALITY\u0026#34;: \u0026#34;quality\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;schedule\u0026#34;, router, { \u0026#34;BUDGET\u0026#34;: \u0026#34;budget\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;budget\u0026#34;, router, { \u0026#34;QUALITY\u0026#34;: \u0026#34;quality\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;quality\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state with example project tasks initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;current_request\u0026#34;: \u0026#34;Create project schedule and analyze budget\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;T1\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Requirements Analysis\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Gather and analyze project requirements\u0026#34;, \u0026#34;duration\u0026#34;: 5, \u0026#34;dependencies\u0026#34;: [], \u0026#34;assigned_to\u0026#34;: \u0026#34;Analysis Team\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;Not Started\u0026#34;, \u0026#34;estimated_cost\u0026#34;: 20000 }, { \u0026#34;id\u0026#34;: \u0026#34;T2\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;System Design\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Create system architecture and design\u0026#34;, \u0026#34;duration\u0026#34;: 10, \u0026#34;dependencies\u0026#34;: [\u0026#34;T1\u0026#34;], \u0026#34;assigned_to\u0026#34;: \u0026#34;Design Team\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;Not Started\u0026#34;, \u0026#34;estimated_cost\u0026#34;: 30000 }, { \u0026#34;id\u0026#34;: \u0026#34;T3\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Implementation\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Develop the system\u0026#34;, \u0026#34;duration\u0026#34;: 20, \u0026#34;dependencies\u0026#34;: [\u0026#34;T2\u0026#34;], \u0026#34;assigned_to\u0026#34;: \u0026#34;Development Team\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;Not Started\u0026#34;, \u0026#34;estimated_cost\u0026#34;: 50000 } ], \u0026#34;schedule\u0026#34;: None, \u0026#34;budget\u0026#34;: None, \u0026#34;quality_metrics\u0026#34;: {}, \u0026#34;next_action\u0026#34;: \u0026#34;COORDINATE\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 5. ระบบวางแผนและปฏิบัติ (Planner-Executor) รูปแบบนี้แยกการทำงานเป็นสองส่วนชัดเจน คือ:\nส่วนวางแผน:\nวิเคราะห์สถานการณ์ กำหนดกลยุทธ์ จัดลำดับความสำคัญของงาน ส่วนปฏิบัติ:\nดำเนินการตามแผน รายงานความคืบหน้า แจ้งเตือนเมื่อพบปัญหา ระบบ AI ที่เล่นเกมเป็นตัวอย่างที่ดี โดยส่วนวางแผนจะคิดกลยุทธ์การเล่น และส่วนปฏิบัติจะควบคุมการเคลื่อนไหวในเกม\nตัวอย่าง Planner-Executor from typing import Dict, List, TypedDict, Optional, Tuple import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter import os # Define game-specific structures @dataclass class GameState: board: List[List[str]] # tic-tac-toe board current_player: str moves_made: int game_over: bool @dataclass class Strategy: main_goal: str priority_positions: List[Tuple[int, int]] fallback_positions: List[Tuple[int, int]] expected_outcome: str @dataclass class Move: position: Tuple[int, int] player: str priority: int reasoning: str class AIState(TypedDict): messages: List[str] game_state: Dict current_strategy: Optional[Dict] planned_move: Optional[Dict] execution_result: Optional[Dict] next_action: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, # หรือโมเดลอื่นที่ OpenRouter รองรับ temperature=0.2, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, # your website URL \u0026#34;X-Title\u0026#34;: \u0026#34;Tic-Tac-Toe AI\u0026#34; # your app name } ) class GameManager: \u0026#34;\u0026#34;\u0026#34;Manages the game state and rules\u0026#34;\u0026#34;\u0026#34; @staticmethod def create_empty_board() -\u0026gt; List[List[str]]: return [[\u0026#34; \u0026#34; for _ in range(3)] for _ in range(3)] @staticmethod def is_valid_move(board: List[List[str]], position: Tuple[int, int]) -\u0026gt; bool: row, col = position if row \u0026lt; 0 or row \u0026gt; 2 or col \u0026lt; 0 or col \u0026gt; 2: return False return board[row][col] == \u0026#34; \u0026#34; @staticmethod def make_move(board: List[List[str]], position: Tuple[int, int], player: str) -\u0026gt; List[List[str]]: new_board = [row[:] for row in board] row, col = position new_board[row][col] = player return new_board @staticmethod def check_winner(board: List[List[str]]) -\u0026gt; Optional[str]: # Check rows for row in board: if row[0] == row[1] == row[2] != \u0026#34; \u0026#34;: return row[0] # Check columns for col in range(3): if board[0][col] == board[1][col] == board[2][col] != \u0026#34; \u0026#34;: return board[0][col] # Check diagonals if board[0][0] == board[1][1] == board[2][2] != \u0026#34; \u0026#34;: return board[0][0] if board[0][2] == board[1][1] == board[2][0] != \u0026#34; \u0026#34;: return board[0][2] return None class Planner: \u0026#34;\u0026#34;\u0026#34;Strategic planner for the game\u0026#34;\u0026#34;\u0026#34; @staticmethod def analyze_game_state(state: GameState) -\u0026gt; Strategy: board_str = \u0026#34;\\n\u0026#34;.join([\u0026#34;|\u0026#34;.join(row) for row in state.board]) messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze this Tic-Tac-Toe board and create a strategic plan: Current Board: {board_str} Player: {state.current_player} Moves Made: {state.moves_made} Please provide a structured strategy with: 1. Main Goal: [win/block/develop] 2. Priority Positions: Provide coordinates as tuples (row, col), 0-2 3. Fallback Positions: Provide alternative coordinates 4. Expected Outcome: [Victory/Draw/Continue] Consider: - Winning opportunities - Blocking opponent\u0026#39;s winning moves - Center and corner control - Development of winning patterns \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Parse response to create strategy (simplified) # In real implementation, would use more robust parsing strategy = Strategy( main_goal=\u0026#34;Win in next move\u0026#34; if \u0026#34;win\u0026#34; in response.content.lower() else \u0026#34;Block opponent\u0026#34;, priority_positions=[(1, 1), (0, 0), (2, 2)], # Example positions fallback_positions=[(0, 1), (1, 0), (1, 2), (2, 1)], expected_outcome=\u0026#34;Victory\u0026#34; if \u0026#34;victory\u0026#34; in response.content.lower() else \u0026#34;Continue\u0026#34; ) return strategy class Executor: \u0026#34;\u0026#34;\u0026#34;Tactical executor of planned moves\u0026#34;\u0026#34;\u0026#34; @staticmethod def execute_move(game_state: GameState, strategy: Strategy) -\u0026gt; Move: # Try priority positions first for pos in strategy.priority_positions: if GameManager.is_valid_move(game_state.board, pos): return Move( position=pos, player=game_state.current_player, priority=1, reasoning=\u0026#34;Priority position available\u0026#34; ) # Try fallback positions for pos in strategy.fallback_positions: if GameManager.is_valid_move(game_state.board, pos): return Move( position=pos, player=game_state.current_player, priority=2, reasoning=\u0026#34;Fallback position used\u0026#34; ) # Find any valid move if nothing else is available for i in range(3): for j in range(3): if GameManager.is_valid_move(game_state.board, (i, j)): return Move( position=(i, j), player=game_state.current_player, priority=3, reasoning=\u0026#34;Last resort move\u0026#34; ) raise ValueError(\u0026#34;No valid moves available\u0026#34;) def strategic_planning(state: AIState) -\u0026gt; AIState: \u0026#34;\u0026#34;\u0026#34; Strategic planning phase \u0026#34;\u0026#34;\u0026#34; game_state = GameState(**state[\u0026#34;game_state\u0026#34;]) strategy = Planner.analyze_game_state(game_state) state[\u0026#34;current_strategy\u0026#34;] = asdict(strategy) state[\u0026#34;next_action\u0026#34;] = \u0026#34;EXECUTE\u0026#34; return state def tactical_execution(state: AIState) -\u0026gt; AIState: \u0026#34;\u0026#34;\u0026#34; Tactical execution phase \u0026#34;\u0026#34;\u0026#34; game_state = GameState(**state[\u0026#34;game_state\u0026#34;]) strategy = Strategy(**state[\u0026#34;current_strategy\u0026#34;]) # Execute the planned move move = Executor.execute_move(game_state, strategy) # Update game state with the executed move new_board = GameManager.make_move( game_state.board, move.position, game_state.current_player ) # Update state state[\u0026#34;game_state\u0026#34;][\u0026#34;board\u0026#34;] = new_board state[\u0026#34;game_state\u0026#34;][\u0026#34;moves_made\u0026#34;] += 1 state[\u0026#34;execution_result\u0026#34;] = asdict(move) # Check for game end conditions winner = GameManager.check_winner(new_board) if winner or state[\u0026#34;game_state\u0026#34;][\u0026#34;moves_made\u0026#34;] \u0026gt;= 9: state[\u0026#34;game_state\u0026#34;][\u0026#34;game_over\u0026#34;] = True state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; else: state[\u0026#34;next_action\u0026#34;] = \u0026#34;PLAN\u0026#34; return state def router(state: AIState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; Route to the next step based on the current state \u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(AIState) # Add nodes workflow.add_node(\u0026#34;plan\u0026#34;, strategic_planning) workflow.add_node(\u0026#34;execute\u0026#34;, tactical_execution) # Add edges workflow.add_edge(\u0026#34;plan\u0026#34;, router) workflow.add_edge(\u0026#34;execute\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;plan\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;plan\u0026#34;, router, { \u0026#34;EXECUTE\u0026#34;: \u0026#34;execute\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;execute\u0026#34;, router, { \u0026#34;PLAN\u0026#34;: \u0026#34;plan\u0026#34;, \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state with empty game initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;game_state\u0026#34;: { \u0026#34;board\u0026#34;: GameManager.create_empty_board(), \u0026#34;current_player\u0026#34;: \u0026#34;X\u0026#34;, \u0026#34;moves_made\u0026#34;: 0, \u0026#34;game_over\u0026#34;: False }, \u0026#34;current_strategy\u0026#34;: None, \u0026#34;planned_move\u0026#34;: None, \u0026#34;execution_result\u0026#34;: None, \u0026#34;next_action\u0026#34;: \u0026#34;PLAN\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 6. Reflexive Agent - ระบบตอบสนองอัตโนมัติ รูปแบบนี้เน้นการตอบสนองที่รวดเร็วต่อการเปลี่ยนแปลง โดย:\nตรวจจับการเปลี่ยนแปลงในสภาพแวดล้อม ตอบสนองทันทีตามกฎที่กำหนดไว้ ไม่ต้องใช้เวลาคิดวิเคราะห์มาก หุ่นยนต์ดูดฝุ่นที่หลบสิ่งกีดขวางอัตโนมัติเป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Reflexive Agent from typing import Dict, List, TypedDict, Tuple, Optional from enum import Enum import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain.chat_models import ChatOpenRouter from langchain_core.messages import HumanMessage, AIMessage import random import os # Define enums for direction and action class Direction(str, Enum): NORTH = \u0026#34;NORTH\u0026#34; SOUTH = \u0026#34;SOUTH\u0026#34; EAST = \u0026#34;EAST\u0026#34; WEST = \u0026#34;WEST\u0026#34; class Action(str, Enum): MOVE_FORWARD = \u0026#34;MOVE_FORWARD\u0026#34; TURN_LEFT = \u0026#34;TURN_LEFT\u0026#34; TURN_RIGHT = \u0026#34;TURN_RIGHT\u0026#34; CLEAN = \u0026#34;CLEAN\u0026#34; RETURN_HOME = \u0026#34;RETURN_HOME\u0026#34; # Define data structures @dataclass class Position: x: int y: int @dataclass class SensorData: front_obstacle: bool left_obstacle: bool right_obstacle: bool dirt_detected: bool battery_level: int @dataclass class RobotState: position: Position direction: Direction battery_level: int cleaned_positions: List[Tuple[int, int]] class AgentState(TypedDict): messages: List[str] robot_state: Dict sensor_data: Dict action_taken: Optional[str] next_action: str # Simulated environment class Environment: def __init__(self, size: int = 10): self.size = size self.obstacles = self._generate_obstacles() self.dirt_locations = self._generate_dirt() def _generate_obstacles(self) -\u0026gt; List[Tuple[int, int]]: # Generate random obstacles obstacles = [] num_obstacles = self.size * 2 for _ in range(num_obstacles): x = random.randint(0, self.size-1) y = random.randint(0, self.size-1) if (x, y) != (0, 0): # Keep starting position clear obstacles.append((x, y)) return obstacles def _generate_dirt(self) -\u0026gt; List[Tuple[int, int]]: # Generate random dirt locations dirt = [] num_dirt = self.size * 3 for _ in range(num_dirt): x = random.randint(0, self.size-1) y = random.randint(0, self.size-1) if (x, y) not in self.obstacles: dirt.append((x, y)) return dirt def get_sensor_data(self, position: Position, direction: Direction) -\u0026gt; SensorData: # Check for obstacles in adjacent positions front_pos = self._get_adjacent_position(position, direction) left_pos = self._get_adjacent_position(position, self._turn_left(direction)) right_pos = self._get_adjacent_position(position, self._turn_right(direction)) return SensorData( front_obstacle=self._is_obstacle(front_pos), left_obstacle=self._is_obstacle(left_pos), right_obstacle=self._is_obstacle(right_pos), dirt_detected=(position.x, position.y) in self.dirt_locations, battery_level=100 # Simplified battery simulation ) def _is_obstacle(self, position: Position) -\u0026gt; bool: # Check if position is obstacle or out of bounds if (position.x \u0026lt; 0 or position.x \u0026gt;= self.size or position.y \u0026lt; 0 or position.y \u0026gt;= self.size): return True return (position.x, position.y) in self.obstacles @staticmethod def _get_adjacent_position(pos: Position, direction: Direction) -\u0026gt; Position: if direction == Direction.NORTH: return Position(pos.x, pos.y + 1) elif direction == Direction.SOUTH: return Position(pos.x, pos.y - 1) elif direction == Direction.EAST: return Position(pos.x + 1, pos.y) else: # WEST return Position(pos.x - 1, pos.y) @staticmethod def _turn_left(direction: Direction) -\u0026gt; Direction: turns = { Direction.NORTH: Direction.WEST, Direction.WEST: Direction.SOUTH, Direction.SOUTH: Direction.EAST, Direction.EAST: Direction.NORTH } return turns[direction] @staticmethod def _turn_right(direction: Direction) -\u0026gt; Direction: turns = { Direction.NORTH: Direction.EAST, Direction.EAST: Direction.SOUTH, Direction.SOUTH: Direction.WEST, Direction.WEST: Direction.NORTH } return turns[direction] # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.2, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, \u0026#34;X-Title\u0026#34;: \u0026#34;Robot Vacuum AI\u0026#34; } ) class StrategicAnalyzer: \u0026#34;\u0026#34;\u0026#34;Analyzes environment and suggests optimal strategies\u0026#34;\u0026#34;\u0026#34; @staticmethod def analyze_situation( sensor_data: SensorData, robot_state: RobotState, env_size: int ) -\u0026gt; Dict: # Create a map representation map_data = [[\u0026#34;?\u0026#34; for _ in range(env_size)] for _ in range(env_size)] map_data[robot_state.position.y][robot_state.position.x] = \u0026#34;R\u0026#34; for x, y in robot_state.cleaned_positions: if map_data[y][x] != \u0026#34;R\u0026#34;: map_data[y][x] = \u0026#34;C\u0026#34; map_str = \u0026#34;\\n\u0026#34;.join([\u0026#34; \u0026#34;.join(row) for row in map_data]) messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze the robot vacuum\u0026#39;s situation and suggest a strategy: Current Map (R=Robot, C=Cleaned, ?=Unknown): {map_str} Sensor Data: - Front obstacle: {sensor_data.front_obstacle} - Left obstacle: {sensor_data.left_obstacle} - Right obstacle: {sensor_data.right_obstacle} - Dirt detected: {sensor_data.dirt_detected} - Battery level: {sensor_data.battery_level}% Robot State: - Position: ({robot_state.position.x}, {robot_state.position.y}) - Direction: {robot_state.direction} - Cleaned positions: {len(robot_state.cleaned_positions)} Suggest: 1. Primary objective 2. Movement pattern 3. Risk assessment 4. Efficiency recommendations \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Parse LLM response (simplified) return { \u0026#34;strategy\u0026#34;: response.content, \u0026#34;risk_level\u0026#34;: \u0026#34;LOW\u0026#34; if sensor_data.battery_level \u0026gt; 50 else \u0026#34;MEDIUM\u0026#34;, \u0026#34;recommended_pattern\u0026#34;: \u0026#34;SPIRAL\u0026#34; if \u0026#34;spiral\u0026#34; in response.content.lower() else \u0026#34;ZIGZAG\u0026#34; } class ReflexiveRules: \u0026#34;\u0026#34;\u0026#34;Define reflexive rules for the robot vacuum\u0026#34;\u0026#34;\u0026#34; def __init__(self): self.analyzer = StrategicAnalyzer() def determine_action( self, sensor_data: SensorData, robot_state: RobotState, env_size: int ) -\u0026gt; Tuple[Action, str]: # Get strategic analysis for complex decisions analysis = self.analyzer.analyze_situation(sensor_data, robot_state, env_size) # Priority 1: Handle low battery if sensor_data.battery_level \u0026lt; 20: return Action.RETURN_HOME, \u0026#34;Low battery, returning to charging station\u0026#34; # Priority 2: Clean dirt if detected if sensor_data.dirt_detected: return Action.CLEAN, \u0026#34;Dirt detected, cleaning current position\u0026#34; # Priority 3: Navigate based on strategic analysis and obstacles if \u0026#34;SPIRAL\u0026#34; in analysis[\u0026#34;recommended_pattern\u0026#34;]: if not sensor_data.right_obstacle: return Action.TURN_RIGHT, \u0026#34;Following spiral pattern\u0026#34; elif not sensor_data.front_obstacle: return Action.MOVE_FORWARD, \u0026#34;Following spiral pattern\u0026#34; # Default obstacle avoidance if sensor_data.front_obstacle: if not sensor_data.right_obstacle: return Action.TURN_RIGHT, f\u0026#34;Avoiding obstacle: {analysis[\u0026#39;strategy\u0026#39;]}\u0026#34; elif not sensor_data.left_obstacle: return Action.TURN_LEFT, f\u0026#34;Avoiding obstacle: {analysis[\u0026#39;strategy\u0026#39;]}\u0026#34; else: return Action.TURN_LEFT, \u0026#34;Surrounded by obstacles, turning around\u0026#34; # Default: Move forward return Action.MOVE_FORWARD, f\u0026#34;Following {analysis[\u0026#39;recommended_pattern\u0026#39;]} pattern\u0026#34; def sense_and_act(state: AgentState) -\u0026gt; AgentState: \u0026#34;\u0026#34;\u0026#34; Main function for the reflexive agent - sense environment and act immediately \u0026#34;\u0026#34;\u0026#34; # Get current state robot_state = RobotState(**state[\u0026#34;robot_state\u0026#34;]) sensor_data = SensorData(**state[\u0026#34;sensor_data\u0026#34;]) # Create rules engine and determine action rules = ReflexiveRules() action, reasoning = rules.determine_action(sensor_data, robot_state, 10) # 10 is env_size # Execute action and update state if action == Action.MOVE_FORWARD: new_position = Environment._get_adjacent_position( robot_state.position, robot_state.direction ) if not Environment._is_obstacle(Position(new_position.x, new_position.y)): robot_state.position = new_position elif action == Action.TURN_LEFT: robot_state.direction = Environment._turn_left(robot_state.direction) elif action == Action.TURN_RIGHT: robot_state.direction = Environment._turn_right(robot_state.direction) elif action == Action.CLEAN: pos = (robot_state.position.x, robot_state.position.y) if pos not in robot_state.cleaned_positions: robot_state.cleaned_positions.append(pos) # Update state state[\u0026#34;robot_state\u0026#34;] = asdict(robot_state) state[\u0026#34;action_taken\u0026#34;] = action state[\u0026#34;messages\u0026#34;].append(reasoning) # Determine if we should continue or end if action == Action.RETURN_HOME and (robot_state.position.x, robot_state.position.y) == (0, 0): state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; else: state[\u0026#34;next_action\u0026#34;] = \u0026#34;CONTINUE\u0026#34; return state def router(state: AgentState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Route to the next step based on the current state\u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(AgentState) # Add node workflow.add_node(\u0026#34;sense_and_act\u0026#34;, sense_and_act) # Add edge workflow.add_edge(\u0026#34;sense_and_act\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;sense_and_act\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;sense_and_act\u0026#34;, router, { \u0026#34;CONTINUE\u0026#34;: \u0026#34;sense_and_act\u0026#34;, \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize environment env = Environment(size=10) # Initialize state initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;robot_state\u0026#34;: { \u0026#34;position\u0026#34;: asdict(Position(0, 0)), \u0026#34;direction\u0026#34;: Direction.NORTH, \u0026#34;battery_level\u0026#34;: 100, \u0026#34;cleaned_positions\u0026#34;: [] }, \u0026#34;sensor_data\u0026#34;: asdict(env.get_sensor_data(Position(0, 0), Direction.NORTH)), \u0026#34;action_taken\u0026#34;: None, \u0026#34;next_action\u0026#34;: \u0026#34;CONTINUE\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) # Update sensor data for next iteration robot_state = RobotState(**output[\u0026#34;robot_state\u0026#34;]) output[\u0026#34;sensor_data\u0026#34;] = asdict(env.get_sensor_data( Position(**robot_state.position), robot_state.direction )) 7. Interactive Learning - การเรียนรู้แบบมีปฏิสัมพันธ์ รูปแบบนี้น่าสนใจเพราะช่วยให้ระบบพัฒนาได้จากการมีปฏิสัมพันธ์กับผู้ใช้ โดย:\nรับข้อเสนอแนะจากผู้ใช้ วิเคราะห์และเรียนรู้จากข้อมูลป้อนกลับ ปรับปรุงพฤติกรรมให้ตรงกับความต้องการ ระบบแปลภาษาที่เรียนรู้จากการแก้ไขของผู้ใช้เป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Interactive Learning from typing import Dict, List, TypedDict, Optional from datetime import datetime import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter import numpy as np from collections import defaultdict import os # Define data structures (dataclasses remain the same) @dataclass class Translation: original_text: str translated_text: str source_language: str target_language: str confidence_score: float timestamp: str @dataclass class UserFeedback: translation_id: str corrected_text: str feedback_type: str # GRAMMAR, CONTEXT, STYLE, etc. comment: str timestamp: str @dataclass class LearningPattern: pattern_type: str original_phrase: str corrected_phrase: str context: str frequency: int confidence: float class TranslatorState(TypedDict): messages: List[str] current_text: str source_language: str target_language: str translation_history: List[Dict] feedback_history: List[Dict] learning_patterns: Dict[str, List[Dict]] current_translation: Optional[Dict] next_action: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.3, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, # your website URL \u0026#34;X-Title\u0026#34;: \u0026#34;Translation Assistant\u0026#34; # your app name } ) class TranslationMemory: \u0026#34;\u0026#34;\u0026#34;Manages translation patterns and corrections\u0026#34;\u0026#34;\u0026#34; def __init__(self): self.patterns = defaultdict(list) def add_pattern(self, pattern: LearningPattern): key = f\u0026#34;{pattern.pattern_type}:{pattern.original_phrase}\u0026#34; existing = next( (p for p in self.patterns[key] if p[\u0026#34;corrected_phrase\u0026#34;] == pattern.corrected_phrase), None ) if existing: existing[\u0026#34;frequency\u0026#34;] += 1 existing[\u0026#34;confidence\u0026#34;] = min(1.0, existing[\u0026#34;confidence\u0026#34;] + 0.1) else: self.patterns[key].append(asdict(pattern)) def get_relevant_patterns(self, text: str, pattern_type: str) -\u0026gt; List[Dict]: relevant = [] for key, patterns in self.patterns.items(): if key.startswith(f\u0026#34;{pattern_type}:\u0026#34;): original = key.split(\u0026#34;:\u0026#34;, 1)[1] if original.lower() in text.lower(): relevant.extend(patterns) return relevant class FeedbackAnalyzer: \u0026#34;\u0026#34;\u0026#34;Analyzes user feedback to extract learning patterns\u0026#34;\u0026#34;\u0026#34; @staticmethod def analyze_feedback( original: Translation, feedback: UserFeedback ) -\u0026gt; List[LearningPattern]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze this translation pair and identify improvement patterns: Original Text: {original.original_text} Initial Translation: {original.translated_text} Corrected Translation: {feedback.corrected_text} Feedback Type: {feedback.feedback_type} User Comment: {feedback.comment} Please identify patterns in these categories: 1. GRAMMAR: Grammar rules and structures 2. CONTEXT: Context-specific word choices 3. STYLE: Writing style and natural expression For each identified pattern, provide: - Pattern type (GRAMMAR/CONTEXT/STYLE) - Original phrase - Corrected phrase - Explanation of the improvement \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Extract patterns (simplified version) patterns = [] for feedback_type in [\u0026#34;GRAMMAR\u0026#34;, \u0026#34;CONTEXT\u0026#34;, \u0026#34;STYLE\u0026#34;]: if feedback_type.lower() in response.content.lower(): pattern = LearningPattern( pattern_type=feedback_type, original_phrase=original.translated_text, corrected_phrase=feedback.corrected_text, context=original.original_text, frequency=1, confidence=0.5 ) patterns.append(pattern) return patterns def translate_with_memory(state: TranslatorState) -\u0026gt; TranslatorState: \u0026#34;\u0026#34;\u0026#34; Translate text using learned patterns and translation memory \u0026#34;\u0026#34;\u0026#34; memory = TranslationMemory() # Load patterns from state for pattern_type, patterns in state[\u0026#34;learning_patterns\u0026#34;].items(): for pattern in patterns: memory.add_pattern(LearningPattern(**pattern)) # Get relevant patterns relevant_patterns = [] for pattern_type in [\u0026#34;GRAMMAR\u0026#34;, \u0026#34;CONTEXT\u0026#34;, \u0026#34;STYLE\u0026#34;]: relevant_patterns.extend( memory.get_relevant_patterns(state[\u0026#34;current_text\u0026#34;], pattern_type) ) # Create translation prompt with patterns messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Translate the following text from {state[\u0026#39;source_language\u0026#39;]} to {state[\u0026#39;target_language\u0026#39;]}. Text to translate: {state[\u0026#39;current_text\u0026#39;]} Consider these learned patterns: {json.dumps(relevant_patterns, indent=2)} Please provide: 1. Translation: (your translation) 2. Confidence: (score between 0-1) 3. Applied Patterns: (list which patterns were used) Format your response with clear sections. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Create translation object (with improved parsing) translation = Translation( original_text=state[\u0026#34;current_text\u0026#34;], translated_text=response.content.split(\u0026#34;Translation:\u0026#34;)[1].split(\u0026#34;Confidence:\u0026#34;)[0].strip(), source_language=state[\u0026#34;source_language\u0026#34;], target_language=state[\u0026#34;target_language\u0026#34;], confidence_score=float(response.content.split(\u0026#34;Confidence:\u0026#34;)[1].split(\u0026#34;\\n\u0026#34;)[0].strip()), timestamp=datetime.now().isoformat() ) state[\u0026#34;current_translation\u0026#34;] = asdict(translation) state[\u0026#34;translation_history\u0026#34;].append(asdict(translation)) state[\u0026#34;next_action\u0026#34;] = \u0026#34;AWAIT_FEEDBACK\u0026#34; return state def process_feedback(state: TranslatorState) -\u0026gt; TranslatorState: \u0026#34;\u0026#34;\u0026#34; Process user feedback and update learning patterns \u0026#34;\u0026#34;\u0026#34; if not state[\u0026#34;feedback_history\u0026#34;]: state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state # Get latest feedback feedback = UserFeedback(**state[\u0026#34;feedback_history\u0026#34;][-1]) original = Translation(**state[\u0026#34;current_translation\u0026#34;]) # Analyze feedback analyzer = FeedbackAnalyzer() new_patterns = analyzer.analyze_feedback(original, feedback) # Update learning patterns memory = TranslationMemory() for pattern in new_patterns: pattern_type = pattern.pattern_type.lower() if pattern_type not in state[\u0026#34;learning_patterns\u0026#34;]: state[\u0026#34;learning_patterns\u0026#34;][pattern_type] = [] memory.add_pattern(pattern) state[\u0026#34;learning_patterns\u0026#34;][pattern_type].append(asdict(pattern)) state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def process_feedback(state: TranslatorState) -\u0026gt; TranslatorState: \u0026#34;\u0026#34;\u0026#34; Process user feedback and update learning patterns \u0026#34;\u0026#34;\u0026#34; if not state[\u0026#34;feedback_history\u0026#34;]: state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state # Get latest feedback feedback = UserFeedback(**state[\u0026#34;feedback_history\u0026#34;][-1]) original = Translation(**state[\u0026#34;current_translation\u0026#34;]) # Analyze feedback analyzer = FeedbackAnalyzer() new_patterns = analyzer.analyze_feedback(original, feedback) # Update learning patterns memory = TranslationMemory() for pattern in new_patterns: pattern_type = pattern.pattern_type.lower() if pattern_type not in state[\u0026#34;learning_patterns\u0026#34;]: state[\u0026#34;learning_patterns\u0026#34;][pattern_type] = [] memory.add_pattern(pattern) state[\u0026#34;learning_patterns\u0026#34;][pattern_type].append(asdict(pattern)) state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: TranslatorState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; Route to the next step based on the current state \u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(TranslatorState) # Add nodes workflow.add_node(\u0026#34;translate\u0026#34;, translate_with_memory) workflow.add_node(\u0026#34;feedback\u0026#34;, process_feedback) # Add edges workflow.add_edge(\u0026#34;translate\u0026#34;, router) workflow.add_edge(\u0026#34;feedback\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;translate\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;translate\u0026#34;, router, { \u0026#34;AWAIT_FEEDBACK\u0026#34;: \u0026#34;feedback\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;feedback\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;current_text\u0026#34;: \u0026#34;The cat sat on the mat.\u0026#34;, \u0026#34;source_language\u0026#34;: \u0026#34;English\u0026#34;, \u0026#34;target_language\u0026#34;: \u0026#34;Thai\u0026#34;, \u0026#34;translation_history\u0026#34;: [], \u0026#34;feedback_history\u0026#34;: [ { \u0026#34;translation_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;corrected_text\u0026#34;: \u0026#34;แมวนั่งอยู่บนเสื่อ\u0026#34;, \u0026#34;feedback_type\u0026#34;: \u0026#34;STYLE\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;More natural Thai expression\u0026#34;, \u0026#34;timestamp\u0026#34;: datetime.now().isoformat() } ], \u0026#34;learning_patterns\u0026#34;: {}, \u0026#34;current_translation\u0026#34;: None, \u0026#34;next_action\u0026#34;: \u0026#34;TRANSLATE\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 8. การแยกงานเป็นลำดับชั้น (Hierarchical Task Decomposition) รูปแบบนี้ช่วยจัดการงานที่ซับซ้อนได้อย่างมีประสิทธิภาพ โดย:\nแยกงานใหญ่เป็นงานย่อยที่จัดการได้ง่ายขึ้น จัดลำดับความสำคัญของงานย่อย ติดตามความคืบหน้าในแต่ละระดับ ผู้ช่วย AI ที่ช่วยจัดงานอีเวนต์ โดยแบ่งเป็นการจองสถานที่ ส่งการ์ดเชิญ และจัดตารางงาน เป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Hierarchical Task Decomposition from typing import Dict, List, TypedDict, Optional from datetime import datetime, timedelta import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter import os # Define data structures @dataclass class Task: id: str name: str description: str priority: int # 1 (highest) to 5 (lowest) status: str # NOT_STARTED, IN_PROGRESS, COMPLETED parent_id: Optional[str] subtasks: List[str] dependencies: List[str] assigned_to: str deadline: str progress: int # 0-100% @dataclass class TaskUpdate: task_id: str status: str progress: int notes: str timestamp: str class PlannerState(TypedDict): messages: List[str] event_details: Dict tasks: Dict[str, Dict] updates: List[Dict] current_focus: Optional[str] next_action: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.2, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, # your website URL \u0026#34;X-Title\u0026#34;: \u0026#34;Event Planning Assistant\u0026#34; # your app name } ) class TaskDecomposer: \u0026#34;\u0026#34;\u0026#34;Handles breaking down complex tasks into subtasks\u0026#34;\u0026#34;\u0026#34; @staticmethod def decompose_event_planning(event_details: Dict) -\u0026gt; List[Task]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Please decompose this event into a structured task hierarchy: EVENT DETAILS: {json.dumps(event_details, indent=2)} MAIN CATEGORIES: 1. Venue Management 2. Guest Management 3. Logistics \u0026amp; Schedule 4. Budget \u0026amp; Contracts For each task, provide: 1. Task ID (unique identifier) 2. Task Name 3. Description (clear and actionable) 4. Priority (1-5, where 1 is highest) 5. Dependencies (list of task IDs) 6. Timeline and deadlines 7. Team assignment Ensure tasks are: - Well-defined and measurable - Properly sequenced with dependencies - Assigned appropriate priorities - Given realistic timelines Format each task in a structured way. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Create task hierarchy (simplified version - would parse LLM response in full implementation) tasks = [ Task( id=\u0026#34;VENUE_MAIN\u0026#34;, name=\u0026#34;Venue Management\u0026#34;, description=\u0026#34;Overall venue selection and management\u0026#34;, priority=1, status=\u0026#34;NOT_STARTED\u0026#34;, parent_id=None, subtasks=[\u0026#34;VENUE_SEARCH\u0026#34;, \u0026#34;VENUE_BOOK\u0026#34;, \u0026#34;VENUE_SETUP\u0026#34;], dependencies=[], assigned_to=\u0026#34;Venue Team\u0026#34;, deadline=(datetime.now() + timedelta(days=30)).isoformat(), progress=0 ), Task( id=\u0026#34;VENUE_SEARCH\u0026#34;, name=\u0026#34;Venue Search\u0026#34;, description=\u0026#34;Research and visit potential venues\u0026#34;, priority=1, status=\u0026#34;NOT_STARTED\u0026#34;, parent_id=\u0026#34;VENUE_MAIN\u0026#34;, subtasks=[], dependencies=[], assigned_to=\u0026#34;Venue Team\u0026#34;, deadline=(datetime.now() + timedelta(days=7)).isoformat(), progress=0 ), # Additional tasks would be parsed from LLM response ] return tasks class TaskPrioritizer: \u0026#34;\u0026#34;\u0026#34;Manages task priorities and dependencies\u0026#34;\u0026#34;\u0026#34; @staticmethod def calculate_critical_path(tasks: Dict[str, Task]) -\u0026gt; List[str]: critical_tasks = [] remaining_tasks = set(tasks.keys()) while remaining_tasks: for task_id in list(remaining_tasks): task = tasks[task_id] if all(dep not in remaining_tasks for dep in task.dependencies): critical_tasks.append(task_id) remaining_tasks.remove(task_id) return critical_tasks @staticmethod def update_priorities(tasks: Dict[str, Task]) -\u0026gt; Dict[str, Task]: critical_path = TaskPrioritizer.calculate_critical_path(tasks) # Adjust priorities based on critical path for i, task_id in enumerate(critical_path): tasks[task_id].priority = min(tasks[task_id].priority, 1 + i // 3) return tasks class ProgressTracker: \u0026#34;\u0026#34;\u0026#34;Tracks and updates task progress\u0026#34;\u0026#34;\u0026#34; @staticmethod def update_task_progress( tasks: Dict[str, Task], update: TaskUpdate ) -\u0026gt; Dict[str, Task]: if update.task_id not in tasks: return tasks # Update specific task task = tasks[update.task_id] task.status = update.status task.progress = update.progress # Update parent task progress if task.parent_id: parent = tasks[task.parent_id] subtask_progress = [ tasks[subtask_id].progress for subtask_id in parent.subtasks ] parent.progress = sum(subtask_progress) // len(subtask_progress) return tasks @staticmethod def get_status_report(tasks: Dict[str, Task]) -\u0026gt; Dict: return { \u0026#34;total_tasks\u0026#34;: len(tasks), \u0026#34;completed\u0026#34;: sum(1 for t in tasks.values() if t.status == \u0026#34;COMPLETED\u0026#34;), \u0026#34;in_progress\u0026#34;: sum(1 for t in tasks.values() if t.status == \u0026#34;IN_PROGRESS\u0026#34;), \u0026#34;not_started\u0026#34;: sum(1 for t in tasks.values() if t.status == \u0026#34;NOT_STARTED\u0026#34;), \u0026#34;overall_progress\u0026#34;: sum(t.progress for t in tasks.values()) // len(tasks) } def decompose_tasks(state: PlannerState) -\u0026gt; PlannerState: \u0026#34;\u0026#34;\u0026#34; Initial task decomposition \u0026#34;\u0026#34;\u0026#34; decomposer = TaskDecomposer() tasks = decomposer.decompose_event_planning(state[\u0026#34;event_details\u0026#34;]) # Convert tasks to dictionary format state[\u0026#34;tasks\u0026#34;] = {task.id: asdict(task) for task in tasks} state[\u0026#34;next_action\u0026#34;] = \u0026#34;PRIORITIZE\u0026#34; return state def prioritize_tasks(state: PlannerState) -\u0026gt; PlannerState: \u0026#34;\u0026#34;\u0026#34; Prioritize tasks and calculate critical path \u0026#34;\u0026#34;\u0026#34; # Convert dict back to Task objects tasks = { task_id: Task(**task_data) for task_id, task_data in state[\u0026#34;tasks\u0026#34;].items() } # Update priorities prioritizer = TaskPrioritizer() tasks = prioritizer.update_priorities(tasks) # Convert back to dict format state[\u0026#34;tasks\u0026#34;] = {task_id: asdict(task) for task_id, task in tasks.items()} state[\u0026#34;next_action\u0026#34;] = \u0026#34;UPDATE_PROGRESS\u0026#34; return state def update_progress(state: PlannerState) -\u0026gt; PlannerState: \u0026#34;\u0026#34;\u0026#34; Update task progress based on recent updates \u0026#34;\u0026#34;\u0026#34; if not state[\u0026#34;updates\u0026#34;]: state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state # Convert dict back to Task objects tasks = { task_id: Task(**task_data) for task_id, task_data in state[\u0026#34;tasks\u0026#34;].items() } # Process each update tracker = ProgressTracker() for update_data in state[\u0026#34;updates\u0026#34;]: update = TaskUpdate(**update_data) tasks = tracker.update_task_progress(tasks, update) # Get status report status_report = tracker.get_status_report(tasks) # Update state state[\u0026#34;tasks\u0026#34;] = {task_id: asdict(task) for task_id, task in tasks.items()} state[\u0026#34;status_report\u0026#34;] = status_report state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: PlannerState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; Route to the next step based on the current state \u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(PlannerState) # Add nodes workflow.add_node(\u0026#34;decompose\u0026#34;, decompose_tasks) workflow.add_node(\u0026#34;prioritize\u0026#34;, prioritize_tasks) workflow.add_node(\u0026#34;progress\u0026#34;, update_progress) # Add edges workflow.add_edge(\u0026#34;decompose\u0026#34;, router) workflow.add_edge(\u0026#34;prioritize\u0026#34;, router) workflow.add_edge(\u0026#34;progress\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;decompose\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;decompose\u0026#34;, router, { \u0026#34;PRIORITIZE\u0026#34;: \u0026#34;prioritize\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;prioritize\u0026#34;, router, { \u0026#34;UPDATE_PROGRESS\u0026#34;: \u0026#34;progress\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;progress\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state with example event initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;event_details\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Tech Conference 2025\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2025-06-15\u0026#34;, \u0026#34;expected_attendees\u0026#34;: 200, \u0026#34;type\u0026#34;: \u0026#34;Conference\u0026#34;, \u0026#34;budget\u0026#34;: 50000, \u0026#34;location_preference\u0026#34;: \u0026#34;City Center\u0026#34;, \u0026#34;special_requirements\u0026#34;: [\u0026#34;AV Equipment\u0026#34;, \u0026#34;Catering\u0026#34;, \u0026#34;Registration Desk\u0026#34;] }, \u0026#34;tasks\u0026#34;: {}, \u0026#34;updates\u0026#34;: [ { \u0026#34;task_id\u0026#34;: \u0026#34;VENUE_SEARCH\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;COMPLETED\u0026#34;, \u0026#34;progress\u0026#34;: 100, \u0026#34;notes\u0026#34;: \u0026#34;Selected Convention Center A\u0026#34;, \u0026#34;timestamp\u0026#34;: datetime.now().isoformat() } ], \u0026#34;current_focus\u0026#34;: None, \u0026#34;next_action\u0026#34;: \u0026#34;DECOMPOSE\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 9. ระบบที่ทำงานตามเป้าหมาย (Goal-Oriented Agent) รูปแบบนี้เน้นการทำงานที่มีจุดมุ่งหมายชัดเจน โดย:\nกำหนดเป้าหมายที่ต้องการ วางแผนการทำงานเพื่อให้บรรลุเป้าหมาย ปรับเปลี่ยนกลยุทธ์ตามสถานการณ์ ระบบวางแผนการเงินที่ปรับกลยุทธ์การลงทุนเพื่อให้บรรลุเป้าหมายการออมเป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Goal-Oriented Agent from typing import Dict, List, TypedDict, Optional from datetime import datetime, timedelta import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter import os # Define data structures @dataclass class FinancialGoal: id: str name: str target_amount: float current_amount: float target_date: str priority: int # 1 (highest) to 5 (lowest) risk_tolerance: str # LOW, MEDIUM, HIGH progress: float # Percentage @dataclass class Investment: type: str # STOCKS, BONDS, SAVINGS, etc. amount: float expected_return: float risk_level: str liquidity: str allocation_percentage: float @dataclass class Strategy: goal_id: str investments: List[Investment] monthly_contribution: float expected_timeline: int # months risk_assessment: str contingency_plans: List[str] class PlannerState(TypedDict): messages: List[str] financial_goals: Dict[str, Dict] current_portfolio: Dict[str, float] market_conditions: Dict[str, str] strategies: Dict[str, Dict] analysis_results: Optional[Dict] next_action: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.2, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, \u0026#34;X-Title\u0026#34;: \u0026#34;Financial Planning Assistant\u0026#34; } ) class GoalAnalyzer: \u0026#34;\u0026#34;\u0026#34;Analyzes financial goals and current progress\u0026#34;\u0026#34;\u0026#34; @staticmethod def analyze_goal_progress(goal: FinancialGoal, strategy: Strategy) -\u0026gt; Dict: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze progress towards this financial goal: Goal Details: - Name: {goal.name} - Target: ${goal.target_amount:,.2f} - Current: ${goal.current_amount:,.2f} - Deadline: {goal.target_date} - Risk Tolerance: {goal.risk_tolerance} Current Strategy: - Monthly Contribution: ${strategy.monthly_contribution:,.2f} - Timeline: {strategy.expected_timeline} months - Investment Mix: {json.dumps([asdict(inv) for inv in strategy.investments], indent=2)} Please analyze: 1. Progress status and likelihood of achievement 2. Risk alignment 3. Required adjustments 4. Recommendations for optimization \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Parse response for analysis results return { \u0026#34;status\u0026#34;: \u0026#34;ON_TRACK\u0026#34; if goal.progress \u0026gt;= (goal.current_amount / goal.target_amount * 100) else \u0026#34;NEEDS_ADJUSTMENT\u0026#34;, \u0026#34;analysis\u0026#34;: response.content, \u0026#34;requires_strategy_update\u0026#34;: \u0026#34;adjustment\u0026#34; in response.content.lower() } class StrategyPlanner: \u0026#34;\u0026#34;\u0026#34;Plans and adjusts investment strategies\u0026#34;\u0026#34;\u0026#34; @staticmethod def create_strategy( goal: FinancialGoal, current_portfolio: Dict[str, float], market_conditions: Dict[str, str] ) -\u0026gt; Strategy: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Create an investment strategy for this financial goal: Goal: {json.dumps(asdict(goal), indent=2)} Current Portfolio: {json.dumps(current_portfolio, indent=2)} Market Conditions: {json.dumps(market_conditions, indent=2)} Provide a comprehensive strategy including: 1. Asset allocation 2. Monthly contribution requirements 3. Risk management approach 4. Timeline and milestones 5. Contingency plans Consider: - Risk tolerance level - Time horizon - Current market conditions - Liquidity needs \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Create strategy (simplified version - would parse LLM response in real implementation) return Strategy( goal_id=goal.id, investments=[ Investment( type=\u0026#34;STOCKS\u0026#34;, amount=goal.target_amount * 0.6, expected_return=0.08, risk_level=\u0026#34;MEDIUM\u0026#34;, liquidity=\u0026#34;MEDIUM\u0026#34;, allocation_percentage=60 ), Investment( type=\u0026#34;BONDS\u0026#34;, amount=goal.target_amount * 0.3, expected_return=0.04, risk_level=\u0026#34;LOW\u0026#34;, liquidity=\u0026#34;MEDIUM\u0026#34;, allocation_percentage=30 ), Investment( type=\u0026#34;SAVINGS\u0026#34;, amount=goal.target_amount * 0.1, expected_return=0.02, risk_level=\u0026#34;LOW\u0026#34;, liquidity=\u0026#34;HIGH\u0026#34;, allocation_percentage=10 ) ], monthly_contribution=(goal.target_amount - goal.current_amount) / 12, expected_timeline=12, risk_assessment=\u0026#34;MODERATE\u0026#34;, contingency_plans=[ \u0026#34;Increase contributions if falling behind\u0026#34;, \u0026#34;Adjust allocation if market conditions change\u0026#34;, \u0026#34;Extended timeline option available\u0026#34; ] ) class StrategyOptimizer: \u0026#34;\u0026#34;\u0026#34;Optimizes and adjusts strategies based on performance\u0026#34;\u0026#34;\u0026#34; @staticmethod def optimize_strategy( strategy: Strategy, goal: FinancialGoal, market_conditions: Dict[str, str] ) -\u0026gt; Strategy: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Optimize this investment strategy based on current conditions: Current Strategy: {json.dumps(asdict(strategy), indent=2)} Goal Progress: {json.dumps(asdict(goal), indent=2)} Market Conditions: {json.dumps(market_conditions, indent=2)} Please recommend: 1. Allocation adjustments 2. Contribution modifications 3. Risk management updates 4. Timeline revisions Explain the reasoning for each recommendation. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Update strategy based on recommendations # (Simplified - would parse LLM response in real implementation) if goal.progress \u0026lt; 50: # If behind schedule strategy.monthly_contribution *= 1.2 # Increase contributions by 20% # Adjust allocations for more aggressive growth for inv in strategy.investments: if inv.type == \u0026#34;STOCKS\u0026#34;: inv.allocation_percentage += 10 elif inv.type == \u0026#34;SAVINGS\u0026#34;: inv.allocation_percentage -= 10 return strategy def analyze_goals(state: PlannerState) -\u0026gt; PlannerState: \u0026#34;\u0026#34;\u0026#34; Analyze progress towards financial goals \u0026#34;\u0026#34;\u0026#34; analysis_results = {} for goal_id, goal_data in state[\u0026#34;financial_goals\u0026#34;].items(): goal = FinancialGoal(**goal_data) strategy = Strategy(**state[\u0026#34;strategies\u0026#34;][goal_id]) if goal_id in state[\u0026#34;strategies\u0026#34;] else None if strategy: analyzer = GoalAnalyzer() analysis_results[goal_id] = analyzer.analyze_goal_progress(goal, strategy) state[\u0026#34;analysis_results\u0026#34;] = analysis_results state[\u0026#34;next_action\u0026#34;] = \u0026#34;PLAN\u0026#34; return state def plan_strategies(state: PlannerState) -\u0026gt; PlannerState: \u0026#34;\u0026#34;\u0026#34; Create or update investment strategies \u0026#34;\u0026#34;\u0026#34; planner = StrategyPlanner() optimizer = StrategyOptimizer() for goal_id, goal_data in state[\u0026#34;financial_goals\u0026#34;].items(): goal = FinancialGoal(**goal_data) if goal_id not in state[\u0026#34;strategies\u0026#34;]: # Create new strategy strategy = planner.create_strategy( goal, state[\u0026#34;current_portfolio\u0026#34;], state[\u0026#34;market_conditions\u0026#34;] ) state[\u0026#34;strategies\u0026#34;][goal_id] = asdict(strategy) elif state[\u0026#34;analysis_results\u0026#34;][goal_id][\u0026#34;requires_strategy_update\u0026#34;]: # Optimize existing strategy current_strategy = Strategy(**state[\u0026#34;strategies\u0026#34;][goal_id]) optimized_strategy = optimizer.optimize_strategy( current_strategy, goal, state[\u0026#34;market_conditions\u0026#34;] ) state[\u0026#34;strategies\u0026#34;][goal_id] = asdict(optimized_strategy) state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: PlannerState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Route to the next step based on the current state\u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(PlannerState) # Add nodes workflow.add_node(\u0026#34;analyze\u0026#34;, analyze_goals) workflow.add_node(\u0026#34;plan\u0026#34;, plan_strategies) # Add edges workflow.add_edge(\u0026#34;analyze\u0026#34;, router) workflow.add_edge(\u0026#34;plan\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;analyze\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;analyze\u0026#34;, router, { \u0026#34;PLAN\u0026#34;: \u0026#34;plan\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;plan\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;financial_goals\u0026#34;: { \u0026#34;RETIREMENT\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;RETIREMENT\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Retirement Fund\u0026#34;, \u0026#34;target_amount\u0026#34;: 2000000.0, \u0026#34;current_amount\u0026#34;: 500000.0, \u0026#34;target_date\u0026#34;: \u0026#34;2045-01-01\u0026#34;, \u0026#34;priority\u0026#34;: 1, \u0026#34;risk_tolerance\u0026#34;: \u0026#34;MEDIUM\u0026#34;, \u0026#34;progress\u0026#34;: 25.0 } }, \u0026#34;current_portfolio\u0026#34;: { \u0026#34;STOCKS\u0026#34;: 300000.0, \u0026#34;BONDS\u0026#34;: 150000.0, \u0026#34;SAVINGS\u0026#34;: 50000.0 }, \u0026#34;market_conditions\u0026#34;: { \u0026#34;stocks_outlook\u0026#34;: \u0026#34;POSITIVE\u0026#34;, \u0026#34;interest_rates\u0026#34;: \u0026#34;RISING\u0026#34;, \u0026#34;economic_indicators\u0026#34;: \u0026#34;STABLE\u0026#34;, \u0026#34;market_volatility\u0026#34;: \u0026#34;MODERATE\u0026#34; }, \u0026#34;strategies\u0026#34;: {}, \u0026#34;analysis_results\u0026#34;: None, \u0026#34;next_action\u0026#34;: \u0026#34;ANALYZE\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 10. ระบบจดจำบริบท (Contextual Memory) รูปแบบนี้ช่วยให้ระบบสามารถจดจำและใช้ประโยชน์จากข้อมูลในอดีต โดย:\nเก็บข้อมูลการโต้ตอบกับผู้ใช้ วิเคราะห์รูปแบบการใช้งาน ปรับการทำงานให้เหมาะกับแต่ละผู้ใช้ ระบบแชทบอทที่จำความชอบของผู้ใช้และปรับการสนทนาให้เหมาะสมเป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Contextual Memory from typing import Dict, List, TypedDict, Optional from datetime import datetime import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter from collections import defaultdict import os # Define data structures @dataclass class UserPreference: topic: str sentiment: float # -1 to 1 frequency: int last_discussed: str keywords: List[str] @dataclass class ConversationStyle: formality_level: str # CASUAL, FORMAL, PROFESSIONAL preferred_language: str communication_pace: str # BRIEF, DETAILED interests: List[str] special_notes: List[str] @dataclass class Interaction: timestamp: str user_message: str bot_response: str topics: List[str] sentiment: float user_feedback: Optional[str] class ChatbotState(TypedDict): messages: List[str] current_input: str user_id: str user_preferences: Dict[str, Dict] conversation_style: Optional[Dict] interaction_history: List[Dict] context_analysis: Optional[Dict] next_action: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.7, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, \u0026#34;X-Title\u0026#34;: \u0026#34;Contextual Chatbot\u0026#34; } ) class PreferenceAnalyzer: \u0026#34;\u0026#34;\u0026#34;Analyzes and maintains user preferences\u0026#34;\u0026#34;\u0026#34; @staticmethod def update_preferences( current_prefs: Dict[str, UserPreference], interaction: Interaction ) -\u0026gt; Dict[str, UserPreference]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze this interaction and update user preferences: User Message: {interaction.user_message} Bot Response: {interaction.bot_response} Current Topics: {interaction.topics} Current Preferences: {json.dumps({k: asdict(v) for k, v in current_prefs.items()}, indent=2)} Please identify: 1. New topics/interests 2. Sentiment towards topics 3. Key preferences or dislikes 4. Patterns in communication style \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Update preferences based on analysis updated_prefs = current_prefs.copy() # Add new topics or update existing ones for topic in interaction.topics: if topic not in updated_prefs: updated_prefs[topic] = UserPreference( topic=topic, sentiment=interaction.sentiment, frequency=1, last_discussed=interaction.timestamp, keywords=[] ) else: pref = updated_prefs[topic] pref.frequency += 1 pref.last_discussed = interaction.timestamp pref.sentiment = (pref.sentiment * (pref.frequency - 1) + interaction.sentiment) / pref.frequency return updated_prefs class ConversationAnalyzer: \u0026#34;\u0026#34;\u0026#34;Analyzes conversation patterns and style\u0026#34;\u0026#34;\u0026#34; @staticmethod def analyze_style(interactions: List[Interaction]) -\u0026gt; ConversationStyle: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze these interactions to determine conversation style: Recent Interactions: {json.dumps([asdict(i) for i in interactions[-5:]], indent=2)} Please determine: 1. Preferred formality level 2. Communication style (brief/detailed) 3. Key interests and themes 4. Special considerations \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Create conversation style (simplified - would parse LLM response in real implementation) return ConversationStyle( formality_level=\u0026#34;CASUAL\u0026#34; if \u0026#34;casual\u0026#34; in response.content.lower() else \u0026#34;FORMAL\u0026#34;, preferred_language=\u0026#34;English\u0026#34;, # Would be detected from interactions communication_pace=\u0026#34;BRIEF\u0026#34; if \u0026#34;brief\u0026#34; in response.content.lower() else \u0026#34;DETAILED\u0026#34;, interests=[topic for i in interactions[-5:] for topic in i.topics], special_notes=[] ) class ContextManager: \u0026#34;\u0026#34;\u0026#34;Manages contextual memory and retrieval\u0026#34;\u0026#34;\u0026#34; def __init__(self): self.short_term_memory: List[Interaction] = [] self.long_term_memory: Dict[str, List[Interaction]] = defaultdict(list) def add_interaction(self, interaction: Interaction, topics: List[str]): # Add to short-term memory self.short_term_memory.append(interaction) if len(self.short_term_memory) \u0026gt; 10: # Keep last 10 interactions self.short_term_memory.pop(0) # Add to long-term memory by topic for topic in topics: self.long_term_memory[topic].append(interaction) def get_relevant_context(self, current_input: str, user_preferences: Dict[str, UserPreference]) -\u0026gt; List[Interaction]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Find relevant context for this input: Current Input: {current_input} User Preferences: {json.dumps({k: asdict(v) for k, v in user_preferences.items()}, indent=2)} Return relevant topics and importance scores. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Get relevant interactions (simplified) relevant = self.short_term_memory[-3:] # Last 3 interactions for topic in user_preferences: if topic.lower() in current_input.lower(): relevant.extend(self.long_term_memory[topic][-2:]) # Last 2 topic-specific interactions return list(set(relevant)) # Remove duplicates class ResponseGenerator: \u0026#34;\u0026#34;\u0026#34;Generates contextually aware responses\u0026#34;\u0026#34;\u0026#34; @staticmethod def generate_response( current_input: str, relevant_context: List[Interaction], conversation_style: ConversationStyle, user_preferences: Dict[str, UserPreference] ) -\u0026gt; str: context_str = \u0026#34;\\n\u0026#34;.join([ f\u0026#34;Previous interaction: {i.user_message} -\u0026gt; {i.bot_response}\u0026#34; for i in relevant_context[-3:] # Last 3 relevant interactions ]) messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Generate a response considering this context: Current Input: {current_input} Previous Context: {context_str} Conversation Style: {json.dumps(asdict(conversation_style), indent=2)} User Preferences: {json.dumps({k: asdict(v) for k, v in user_preferences.items()}, indent=2)} Generate a response that: 1. Matches the user\u0026#39;s preferred style 2. References relevant past interactions 3. Shows awareness of user preferences 4. Maintains conversation continuity \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) return response.content def analyze_context(state: ChatbotState) -\u0026gt; ChatbotState: \u0026#34;\u0026#34;\u0026#34; Analyze context and user preferences \u0026#34;\u0026#34;\u0026#34; if state[\u0026#34;interaction_history\u0026#34;]: # Convert recent interactions to objects recent_interactions = [ Interaction(**interaction) for interaction in state[\u0026#34;interaction_history\u0026#34;][-5:] ] # Analyze conversation style analyzer = ConversationAnalyzer() conversation_style = analyzer.analyze_style(recent_interactions) state[\u0026#34;conversation_style\u0026#34;] = asdict(conversation_style) # Get relevant context context_manager = ContextManager() for interaction in state[\u0026#34;interaction_history\u0026#34;]: context_manager.add_interaction( Interaction(**interaction), interaction.get(\u0026#34;topics\u0026#34;, []) ) current_prefs = { k: UserPreference(**v) for k, v in state[\u0026#34;user_preferences\u0026#34;].items() } relevant_context = context_manager.get_relevant_context( state[\u0026#34;current_input\u0026#34;], current_prefs ) state[\u0026#34;context_analysis\u0026#34;] = { \u0026#34;relevant_interactions\u0026#34;: [asdict(i) for i in relevant_context], \u0026#34;conversation_style\u0026#34;: asdict(conversation_style) } state[\u0026#34;next_action\u0026#34;] = \u0026#34;RESPOND\u0026#34; return state def generate_response(state: ChatbotState) -\u0026gt; ChatbotState: \u0026#34;\u0026#34;\u0026#34; Generate contextually aware response \u0026#34;\u0026#34;\u0026#34; # Convert data structures conversation_style = ConversationStyle(**state[\u0026#34;conversation_style\u0026#34;]) user_preferences = { k: UserPreference(**v) for k, v in state[\u0026#34;user_preferences\u0026#34;].items() } relevant_context = [ Interaction(**i) for i in state[\u0026#34;context_analysis\u0026#34;][\u0026#34;relevant_interactions\u0026#34;] ] # Generate response generator = ResponseGenerator() response = generator.generate_response( state[\u0026#34;current_input\u0026#34;], relevant_context, conversation_style, user_preferences ) # Create new interaction interaction = Interaction( timestamp=datetime.now().isoformat(), user_message=state[\u0026#34;current_input\u0026#34;], bot_response=response, topics=[], # Would be extracted from response sentiment=0.0, # Would be analyzed user_feedback=None ) # Update state state[\u0026#34;messages\u0026#34;].append(response) state[\u0026#34;interaction_history\u0026#34;].append(asdict(interaction)) state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: ChatbotState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Route to the next step based on the current state\u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(ChatbotState) # Add nodes workflow.add_node(\u0026#34;analyze\u0026#34;, analyze_context) workflow.add_node(\u0026#34;respond\u0026#34;, generate_response) # Add edges workflow.add_edge(\u0026#34;analyze\u0026#34;, router) workflow.add_edge(\u0026#34;respond\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;analyze\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;analyze\u0026#34;, router, { \u0026#34;RESPOND\u0026#34;: \u0026#34;respond\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;respond\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;current_input\u0026#34;: \u0026#34;What restaurants do you recommend?\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user123\u0026#34;, \u0026#34;user_preferences\u0026#34;: { \u0026#34;cuisine\u0026#34;: { \u0026#34;topic\u0026#34;: \u0026#34;cuisine\u0026#34;, \u0026#34;sentiment\u0026#34;: 0.8, \u0026#34;frequency\u0026#34;: 5, \u0026#34;last_discussed\u0026#34;: \u0026#34;2024-02-05T10:00:00\u0026#34;, \u0026#34;keywords\u0026#34;: [\u0026#34;Thai\u0026#34;, \u0026#34;Italian\u0026#34;, \u0026#34;vegetarian\u0026#34;] } }, \u0026#34;conversation_style\u0026#34;: { \u0026#34;formality_level\u0026#34;: \u0026#34;CASUAL\u0026#34;, \u0026#34;preferred_language\u0026#34;: \u0026#34;English\u0026#34;, \u0026#34;communication_pace\u0026#34;: \u0026#34;DETAILED\u0026#34;, \u0026#34;interests\u0026#34;: [\u0026#34;food\u0026#34;, \u0026#34;travel\u0026#34;], \u0026#34;special_notes\u0026#34;: [\u0026#34;Prefers detailed explanations\u0026#34;] }, \u0026#34;interaction_history\u0026#34;: [ { \u0026#34;timestamp\u0026#34;: \u0026#34;2024-02-05T09:00:00\u0026#34;, \u0026#34;user_message\u0026#34;: \u0026#34;I love Thai food\u0026#34;, \u0026#34;bot_response\u0026#34;: \u0026#34;Thai cuisine is amazing! Do you have a favorite dish?\u0026#34;, \u0026#34;topics\u0026#34;: [\u0026#34;cuisine\u0026#34;, \u0026#34;Thai\u0026#34;], \u0026#34;sentiment\u0026#34;: 0.9, \u0026#34;user_feedback\u0026#34;: None } ], \u0026#34;context_analysis\u0026#34;: None, \u0026#34;next_action\u0026#34;: \u0026#34;ANALYZE\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 11. ระบบหลายตัวแทนที่ทำงานร่วมกัน (Collaborative Multi-Agent Systems) รูปแบบนี้น่าสนใจเพราะช่วยให้ระบบย่อยหลายๆ ระบบทำงานร่วมกันได้อย่างมีประสิทธิภาพ โดย:\nแบ่งงานตามความเชี่ยวชาญ ประสานงานระหว่างระบบย่อย แก้ไขความขัดแย้งที่อาจเกิดขึ้น โดรนขนส่งที่ทำงานประสานกันเพื่อส่งพัสดุในเมืองเป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Collaborative Multi-Agent Systems from typing import Dict, List, TypedDict, Optional, Tuple from datetime import datetime, timedelta import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter import os import random from enum import Enum # Define data structures class DroneStatus(str, Enum): IDLE = \u0026#34;IDLE\u0026#34; LOADING = \u0026#34;LOADING\u0026#34; DELIVERING = \u0026#34;DELIVERING\u0026#34; RETURNING = \u0026#34;RETURNING\u0026#34; CHARGING = \u0026#34;CHARGING\u0026#34; MAINTENANCE = \u0026#34;MAINTENANCE\u0026#34; @dataclass class Location: x: float y: float name: str is_charging_station: bool = False is_depot: bool = False @dataclass class Package: id: str pickup_location: Location delivery_location: Location weight: float priority: int # 1 (highest) to 5 (lowest) deadline: str status: str # PENDING, ASSIGNED, IN_TRANSIT, DELIVERED @dataclass class Drone: id: str current_location: Location status: DroneStatus battery_level: float max_payload: float current_package: Optional[str] assigned_zone: List[float] # [x_min, y_min, x_max, y_max] delivery_history: List[str] @dataclass class DeliveryPlan: drone_id: str package_ids: List[str] route: List[Location] estimated_battery_usage: float estimated_completion_time: str priority_score: float class SystemState(TypedDict): messages: List[str] drones: Dict[str, Dict] packages: Dict[str, Dict] delivery_plans: Dict[str, Dict] conflict_resolutions: List[Dict] next_action: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.2, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, \u0026#34;X-Title\u0026#34;: \u0026#34;Drone Fleet Manager\u0026#34; } ) class RouteOptimizer: \u0026#34;\u0026#34;\u0026#34;Optimizes delivery routes for each drone\u0026#34;\u0026#34;\u0026#34; @staticmethod def calculate_distance(loc1: Location, loc2: Location) -\u0026gt; float: return ((loc1.x - loc2.x) ** 2 + (loc1.y - loc2.y) ** 2) ** 0.5 @staticmethod def estimate_battery_usage(route: List[Location], package_weight: float) -\u0026gt; float: total_distance = sum( RouteOptimizer.calculate_distance(route[i], route[i+1]) for i in range(len(route)-1) ) # Simple battery usage model: distance + weight factor return total_distance * (1 + package_weight * 0.1) @staticmethod def optimize_route( drone: Drone, packages: List[Package], charging_stations: List[Location] ) -\u0026gt; DeliveryPlan: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Optimize delivery route for drone considering: Drone Status: {json.dumps(asdict(drone), indent=2)} Available Packages: {json.dumps([asdict(p) for p in packages], indent=2)} Charging Stations: {json.dumps([asdict(s) for s in charging_stations], indent=2)} Consider: 1. Battery efficiency 2. Package priorities 3. Deadlines 4. Drone zone restrictions 5. Charging station locations Provide: 1. Optimized package sequence 2. Complete route with charging stops 3. Estimated battery usage 4. Expected completion time \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Create delivery plan (simplified - would parse LLM response in real implementation) route = [drone.current_location] if packages: route.extend([ packages[0].pickup_location, packages[0].delivery_location ]) if drone.battery_level \u0026lt; 0.3: route.append(min( charging_stations, key=lambda s: RouteOptimizer.calculate_distance(route[-1], s) )) return DeliveryPlan( drone_id=drone.id, package_ids=[p.id for p in packages], route=route, estimated_battery_usage=RouteOptimizer.estimate_battery_usage( route, sum(p.weight for p in packages) ), estimated_completion_time=( datetime.now() + timedelta(minutes=len(route)*10) ).isoformat(), priority_score=sum(1/p.priority for p in packages) ) class ConflictResolver: \u0026#34;\u0026#34;\u0026#34;Resolves conflicts between drone delivery plans\u0026#34;\u0026#34;\u0026#34; @staticmethod def detect_conflicts(plans: List[DeliveryPlan]) -\u0026gt; List[Dict]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze these delivery plans for potential conflicts: Delivery Plans: {json.dumps([asdict(p) for p in plans], indent=2)} Check for: 1. Path intersections 2. Resource conflicts (charging stations) 3. Timing conflicts 4. Zone violations Identify specific conflicts and suggest resolutions. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Process conflicts (simplified) conflicts = [] for i, plan1 in enumerate(plans): for plan2 in plans[i+1:]: # Check for path intersections for loc1 in plan1.route: for loc2 in plan2.route: if (loc1.x == loc2.x and loc1.y == loc2.y and loc1.is_charging_station): conflicts.append({ \u0026#34;type\u0026#34;: \u0026#34;CHARGING_STATION_CONFLICT\u0026#34;, \u0026#34;drones\u0026#34;: [plan1.drone_id, plan2.drone_id], \u0026#34;location\u0026#34;: asdict(loc1), \u0026#34;resolution\u0026#34;: \u0026#34;RESEQUENCE\u0026#34; }) return conflicts @staticmethod def resolve_conflicts( conflicts: List[Dict], plans: Dict[str, DeliveryPlan] ) -\u0026gt; Dict[str, DeliveryPlan]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Resolve these delivery plan conflicts: Conflicts: {json.dumps(conflicts, indent=2)} Current Plans: {json.dumps({k: asdict(v) for k, v in plans.items()}, indent=2)} Provide: 1. Modified routes 2. Updated timing 3. Rationale for changes \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Resolve conflicts (simplified) updated_plans = plans.copy() for conflict in conflicts: if conflict[\u0026#34;type\u0026#34;] == \u0026#34;CHARGING_STATION_CONFLICT\u0026#34;: # Add delay to second drone\u0026#39;s plan drone_id = conflict[\u0026#34;drones\u0026#34;][1] plan = updated_plans[drone_id] plan.estimated_completion_time = ( datetime.fromisoformat(plan.estimated_completion_time) + timedelta(minutes=15) ).isoformat() return updated_plans class FleetCoordinator: \u0026#34;\u0026#34;\u0026#34;Coordinates overall fleet operations\u0026#34;\u0026#34;\u0026#34; @staticmethod def assign_packages( drones: Dict[str, Drone], packages: List[Package], charging_stations: List[Location] ) -\u0026gt; Dict[str, DeliveryPlan]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Assign packages to drones optimally: Available Drones: {json.dumps({k: asdict(v) for k, v in drones.items()}, indent=2)} Pending Packages: {json.dumps([asdict(p) for p in packages], indent=2)} Consider: 1. Drone locations and zones 2. Package priorities and deadlines 3. Battery levels 4. Load balancing Provide assignment plan with rationale. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Create delivery plans (simplified) optimizer = RouteOptimizer() plans = {} for drone in drones.values(): if drone.status in [DroneStatus.IDLE, DroneStatus.RETURNING]: # Find packages in drone\u0026#39;s zone zone_packages = [ p for p in packages if (drone.assigned_zone[0] \u0026lt;= p.delivery_location.x \u0026lt;= drone.assigned_zone[2] and drone.assigned_zone[1] \u0026lt;= p.delivery_location.y \u0026lt;= drone.assigned_zone[3]) ] if zone_packages: plans[drone.id] = optimizer.optimize_route( drone, sorted(zone_packages, key=lambda p: p.priority)[:2], charging_stations ) return plans def plan_deliveries(state: SystemState) -\u0026gt; SystemState: \u0026#34;\u0026#34;\u0026#34; Plan and optimize delivery routes \u0026#34;\u0026#34;\u0026#34; # Convert data structures drones = { k: Drone(**d) for k, d in state[\u0026#34;drones\u0026#34;].items() } packages = [ Package(**p) for p in state[\u0026#34;packages\u0026#34;].values() if p[\u0026#34;status\u0026#34;] == \u0026#34;PENDING\u0026#34; ] charging_stations = [ Location(0, 0, \u0026#34;Station 1\u0026#34;, True), Location(10, 10, \u0026#34;Station 2\u0026#34;, True) ] # Create delivery plans coordinator = FleetCoordinator() plans = coordinator.assign_packages(drones, packages, charging_stations) # Convert to dict format state[\u0026#34;delivery_plans\u0026#34;] = { k: asdict(v) for k, v in plans.items() } state[\u0026#34;next_action\u0026#34;] = \u0026#34;RESOLVE_CONFLICTS\u0026#34; return state def resolve_conflicts(state: SystemState) -\u0026gt; SystemState: \u0026#34;\u0026#34;\u0026#34; Detect and resolve conflicts between delivery plans \u0026#34;\u0026#34;\u0026#34; if not state[\u0026#34;delivery_plans\u0026#34;]: state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state # Convert plans to objects plans = { k: DeliveryPlan(**p) for k, p in state[\u0026#34;delivery_plans\u0026#34;].items() } # Detect and resolve conflicts resolver = ConflictResolver() conflicts = resolver.detect_conflicts(list(plans.values())) if conflicts: updated_plans = resolver.resolve_conflicts(conflicts, plans) state[\u0026#34;delivery_plans\u0026#34;] = { k: asdict(v) for k, v in updated_plans.items() } state[\u0026#34;conflict_resolutions\u0026#34;] = conflicts state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: SystemState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Route to the next step based on the current state\u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(SystemState) # Add nodes workflow.add_node(\u0026#34;plan\u0026#34;, plan_deliveries) workflow.add_node(\u0026#34;resolve\u0026#34;, resolve_conflicts) # Add edges workflow.add_edge(\u0026#34;plan\u0026#34;, router) workflow.add_edge(\u0026#34;resolve\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;plan\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;plan\u0026#34;, router, { \u0026#34;RESOLVE_CONFLICTS\u0026#34;: \u0026#34;resolve\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;resolve\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;drones\u0026#34;: { \u0026#34;drone1\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;drone1\u0026#34;, \u0026#34;current_location\u0026#34;: asdict(Location(0, 0, \u0026#34;Depot\u0026#34;, is_depot=True)), \u0026#34;status\u0026#34;: \u0026#34;IDLE\u0026#34;, \u0026#34;battery_level\u0026#34;: 0.9, \u0026#34;max_payload\u0026#34;: 5.0, \u0026#34;current_package\u0026#34;: None, \u0026#34;assigned_zone\u0026#34;: [0, 0, 5, 5], \u0026#34;delivery_history\u0026#34;: [] }, \u0026#34;drone2\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;drone2\u0026#34;, \u0026#34;current_location\u0026#34;: asdict(Location(5, 5, \u0026#34;Depot 2\u0026#34;, is_depot=True)), \u0026#34;status\u0026#34;: \u0026#34;IDLE\u0026#34;, \u0026#34;battery_level\u0026#34;: 0.8, \u0026#34;max_payload\u0026#34;: 5.0, \u0026#34;current_package\u0026#34;: None, \u0026#34;assigned_zone\u0026#34;: [5, 5, 10, 10], \u0026#34;delivery_history\u0026#34;: [] } }, \u0026#34;packages\u0026#34;: { \u0026#34;pkg1\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;pkg1\u0026#34;, \u0026#34;pickup_location\u0026#34;: asdict(Location(1, 1, \u0026#34;Warehouse A\u0026#34;)), \u0026#34;delivery_location\u0026#34;: asdict(Location(4, 4, \u0026#34;Customer 1\u0026#34;)), \u0026#34;weight\u0026#34;: 2.0, \u0026#34;priority\u0026#34;: 1, \u0026#34;deadline\u0026#34;: (datetime.now() + timedelta(hours=2)).isoformat(), \u0026#34;status\u0026#34;: \u0026#34;PENDING\u0026#34; }, \u0026#34;pkg2\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;pkg2\u0026#34;, \u0026#34;pickup_location\u0026#34;: asdict(Location(6, 6, \u0026#34;Warehouse B\u0026#34;)), \u0026#34;delivery_location\u0026#34;: asdict(Location(8, 8, \u0026#34;Customer 2\u0026#34;)), \u0026#34;weight\u0026#34;: 3.0, \u0026#34;priority\u0026#34;: 2, \u0026#34;deadline\u0026#34;: (datetime.now() + timedelta(hours=3)).isoformat(), \u0026#34;status\u0026#34;: \u0026#34;PENDING\u0026#34; } }, \u0026#34;delivery_plans\u0026#34;: {}, \u0026#34;conflict_resolutions\u0026#34;: [], \u0026#34;next_action\u0026#34;: \u0026#34;PLAN\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 12. ระบบสำรวจ (Exploratory Agent) รูปแบบนี้เหมาะกับการค้นหาข้อมูลและโอกาสใหม่ๆ โดย:\nสำรวจสภาพแวดล้อมหรือข้อมูลที่ไม่คุ้นเคย วิเคราะห์และจัดเก็บข้อมูลที่พบ ระบุรูปแบบหรือโอกาสที่น่าสนใจ ผู้ช่วยวิจัยที่สแกนวารสารวิชาการเพื่อค้นหาแนวโน้มใหม่ๆ เป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Exploratory Agent from typing import Dict, List, TypedDict, Optional from datetime import datetime import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter from collections import defaultdict import os # Define data structures @dataclass class ResearchPaper: title: str authors: List[str] abstract: str keywords: List[str] publication_date: str journal: str citations: int research_areas: List[str] @dataclass class ResearchTrend: topic: str emerging_keywords: List[str] key_papers: List[str] growth_rate: float # Trend growth rate relevance_score: float # 0-1 first_observed: str last_updated: str @dataclass class Insight: trend_id: str description: str supporting_evidence: List[str] potential_impact: str confidence_score: float timestamp: str class ResearchState(TypedDict): messages: List[str] papers: Dict[str, Dict] identified_trends: Dict[str, Dict] insights: List[Dict] research_focus: List[str] analysis_results: Optional[Dict] next_action: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.3, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, \u0026#34;X-Title\u0026#34;: \u0026#34;Research Assistant\u0026#34; } ) class TrendAnalyzer: \u0026#34;\u0026#34;\u0026#34;Analyzes research papers to identify trends\u0026#34;\u0026#34;\u0026#34; @staticmethod def identify_trends(papers: List[ResearchPaper]) -\u0026gt; List[ResearchTrend]: # Group papers by research areas area_papers = defaultdict(list) for paper in papers: for area in paper.research_areas: area_papers[area].append(paper) messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze these research papers and identify emerging trends: Papers by Research Area: {json.dumps({area: [asdict(p) for p in papers] for area, papers in area_papers.items()}, indent=2)} For each trend, identify: 1. Core topic and theme 2. Key emerging keywords 3. Most influential papers 4. Growth trajectory 5. Potential impact Focus on: - Novel research directions - Emerging methodologies - Cross-disciplinary connections - Technology applications \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Process trends (simplified - would parse LLM response in real implementation) trends = [] for area, area_paper_list in area_papers.items(): if len(area_paper_list) \u0026gt;= 3: # Minimum papers to identify trend recent_papers = sorted( area_paper_list, key=lambda p: p.publication_date, reverse=True )[:3] trend = ResearchTrend( topic=area, emerging_keywords=list(set( kw for p in recent_papers for kw in p.keywords )), key_papers=[p.title for p in recent_papers], growth_rate=0.5, # Would calculate from citation patterns relevance_score=0.8, # Would calculate based on analysis first_observed=min(p.publication_date for p in area_paper_list), last_updated=max(p.publication_date for p in area_paper_list) ) trends.append(trend) return trends class InsightGenerator: \u0026#34;\u0026#34;\u0026#34;Generates insights from identified trends\u0026#34;\u0026#34;\u0026#34; @staticmethod def generate_insights( trends: List[ResearchTrend], papers: Dict[str, ResearchPaper] ) -\u0026gt; List[Insight]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Generate research insights based on these trends: Research Trends: {json.dumps([asdict(t) for t in trends], indent=2)} Supporting Papers: {json.dumps({k: asdict(v) for k, v in papers.items()}, indent=2)} For each insight: 1. Describe the key finding 2. Provide supporting evidence 3. Assess potential impact 4. Estimate confidence level Consider: - Cross-trend patterns - Unexpected connections - Research gaps - Future implications \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Generate insights (simplified) insights = [] for trend in trends: insight = Insight( trend_id=trend.topic, description=f\u0026#34;Emerging trend in {trend.topic}\u0026#34;, supporting_evidence=trend.key_papers, potential_impact=\u0026#34;HIGH\u0026#34; if trend.growth_rate \u0026gt; 0.7 else \u0026#34;MEDIUM\u0026#34;, confidence_score=trend.relevance_score, timestamp=datetime.now().isoformat() ) insights.append(insight) return insights class PatternMatcher: \u0026#34;\u0026#34;\u0026#34;Identifies patterns and connections across research areas\u0026#34;\u0026#34;\u0026#34; @staticmethod def find_patterns( trends: List[ResearchTrend], insights: List[Insight] ) -\u0026gt; Dict: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Identify patterns and connections across research trends: Trends: {json.dumps([asdict(t) for t in trends], indent=2)} Insights: {json.dumps([asdict(i) for i in insights], indent=2)} Look for: 1. Common themes across areas 2. Complementary research directions 3. Technology convergence 4. Methodology patterns Highlight: - Strong connections - Research opportunities - Potential collaborations \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Analyze patterns (simplified) patterns = { \u0026#34;theme_clusters\u0026#34;: defaultdict(list), \u0026#34;methodology_patterns\u0026#34;: [], \u0026#34;research_opportunities\u0026#34;: [] } # Group related trends for trend in trends: for keyword in trend.emerging_keywords: patterns[\u0026#34;theme_clusters\u0026#34;][keyword].append(trend.topic) return patterns def analyze_trends(state: ResearchState) -\u0026gt; ResearchState: \u0026#34;\u0026#34;\u0026#34; Identify and analyze research trends \u0026#34;\u0026#34;\u0026#34; # Convert papers to objects papers = [ ResearchPaper(**paper_data) for paper_data in state[\u0026#34;papers\u0026#34;].values() ] # Identify trends analyzer = TrendAnalyzer() trends = analyzer.identify_trends(papers) # Store trends state[\u0026#34;identified_trends\u0026#34;] = { trend.topic: asdict(trend) for trend in trends } state[\u0026#34;next_action\u0026#34;] = \u0026#34;GENERATE_INSIGHTS\u0026#34; return state def generate_insights(state: ResearchState) -\u0026gt; ResearchState: \u0026#34;\u0026#34;\u0026#34; Generate insights from identified trends \u0026#34;\u0026#34;\u0026#34; # Convert data structures trends = [ ResearchTrend(**trend_data) for trend_data in state[\u0026#34;identified_trends\u0026#34;].values() ] papers = { k: ResearchPaper(**v) for k, v in state[\u0026#34;papers\u0026#34;].items() } # Generate insights generator = InsightGenerator() insights = generator.generate_insights(trends, papers) # Find patterns matcher = PatternMatcher() patterns = matcher.find_patterns(trends, insights) # Update state state[\u0026#34;insights\u0026#34;] = [asdict(insight) for insight in insights] state[\u0026#34;analysis_results\u0026#34;] = patterns state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: ResearchState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Route to the next step based on the current state\u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(ResearchState) # Add nodes workflow.add_node(\u0026#34;analyze\u0026#34;, analyze_trends) workflow.add_node(\u0026#34;insights\u0026#34;, generate_insights) # Add edges workflow.add_edge(\u0026#34;analyze\u0026#34;, router) workflow.add_edge(\u0026#34;insights\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;analyze\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;analyze\u0026#34;, router, { \u0026#34;GENERATE_INSIGHTS\u0026#34;: \u0026#34;insights\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;insights\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state with example papers initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;papers\u0026#34;: { \u0026#34;paper1\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Deep Learning in Medical Imaging\u0026#34;, \u0026#34;authors\u0026#34;: [\u0026#34;Smith, J.\u0026#34;, \u0026#34;Jones, K.\u0026#34;], \u0026#34;abstract\u0026#34;: \u0026#34;This paper explores applications of deep learning...\u0026#34;, \u0026#34;keywords\u0026#34;: [\u0026#34;deep learning\u0026#34;, \u0026#34;medical imaging\u0026#34;, \u0026#34;AI\u0026#34;], \u0026#34;publication_date\u0026#34;: \u0026#34;2024-01-15\u0026#34;, \u0026#34;journal\u0026#34;: \u0026#34;AI in Medicine\u0026#34;, \u0026#34;citations\u0026#34;: 10, \u0026#34;research_areas\u0026#34;: [\u0026#34;AI\u0026#34;, \u0026#34;Healthcare\u0026#34;] }, \u0026#34;paper2\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Advances in Quantum Computing\u0026#34;, \u0026#34;authors\u0026#34;: [\u0026#34;Brown, R.\u0026#34;, \u0026#34;Lee, M.\u0026#34;], \u0026#34;abstract\u0026#34;: \u0026#34;Recent developments in quantum computing...\u0026#34;, \u0026#34;keywords\u0026#34;: [\u0026#34;quantum computing\u0026#34;, \u0026#34;qubits\u0026#34;, \u0026#34;algorithms\u0026#34;], \u0026#34;publication_date\u0026#34;: \u0026#34;2024-01-20\u0026#34;, \u0026#34;journal\u0026#34;: \u0026#34;Quantum Computing Review\u0026#34;, \u0026#34;citations\u0026#34;: 15, \u0026#34;research_areas\u0026#34;: [\u0026#34;Quantum Computing\u0026#34;, \u0026#34;Computer Science\u0026#34;] } }, \u0026#34;identified_trends\u0026#34;: {}, \u0026#34;insights\u0026#34;: [], \u0026#34;research_focus\u0026#34;: [\u0026#34;AI\u0026#34;, \u0026#34;Quantum Computing\u0026#34;, \u0026#34;Healthcare\u0026#34;], \u0026#34;analysis_results\u0026#34;: None, \u0026#34;next_action\u0026#34;: \u0026#34;ANALYZE\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 13. ระบบจัดการขั้นตอนการทำงานแบบปรับตัวได้ (Adaptive Workflow Orchestration) รูปแบบนี้ช่วยให้ระบบปรับเปลี่ยนการทำงานตามสถานการณ์ได้อย่างยืดหยุ่น โดย:\nติดตามการเปลี่ยนแปลงของสภาพแวดล้อม ปรับลำดับความสำคัญของงาน จัดสรรทรัพยากรใหม่ตามความจำเป็น ระบบบริหารจัดการโรงพยาบาลที่ปรับการจัดสรรทรัพยากรตามจำนวนผู้ป่วยที่เข้ามาเป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Adaptive Workflow Orchestration from typing import Dict, List, TypedDict, Optional from datetime import datetime, timedelta import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter from enum import Enum import os # Define data structures class ResourceType(str, Enum): DOCTOR = \u0026#34;DOCTOR\u0026#34; NURSE = \u0026#34;NURSE\u0026#34; BED = \u0026#34;BED\u0026#34; EQUIPMENT = \u0026#34;EQUIPMENT\u0026#34; ICU = \u0026#34;ICU\u0026#34; EMERGENCY = \u0026#34;EMERGENCY\u0026#34; class PatientPriority(str, Enum): CRITICAL = \u0026#34;CRITICAL\u0026#34; HIGH = \u0026#34;HIGH\u0026#34; MEDIUM = \u0026#34;MEDIUM\u0026#34; LOW = \u0026#34;LOW\u0026#34; @dataclass class Resource: id: str type: ResourceType department: str status: str # AVAILABLE, BUSY, MAINTENANCE current_assignment: Optional[str] capacity: float # 0-1 for utilization skills: List[str] @dataclass class Department: name: str current_load: float # 0-1 for utilization patient_count: int resources: Dict[ResourceType, List[str]] wait_time: int # minutes status: str # NORMAL, HIGH_LOAD, CRITICAL @dataclass class Patient: id: str priority: PatientPriority department: str required_resources: List[ResourceType] arrival_time: str status: str # WAITING, IN_TREATMENT, DISCHARGED estimated_duration: int # minutes @dataclass class ResourceAllocation: patient_id: str resource_ids: List[str] department: str start_time: str duration: int priority: PatientPriority class HospitalState(TypedDict): messages: List[str] departments: Dict[str, Dict] resources: Dict[str, Dict] patients: Dict[str, Dict] allocations: Dict[str, Dict] metrics: Dict[str, float] next_action: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.2, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, \u0026#34;X-Title\u0026#34;: \u0026#34;Hospital Resource Manager\u0026#34; } ) class LoadAnalyzer: \u0026#34;\u0026#34;\u0026#34;Analyzes department loads and resource utilization\u0026#34;\u0026#34;\u0026#34; @staticmethod def analyze_department_loads( departments: Dict[str, Department], patients: Dict[str, Patient] ) -\u0026gt; Dict[str, float]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze hospital department loads: Departments: {json.dumps({k: asdict(v) for k, v in departments.items()}, indent=2)} Current Patients: {json.dumps({k: asdict(v) for k, v in patients.items()}, indent=2)} Consider: 1. Current patient count vs capacity 2. Patient priorities and types 3. Wait times 4. Resource utilization Provide load analysis and recommendations. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Calculate loads (simplified) loads = {} for dept_name, dept in departments.items(): dept_patients = sum(1 for p in patients.values() if p.department == dept_name) critical_patients = sum( 1 for p in patients.values() if p.department == dept_name and p.priority == PatientPriority.CRITICAL ) # Calculate load score (0-1) base_load = dept_patients / 20 # Assuming 20 patients is max capacity critical_factor = critical_patients * 0.1 # Extra 10% load per critical patient wait_time_factor = min(dept.wait_time / 120, 0.5) # Max 50% impact from wait time loads[dept_name] = min(base_load + critical_factor + wait_time_factor, 1.0) return loads class ResourceOptimizer: \u0026#34;\u0026#34;\u0026#34;Optimizes resource allocation based on loads and priorities\u0026#34;\u0026#34;\u0026#34; @staticmethod def optimize_resources( departments: Dict[str, Department], resources: Dict[str, Resource], patients: Dict[str, Patient], current_loads: Dict[str, float] ) -\u0026gt; List[ResourceAllocation]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Optimize resource allocation based on current situation: Department Loads: {json.dumps(current_loads, indent=2)} Available Resources: {json.dumps({k: asdict(v) for k, v in resources.items()}, indent=2)} Waiting Patients: {json.dumps({k: asdict(v) for k, v in patients.items() if v.status == \u0026#34;WAITING\u0026#34;}, indent=2)} Consider: 1. Patient priorities 2. Department loads 3. Resource capabilities 4. Wait times 5. Resource utilization balance Provide optimal resource allocation plan. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Create allocations (simplified) allocations = [] waiting_patients = {k: p for k, p in patients.items() if p.status == \u0026#34;WAITING\u0026#34;} available_resources = {k: r for k, r in resources.items() if r.status == \u0026#34;AVAILABLE\u0026#34;} # Prioritize patients by severity and wait time sorted_patients = sorted( waiting_patients.values(), key=lambda p: ( PatientPriority[p.priority].value, datetime.fromisoformat(p.arrival_time) ) ) for patient in sorted_patients: # Find available required resources needed_resources = [] for resource_type in patient.required_resources: matching_resources = [ r for r in available_resources.values() if r.type == resource_type and r.department == patient.department ] if matching_resources: needed_resources.append(matching_resources[0].id) del available_resources[matching_resources[0].id] if len(needed_resources) == len(patient.required_resources): allocation = ResourceAllocation( patient_id=patient.id, resource_ids=needed_resources, department=patient.department, start_time=datetime.now().isoformat(), duration=patient.estimated_duration, priority=patient.priority ) allocations.append(allocation) return allocations class WorkflowAdjuster: \u0026#34;\u0026#34;\u0026#34;Adjusts workflows based on current situation\u0026#34;\u0026#34;\u0026#34; @staticmethod def adjust_workflows( departments: Dict[str, Department], loads: Dict[str, float], resources: Dict[str, Resource] ) -\u0026gt; Dict[str, List[str]]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Recommend workflow adjustments based on current situation: Department Status: {json.dumps({k: asdict(v) for k, v in departments.items()}, indent=2)} Department Loads: {json.dumps(loads, indent=2)} Available Resources: {json.dumps({k: asdict(v) for k, v in resources.items()}, indent=2)} Consider: 1. Load balancing opportunities 2. Resource reallocation needs 3. Process optimization 4. Emergency protocols Provide specific workflow adjustment recommendations. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Generate adjustments (simplified) adjustments = defaultdict(list) for dept_name, load in loads.items(): if load \u0026gt; 0.8: # High load adjustments[dept_name].extend([ \u0026#34;ACTIVATE_EMERGENCY_PROTOCOL\u0026#34;, \u0026#34;REQUEST_ADDITIONAL_STAFF\u0026#34;, \u0026#34;EXPEDITE_DISCHARGES\u0026#34; ]) elif load \u0026gt; 0.6: # Moderate load adjustments[dept_name].extend([ \u0026#34;OPTIMIZE_RESOURCE_ALLOCATION\u0026#34;, \u0026#34;REVIEW_WAIT_TIMES\u0026#34; ]) return adjustments def analyze_situation(state: HospitalState) -\u0026gt; HospitalState: \u0026#34;\u0026#34;\u0026#34; Analyze current hospital situation \u0026#34;\u0026#34;\u0026#34; # Convert data structures departments = { k: Department(**d) for k, d in state[\u0026#34;departments\u0026#34;].items() } patients = { k: Patient(**p) for k, p in state[\u0026#34;patients\u0026#34;].items() } # Analyze loads analyzer = LoadAnalyzer() loads = analyzer.analyze_department_loads(departments, patients) # Store analysis results state[\u0026#34;metrics\u0026#34;][\u0026#34;department_loads\u0026#34;] = loads state[\u0026#34;next_action\u0026#34;] = \u0026#34;OPTIMIZE\u0026#34; return state def optimize_resources(state: HospitalState) -\u0026gt; HospitalState: \u0026#34;\u0026#34;\u0026#34; Optimize resource allocation \u0026#34;\u0026#34;\u0026#34; # Convert data structures departments = { k: Department(**d) for k, d in state[\u0026#34;departments\u0026#34;].items() } resources = { k: Resource(**r) for k, r in state[\u0026#34;resources\u0026#34;].items() } patients = { k: Patient(**p) for k, p in state[\u0026#34;patients\u0026#34;].items() } # Optimize resources optimizer = ResourceOptimizer() allocations = optimizer.optimize_resources( departments, resources, patients, state[\u0026#34;metrics\u0026#34;][\u0026#34;department_loads\u0026#34;] ) # Update allocations state[\u0026#34;allocations\u0026#34;] = { f\u0026#34;alloc_{i}\u0026#34;: asdict(alloc) for i, alloc in enumerate(allocations) } state[\u0026#34;next_action\u0026#34;] = \u0026#34;ADJUST\u0026#34; return state def adjust_workflows(state: HospitalState) -\u0026gt; HospitalState: \u0026#34;\u0026#34;\u0026#34; Adjust workflows based on current situation \u0026#34;\u0026#34;\u0026#34; # Convert data structures departments = { k: Department(**d) for k, d in state[\u0026#34;departments\u0026#34;].items() } resources = { k: Resource(**r) for k, r in state[\u0026#34;resources\u0026#34;].items() } # Adjust workflows adjuster = WorkflowAdjuster() adjustments = adjuster.adjust_workflows( departments, state[\u0026#34;metrics\u0026#34;][\u0026#34;department_loads\u0026#34;], resources ) # Store adjustments state[\u0026#34;metrics\u0026#34;][\u0026#34;workflow_adjustments\u0026#34;] = adjustments state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: HospitalState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Route to the next step based on the current state\u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(HospitalState) # Add nodes workflow.add_node(\u0026#34;analyze\u0026#34;, analyze_situation) workflow.add_node(\u0026#34;optimize\u0026#34;, optimize_resources) workflow.add_node(\u0026#34;adjust\u0026#34;, adjust_workflows) # Add edges workflow.add_edge(\u0026#34;analyze\u0026#34;, router) workflow.add_edge(\u0026#34;optimize\u0026#34;, router) workflow.add_edge(\u0026#34;adjust\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;analyze\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;analyze\u0026#34;, router, { \u0026#34;OPTIMIZE\u0026#34;: \u0026#34;optimize\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;optimize\u0026#34;, router, { \u0026#34;ADJUST\u0026#34;: \u0026#34;adjust\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;adjust\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;departments\u0026#34;: { \u0026#34;emergency\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Emergency\u0026#34;, \u0026#34;current_load\u0026#34;: 0.7, \u0026#34;patient_count\u0026#34;: 15, \u0026#34;resources\u0026#34;: { \u0026#34;DOCTOR\u0026#34;: [\u0026#34;doc1\u0026#34;, \u0026#34;doc2\u0026#34;], \u0026#34;NURSE\u0026#34;: [\u0026#34;nurse1\u0026#34;, \u0026#34;nurse2\u0026#34;], \u0026#34;BED\u0026#34;: [\u0026#34;bed1\u0026#34;, \u0026#34;bed2\u0026#34;] }, \u0026#34;wait_time\u0026#34;: 45, \u0026#34;status\u0026#34;: \u0026#34;HIGH_LOAD\u0026#34; } }, \u0026#34;resources\u0026#34;: { \u0026#34;doc1\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;doc1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;DOCTOR\u0026#34;, \u0026#34;department\u0026#34;: \u0026#34;emergency\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;BUSY\u0026#34;, \u0026#34;current_assignment\u0026#34;: \u0026#34;patient1\u0026#34;, \u0026#34;capacity\u0026#34;: 0.8, \u0026#34;skills\u0026#34;: [\u0026#34;emergency\u0026#34;, \u0026#34;general\u0026#34;] } }, \u0026#34;patients\u0026#34;: { \u0026#34;patient1\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;patient1\u0026#34;, \u0026#34;priority\u0026#34;: \u0026#34;HIGH\u0026#34;, \u0026#34;department\u0026#34;: \u0026#34;emergency\u0026#34;, \u0026#34;required_resources\u0026#34;: [\u0026#34;DOCTOR\u0026#34;, \u0026#34;BED\u0026#34;], \u0026#34;arrival_time\u0026#34;: \u0026#34;2024-02-06T10:00:00\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;IN_TREATMENT\u0026#34;, \u0026#34;estimated_duration\u0026#34;: 60 } }, \u0026#34;allocations\u0026#34;: {}, \u0026#34;metrics\u0026#34;: {}, \u0026#34;next_action\u0026#34;: \u0026#34;ANALYZE\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 14. ระบบซ่อมแซมตัวเอง (Self-Healing Systems) รูปแบบนี้น่าสนใจเพราะช่วยให้ระบบสามารถรักษาเสถียรภาพการทำงานได้ด้วยตัวเอง โดย:\nตรวจจับปัญหาหรือข้อผิดพลาด วิเคราะห์สาเหตุของปัญหา ดำเนินการแก้ไขโดยอัตโนมัติ ระบบจัดการคลาวด์ที่สามารถตรวจจับและแก้ไขปัญหาเซิร์ฟเวอร์ที่ทำงานผิดปกติเป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Self-Healing Systems from typing import Dict, List, TypedDict, Optional from datetime import datetime, timedelta import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter from enum import Enum import os # Define data structures class ServerStatus(str, Enum): HEALTHY = \u0026#34;HEALTHY\u0026#34; WARNING = \u0026#34;WARNING\u0026#34; CRITICAL = \u0026#34;CRITICAL\u0026#34; MAINTENANCE = \u0026#34;MAINTENANCE\u0026#34; OFFLINE = \u0026#34;OFFLINE\u0026#34; class IssueType(str, Enum): CPU_OVERLOAD = \u0026#34;CPU_OVERLOAD\u0026#34; MEMORY_LEAK = \u0026#34;MEMORY_LEAK\u0026#34; DISK_FULL = \u0026#34;DISK_FULL\u0026#34; NETWORK_LATENCY = \u0026#34;NETWORK_LATENCY\u0026#34; SERVICE_DOWN = \u0026#34;SERVICE_DOWN\u0026#34; DATABASE_SLOW = \u0026#34;DATABASE_SLOW\u0026#34; @dataclass class ServerMetrics: cpu_usage: float memory_usage: float disk_usage: float network_latency: float response_time: float error_rate: float uptime: float timestamp: str @dataclass class Server: id: str name: str status: ServerStatus role: str # web, database, cache, etc. current_metrics: ServerMetrics historical_metrics: List[ServerMetrics] active_issues: List[str] maintenance_history: List[Dict] @dataclass class Issue: id: str server_id: str type: IssueType severity: float # 0-1 detected_time: str description: str root_cause: Optional[str] resolution_steps: List[str] status: str # DETECTED, ANALYZING, RESOLVING, RESOLVED @dataclass class Resolution: issue_id: str server_id: str actions: List[str] expected_impact: Dict[str, float] success_criteria: Dict[str, float] rollback_plan: List[str] class CloudState(TypedDict): messages: List[str] servers: Dict[str, Dict] issues: Dict[str, Dict] resolutions: Dict[str, Dict] system_health: Dict[str, float] next_action: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.2, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, \u0026#34;X-Title\u0026#34;: \u0026#34;Cloud Health Monitor\u0026#34; } ) class HealthMonitor: \u0026#34;\u0026#34;\u0026#34;Monitors server health and detects issues\u0026#34;\u0026#34;\u0026#34; @staticmethod def analyze_metrics(server: Server) -\u0026gt; List[Issue]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze these server metrics for potential issues: Server Info: {json.dumps(asdict(server), indent=2)} Key Metrics: - CPU Usage: {server.current_metrics.cpu_usage}% - Memory Usage: {server.current_metrics.memory_usage}% - Disk Usage: {server.current_metrics.disk_usage}% - Network Latency: {server.current_metrics.network_latency}ms - Error Rate: {server.current_metrics.error_rate}% Historical Metrics: {json.dumps([asdict(m) for m in server.historical_metrics[-5:]], indent=2)} Identify: 1. Performance issues 2. Resource constraints 3. Service degradation 4. Anomalous behavior For each issue provide: 1. Issue type 2. Severity 3. Potential root causes 4. Initial resolution steps \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Detect issues (simplified) issues = [] metrics = server.current_metrics # Check CPU if metrics.cpu_usage \u0026gt; 90: issues.append(Issue( id=f\u0026#34;issue_{len(issues)}\u0026#34;, server_id=server.id, type=IssueType.CPU_OVERLOAD, severity=min((metrics.cpu_usage - 90) / 10, 1.0), detected_time=datetime.now().isoformat(), description=\u0026#34;CPU usage critically high\u0026#34;, root_cause=None, resolution_steps=[\u0026#34;Scale up CPU\u0026#34;, \u0026#34;Check runaway processes\u0026#34;], status=\u0026#34;DETECTED\u0026#34; )) # Check Memory if metrics.memory_usage \u0026gt; 85: issues.append(Issue( id=f\u0026#34;issue_{len(issues)}\u0026#34;, server_id=server.id, type=IssueType.MEMORY_LEAK, severity=min((metrics.memory_usage - 85) / 15, 1.0), detected_time=datetime.now().isoformat(), description=\u0026#34;Memory usage abnormally high\u0026#34;, root_cause=None, resolution_steps=[\u0026#34;Analyze memory dumps\u0026#34;, \u0026#34;Check memory leaks\u0026#34;], status=\u0026#34;DETECTED\u0026#34; )) return issues class DiagnosticEngine: \u0026#34;\u0026#34;\u0026#34;Analyzes issues and determines root causes\u0026#34;\u0026#34;\u0026#34; @staticmethod def analyze_issue( issue: Issue, server: Server, system_health: Dict[str, float] ) -\u0026gt; Issue: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze this server issue and determine root cause: Issue Details: {json.dumps(asdict(issue), indent=2)} Server Information: {json.dumps(asdict(server), indent=2)} System Health Context: {json.dumps(system_health, indent=2)} Provide: 1. Detailed root cause analysis 2. Impact assessment 3. Recommended resolution steps 4. Risk evaluation \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Update issue with analysis (simplified) if issue.type == IssueType.CPU_OVERLOAD: issue.root_cause = \u0026#34;High application load causing CPU spikes\u0026#34; issue.resolution_steps.extend([ \u0026#34;Enable auto-scaling\u0026#34;, \u0026#34;Optimize application code\u0026#34;, \u0026#34;Add load balancing\u0026#34; ]) elif issue.type == IssueType.MEMORY_LEAK: issue.root_cause = \u0026#34;Application memory leak detected\u0026#34; issue.resolution_steps.extend([ \u0026#34;Restart problematic services\u0026#34;, \u0026#34;Apply memory leak patches\u0026#34;, \u0026#34;Monitor memory patterns\u0026#34; ]) issue.status = \u0026#34;ANALYZING\u0026#34; return issue class RepairExecutor: \u0026#34;\u0026#34;\u0026#34;Executes repair actions and monitors results\u0026#34;\u0026#34;\u0026#34; @staticmethod def create_resolution_plan( issue: Issue, server: Server ) -\u0026gt; Resolution: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Create a resolution plan for this issue: Issue: {json.dumps(asdict(issue), indent=2)} Server: {json.dumps(asdict(server), indent=2)} Provide: 1. Detailed action steps 2. Success criteria 3. Expected impacts 4. Rollback procedures 5. Risk mitigation strategies \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Create resolution plan (simplified) return Resolution( issue_id=issue.id, server_id=server.id, actions=issue.resolution_steps, expected_impact={ \u0026#34;cpu_usage\u0026#34;: -20 if issue.type == IssueType.CPU_OVERLOAD else 0, \u0026#34;memory_usage\u0026#34;: -30 if issue.type == IssueType.MEMORY_LEAK else 0, \u0026#34;response_time\u0026#34;: -50 }, success_criteria={ \u0026#34;cpu_usage\u0026#34;: 70, \u0026#34;memory_usage\u0026#34;: 70, \u0026#34;error_rate\u0026#34;: 1 }, rollback_plan=[ \u0026#34;Stop new resolution actions\u0026#34;, \u0026#34;Restore from last known good configuration\u0026#34;, \u0026#34;Reset affected services\u0026#34; ] ) def monitor_health(state: CloudState) -\u0026gt; CloudState: \u0026#34;\u0026#34;\u0026#34; Monitor server health and detect issues \u0026#34;\u0026#34;\u0026#34; # Convert data structures servers = { k: Server(**s) for k, s in state[\u0026#34;servers\u0026#34;].items() } # Check each server monitor = HealthMonitor() new_issues = [] for server in servers.values(): server_issues = monitor.analyze_metrics(server) new_issues.extend(server_issues) # Update state for issue in new_issues: state[\u0026#34;issues\u0026#34;][issue.id] = asdict(issue) # Calculate system health total_servers = len(servers) healthy_servers = sum(1 for s in servers.values() if s.status == ServerStatus.HEALTHY) state[\u0026#34;system_health\u0026#34;] = { \u0026#34;overall_health\u0026#34;: healthy_servers / total_servers, \u0026#34;total_issues\u0026#34;: len(state[\u0026#34;issues\u0026#34;]), \u0026#34;critical_issues\u0026#34;: sum(1 for i in state[\u0026#34;issues\u0026#34;].values() if float(i[\u0026#34;severity\u0026#34;]) \u0026gt; 0.7) } state[\u0026#34;next_action\u0026#34;] = \u0026#34;DIAGNOSE\u0026#34; if new_issues else \u0026#34;END\u0026#34; return state def diagnose_issues(state: CloudState) -\u0026gt; CloudState: \u0026#34;\u0026#34;\u0026#34; Analyze issues and determine root causes \u0026#34;\u0026#34;\u0026#34; # Convert data structures issues = { k: Issue(**i) for k, i in state[\u0026#34;issues\u0026#34;].items() if i[\u0026#34;status\u0026#34;] == \u0026#34;DETECTED\u0026#34; } servers = { k: Server(**s) for k, s in state[\u0026#34;servers\u0026#34;].items() } # Analyze each issue engine = DiagnosticEngine() for issue_id, issue in issues.items(): server = servers[issue.server_id] updated_issue = engine.analyze_issue( issue, server, state[\u0026#34;system_health\u0026#34;] ) state[\u0026#34;issues\u0026#34;][issue_id] = asdict(updated_issue) state[\u0026#34;next_action\u0026#34;] = \u0026#34;REPAIR\u0026#34; if issues else \u0026#34;END\u0026#34; return state def execute_repairs(state: CloudState) -\u0026gt; CloudState: \u0026#34;\u0026#34;\u0026#34; Execute repair actions for analyzed issues \u0026#34;\u0026#34;\u0026#34; # Convert data structures issues = { k: Issue(**i) for k, i in state[\u0026#34;issues\u0026#34;].items() if i[\u0026#34;status\u0026#34;] == \u0026#34;ANALYZING\u0026#34; } servers = { k: Server(**s) for k, s in state[\u0026#34;servers\u0026#34;].items() } # Create and execute repair plans executor = RepairExecutor() for issue_id, issue in issues.items(): server = servers[issue.server_id] resolution = executor.create_resolution_plan(issue, server) state[\u0026#34;resolutions\u0026#34;][issue_id] = asdict(resolution) # Update issue status issue.status = \u0026#34;RESOLVING\u0026#34; state[\u0026#34;issues\u0026#34;][issue_id] = asdict(issue) state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: CloudState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Route to the next step based on the current state\u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(CloudState) # Add nodes workflow.add_node(\u0026#34;monitor\u0026#34;, monitor_health) workflow.add_node(\u0026#34;diagnose\u0026#34;, diagnose_issues) workflow.add_node(\u0026#34;repair\u0026#34;, execute_repairs) # Add edges workflow.add_edge(\u0026#34;monitor\u0026#34;, router) workflow.add_edge(\u0026#34;diagnose\u0026#34;, router) workflow.add_edge(\u0026#34;repair\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;monitor\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;monitor\u0026#34;, router, { \u0026#34;DIAGNOSE\u0026#34;: \u0026#34;diagnose\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;diagnose\u0026#34;, router, { \u0026#34;REPAIR\u0026#34;: \u0026#34;repair\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;repair\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;servers\u0026#34;: { \u0026#34;web1\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;web1\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Web Server 1\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;WARNING\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;current_metrics\u0026#34;: { \u0026#34;cpu_usage\u0026#34;: 95.0, \u0026#34;memory_usage\u0026#34;: 87.0, \u0026#34;disk_usage\u0026#34;: 75.0, \u0026#34;network_latency\u0026#34;: 150.0, \u0026#34;response_time\u0026#34;: 2.5, \u0026#34;error_rate\u0026#34;: 2.0, \u0026#34;uptime\u0026#34;: 15.5, \u0026#34;timestamp\u0026#34;: datetime.now().isoformat() }, \u0026#34;historical_metrics\u0026#34;: [], \u0026#34;active_issues\u0026#34;: [], \u0026#34;maintenance_history\u0026#34;: [] } }, \u0026#34;issues\u0026#34;: {}, \u0026#34;resolutions\u0026#34;: {}, \u0026#34;system_health\u0026#34;: {}, \u0026#34;next_action\u0026#34;: \u0026#34;MONITOR\u0026#34; } # Run the workflow app = workflow.compile() for output in app.stream(initial_state): print(\u0026#34;\\nStep Output:\u0026#34;) print(json.dumps(output, indent=2)) 15. ระบบตัดสินใจตามหลักจริยธรรม (Ethical Decision-Making) รูปแบบนี้มีความสำคัญมากในยุคที่ AI มีบทบาทในการตัดสินใจที่ส่งผลกระทบต่อชีวิตมนุษย์ โดย:\nพิจารณาผลกระทบทางจริยธรรม ชั่งน้ำหนักระหว่างประโยชน์และความเสี่ยง ตัดสินใจบนพื้นฐานของค่านิยมและบรรทัดฐานของสังคม รถยนต์ไร้คนขับที่ต้องตัดสินใจในสถานการณ์ฉุกเฉินโดยคำนึงถึงความปลอดภัยของทุกฝ่ายเป็นตัวอย่างที่ดีของการใช้งานรูปแบบนี้\nตัวอย่าง Ethical Decision-Making from typing import Dict, List, TypedDict, Optional, Tuple from datetime import datetime import json from dataclasses import dataclass, asdict from langgraph.graph import StateGraph, END from langchain_core.messages import HumanMessage, AIMessage from langchain.chat_models import ChatOpenRouter from enum import Enum import os # Define data structures class EntityType(str, Enum): VEHICLE = \u0026#34;VEHICLE\u0026#34; PEDESTRIAN = \u0026#34;PEDESTRIAN\u0026#34; CYCLIST = \u0026#34;CYCLIST\u0026#34; OBSTACLE = \u0026#34;OBSTACLE\u0026#34; TRAFFIC_LIGHT = \u0026#34;TRAFFIC_LIGHT\u0026#34; class RiskLevel(str, Enum): LOW = \u0026#34;LOW\u0026#34; MEDIUM = \u0026#34;MEDIUM\u0026#34; HIGH = \u0026#34;HIGH\u0026#34; CRITICAL = \u0026#34;CRITICAL\u0026#34; @dataclass class Position: x: float y: float speed: float direction: float @dataclass class Entity: id: str type: EntityType position: Position size: Tuple[float, float] # width, height velocity: Tuple[float, float] # vx, vy priority: int # 1 (highest) to 5 (lowest) vulnerability: float # 0-1 protected_status: bool # True for children, elderly, etc. @dataclass class Scenario: timestamp: str vehicle_state: Entity entities: List[Entity] road_conditions: Dict[str, float] # friction, visibility, etc. weather_conditions: Dict[str, str] time_to_impact: float possible_actions: List[str] @dataclass class EthicalPrinciple: id: str name: str description: str weight: float conditions: List[str] priority: int @dataclass class Decision: action: str reasoning: List[str] ethical_scores: Dict[str, float] risk_assessment: Dict[str, float] consequences: List[Dict] confidence: float class VehicleState(TypedDict): messages: List[str] current_scenario: Dict ethical_principles: Dict[str, Dict] available_actions: List[str] risk_assessments: Dict[str, Dict] decision: Optional[Dict] next_action: str # Initialize OpenRouter LLM llm = ChatOpenRouter( api_key=os.environ[\u0026#34;OPENROUTER_API_KEY\u0026#34;], model=\u0026#34;openai/gpt-4-turbo\u0026#34;, temperature=0.2, headers={ \u0026#34;HTTP-Referer\u0026#34;: \u0026#34;http://localhost:8000\u0026#34;, \u0026#34;X-Title\u0026#34;: \u0026#34;Ethical Vehicle AI\u0026#34; } ) # Define ethical principles ETHICAL_PRINCIPLES = { \u0026#34;minimize_harm\u0026#34;: EthicalPrinciple( id=\u0026#34;minimize_harm\u0026#34;, name=\u0026#34;Minimize Harm\u0026#34;, description=\u0026#34;Minimize overall harm to all entities involved\u0026#34;, weight=1.0, conditions=[\u0026#34;Consider vulnerability\u0026#34;, \u0026#34;Protect human life\u0026#34;], priority=1 ), \u0026#34;protect_vulnerable\u0026#34;: EthicalPrinciple( id=\u0026#34;protect_vulnerable\u0026#34;, name=\u0026#34;Protect Vulnerable\u0026#34;, description=\u0026#34;Prioritize protection of vulnerable individuals\u0026#34;, weight=0.9, conditions=[\u0026#34;Children\u0026#34;, \u0026#34;Elderly\u0026#34;, \u0026#34;Disabled\u0026#34;], priority=2 ), \u0026#34;fairness\u0026#34;: EthicalPrinciple( id=\u0026#34;fairness\u0026#34;, name=\u0026#34;Fairness\u0026#34;, description=\u0026#34;Ensure fair treatment regardless of characteristics\u0026#34;, weight=0.8, conditions=[\u0026#34;No discrimination\u0026#34;, \u0026#34;Equal consideration\u0026#34;], priority=3 ) } class RiskAnalyzer: \u0026#34;\u0026#34;\u0026#34;Analyzes risks for different actions\u0026#34;\u0026#34;\u0026#34; @staticmethod def calculate_collision_risk( vehicle: Entity, entity: Entity, time_to_impact: float ) -\u0026gt; float: # Simple risk calculation based on time to impact and relative velocity relative_velocity = ( (vehicle.velocity[0] - entity.velocity[0])**2 + (vehicle.velocity[1] - entity.velocity[1])**2 )**0.5 distance = ( (vehicle.position.x - entity.position.x)**2 + (vehicle.position.y - entity.position.y)**2 )**0.5 # Higher risk for closer entities and higher relative velocities risk = (relative_velocity * entity.vulnerability) / (distance + 1) return min(risk, 1.0) @staticmethod def analyze_action_risks( scenario: Scenario, action: str ) -\u0026gt; Dict[str, float]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Analyze risks for this action in the current scenario: Scenario: {json.dumps(asdict(scenario), indent=2)} Proposed Action: {action} Consider: 1. Collision risks 2. Entity vulnerabilities 3. Environmental factors 4. Time constraints Provide risk assessment for: 1. Immediate safety 2. Secondary effects 3. Long-term consequences \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Calculate risks (simplified) risks = { \u0026#34;collision\u0026#34;: sum( RiskAnalyzer.calculate_collision_risk( scenario.vehicle_state, entity, scenario.time_to_impact ) for entity in scenario.entities ) / len(scenario.entities), \u0026#34;environmental\u0026#34;: sum( v for v in scenario.road_conditions.values() ) / len(scenario.road_conditions), \u0026#34;time_pressure\u0026#34;: 1.0 / (scenario.time_to_impact + 1) } return risks class EthicalEvaluator: \u0026#34;\u0026#34;\u0026#34;Evaluates ethical implications of actions\u0026#34;\u0026#34;\u0026#34; @staticmethod def evaluate_action( action: str, scenario: Scenario, principles: Dict[str, EthicalPrinciple], risks: Dict[str, float] ) -\u0026gt; Dict[str, float]: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Evaluate ethical implications of this action: Action: {action} Scenario: {json.dumps(asdict(scenario), indent=2)} Ethical Principles: {json.dumps({k: asdict(v) for k, v in principles.items()}, indent=2)} Risk Assessment: {json.dumps(risks, indent=2)} Consider: 1. Impact on all entities 2. Adherence to ethical principles 3. Risk-benefit balance 4. Social values and norms Provide scores and explanations for each principle. \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Calculate ethical scores (simplified) scores = {} for principle in principles.values(): if principle.id == \u0026#34;minimize_harm\u0026#34;: scores[principle.id] = 1.0 - max(risks.values()) elif principle.id == \u0026#34;protect_vulnerable\u0026#34;: vulnerable_entities = [ e for e in scenario.entities if e.protected_status ] if vulnerable_entities: avg_risk = sum( RiskAnalyzer.calculate_collision_risk( scenario.vehicle_state, entity, scenario.time_to_impact ) for entity in vulnerable_entities ) / len(vulnerable_entities) scores[principle.id] = 1.0 - avg_risk else: scores[principle.id] = 1.0 elif principle.id == \u0026#34;fairness\u0026#34;: # Check if risks are evenly distributed risk_variance = max(risks.values()) - min(risks.values()) scores[principle.id] = 1.0 - risk_variance return scores class DecisionMaker: \u0026#34;\u0026#34;\u0026#34;Makes final decisions based on ethical evaluation and risks\u0026#34;\u0026#34;\u0026#34; @staticmethod def make_decision( scenario: Scenario, ethical_scores: Dict[str, Dict[str, float]], risk_assessments: Dict[str, Dict[str, float]] ) -\u0026gt; Decision: messages = [ HumanMessage(content=f\u0026#34;\u0026#34;\u0026#34; Make a decision based on ethical evaluation and risks: Scenario: {json.dumps(asdict(scenario), indent=2)} Ethical Scores: {json.dumps(ethical_scores, indent=2)} Risk Assessments: {json.dumps(risk_assessments, indent=2)} Consider: 1. Overall ethical alignment 2. Risk minimization 3. Time constraints 4. Practical feasibility Provide: 1. Chosen action 2. Detailed reasoning 3. Expected consequences 4. Confidence level \u0026#34;\u0026#34;\u0026#34;) ] response = llm.invoke(messages) # Select best action (simplified) action_scores = {} for action in scenario.possible_actions: # Combine ethical scores and risk assessments ethical_score = sum( score * ETHICAL_PRINCIPLES[principle].weight for principle, score in ethical_scores[action].items() ) risk_score = 1.0 - sum(risk_assessments[action].values()) / len(risk_assessments[action]) # Weight ethical considerations more heavily action_scores[action] = (ethical_score * 0.7) + (risk_score * 0.3) best_action = max(action_scores.items(), key=lambda x: x[1])[0] return Decision( action=best_action, reasoning=[ \u0026#34;Highest combined ethical and safety score\u0026#34;, f\u0026#34;Ethical score: {ethical_scores[best_action]}\u0026#34;, f\u0026#34;Risk assessment: {risk_assessments[best_action]}\u0026#34; ], ethical_scores=ethical_scores[best_action], risk_assessment=risk_assessments[best_action], consequences=[ {\u0026#34;type\u0026#34;: \u0026#34;immediate\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Avoid collision\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;secondary\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Minimal disruption\u0026#34;} ], confidence=action_scores[best_action] ) def analyze_risks(state: VehicleState) -\u0026gt; VehicleState: \u0026#34;\u0026#34;\u0026#34; Analyze risks for each possible action \u0026#34;\u0026#34;\u0026#34; # Convert data structures scenario = Scenario(**state[\u0026#34;current_scenario\u0026#34;]) # Analyze risks for each action analyzer = RiskAnalyzer() risk_assessments = {} for action in state[\u0026#34;available_actions\u0026#34;]: risks = analyzer.analyze_action_risks(scenario, action) risk_assessments[action] = risks state[\u0026#34;risk_assessments\u0026#34;] = risk_assessments state[\u0026#34;next_action\u0026#34;] = \u0026#34;EVALUATE\u0026#34; return state def evaluate_ethics(state: VehicleState) -\u0026gt; VehicleState: \u0026#34;\u0026#34;\u0026#34; Evaluate ethical implications of each action \u0026#34;\u0026#34;\u0026#34; # Convert data structures scenario = Scenario(**state[\u0026#34;current_scenario\u0026#34;]) principles = { k: EthicalPrinciple(**p) for k, p in state[\u0026#34;ethical_principles\u0026#34;].items() } # Evaluate each action evaluator = EthicalEvaluator() ethical_scores = {} for action in state[\u0026#34;available_actions\u0026#34;]: scores = evaluator.evaluate_action( action, scenario, principles, state[\u0026#34;risk_assessments\u0026#34;][action] ) ethical_scores[action] = scores state[\u0026#34;ethical_scores\u0026#34;] = ethical_scores state[\u0026#34;next_action\u0026#34;] = \u0026#34;DECIDE\u0026#34; return state def make_decision(state: VehicleState) -\u0026gt; VehicleState: \u0026#34;\u0026#34;\u0026#34; Make final decision based on ethical evaluation and risks \u0026#34;\u0026#34;\u0026#34; # Convert data structures scenario = Scenario(**state[\u0026#34;current_scenario\u0026#34;]) # Make decision decision_maker = DecisionMaker() decision = decision_maker.make_decision( scenario, state[\u0026#34;ethical_scores\u0026#34;], state[\u0026#34;risk_assessments\u0026#34;] ) state[\u0026#34;decision\u0026#34;] = asdict(decision) state[\u0026#34;next_action\u0026#34;] = \u0026#34;END\u0026#34; return state def router(state: VehicleState) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Route to the next step based on the current state\u0026#34;\u0026#34;\u0026#34; return state[\u0026#34;next_action\u0026#34;] # Create the graph workflow = StateGraph(VehicleState) # Add nodes workflow.add_node(\u0026#34;analyze\u0026#34;, analyze_risks) workflow.add_node(\u0026#34;evaluate\u0026#34;, evaluate_ethics) workflow.add_node(\u0026#34;decide\u0026#34;, make_decision) # Add edges workflow.add_edge(\u0026#34;analyze\u0026#34;, router) workflow.add_edge(\u0026#34;evaluate\u0026#34;, router) workflow.add_edge(\u0026#34;decide\u0026#34;, router) # Set entry point workflow.set_entry_point(\u0026#34;analyze\u0026#34;) # Create conditional edges workflow.add_conditional_edges( \u0026#34;analyze\u0026#34;, router, { \u0026#34;EVALUATE\u0026#34;: \u0026#34;evaluate\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;evaluate\u0026#34;, router, { \u0026#34;DECIDE\u0026#34;: \u0026#34;decide\u0026#34;, \u0026#34;END\u0026#34;: END } ) workflow.add_conditional_edges( \u0026#34;decide\u0026#34;, router, { \u0026#34;END\u0026#34;: END } ) # Example usage if __name__ == \u0026#34;__main__\u0026#34;: # Initialize state with example emergency scenario initial_state = { \u0026#34;messages\u0026#34;: [], \u0026#34;current_scenario\u0026#34;: { \u0026#34;timestamp\u0026#34;: datetime.now().isoformat(), \u0026#34;vehicle_state\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;ego_vehicle\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;VEHICLE\u0026#34;, \u0026#34;position\u0026#34;: { \u0026#34;x\u0026#34;: 0.0, \u0026#34;y\u0026#34;: 0.0, \u0026#34;speed\u0026#34;: 50.0, \u0026#34;direction\u0026#34;: 0.0 }, \u0026#34;size\u0026#34;: (2.0, 4.5), \u0026#34;velocity\u0026#34;: (14.0, 0.0), \u0026#34;priority\u0026#34;: 3, \u0026#34;vulnerability\u0026#34;: 0.5, \u0026#34;protected_status\u0026#34;: False }, \u0026#34;entities\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;pedestrian1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;PEDESTRIAN\u0026#34;, \u0026#34;position\u0026#34;: { \u0026#34;x\u0026#34;: 10.0, \u0026#34;y\u0026#34;: 0.0, \u0026#34;speed\u0026#34;: 1.0, \u0026#34;direction\u0026#34;: 90.0 }, \u0026#34;size\u0026#34;: (0.5, 0.5), \u0026#34;velocity\u0026#34;: (0.0, 1.0), \u0026#34;priority\u0026#34;: 1, \u0026#34;vulnerability\u0026#34;: 0.9, \u0026#34;protected_status\u0026#34;: True } ], \u0026#34;road_conditions\u0026#34;: { \u0026#34;friction\u0026#34;: 0.8, \u0026#34;visibility\u0026#34;: 0.9 }, \u0026#34;weather_conditions\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;CLEAR\u0026#34;, \u0026#34;intensity\u0026#34;: \u0026#34;NONE\u0026#34; }, \u0026#34;time_to_impact\u0026#34;: 0.5, \u0026#34;possible_actions\u0026#34;: [ \u0026#34;EMERGENCY_BRAKE\u0026#34;, \u0026#34;SWERVE_LEFT\u0026#34;, \u0026#34;SWERVE_RIGHT\u0026#34; ] }, \u0026#34;ethical_principles\u0026#34;: { k: asdict(v) for k, v in ETHICAL_PRINCIPLES.items() }, \u0026#34;available_actions\u0026#34;: [ \u0026#34;EMERGENCY_BRAKE\u0026#34;, \u0026#34;SWERVE_LEFT\u0026#34;, \u0026#34;SWERVE_RIGHT\u0026#34; ], \u0026#34;risk_assessments\u0026#34;: {}, \u0026#34;ethical_scores\u0026#34;: {}, \u0026#34;decision\u0026#34;: None, \u0026#34;next_action\u0026#34;: \u0026#34;ANALYZE\u0026#34; } # Run the workflow app = workflow.compile() print(\u0026#34;\\nInitial Scenario Analysis:\u0026#34;) print(\u0026#34;=========================\u0026#34;) print(f\u0026#34;Vehicle Speed: {initial_state[\u0026#39;current_scenario\u0026#39;][\u0026#39;vehicle_state\u0026#39;][\u0026#39;position\u0026#39;][\u0026#39;speed\u0026#39;]} km/h\u0026#34;) print(f\u0026#34;Time to Impact: {initial_state[\u0026#39;current_scenario\u0026#39;][\u0026#39;time_to_impact\u0026#39;]} seconds\u0026#34;) print(f\u0026#34;Available Actions: {\u0026#39;, \u0026#39;.join(initial_state[\u0026#39;available_actions\u0026#39;])}\u0026#34;) print(\u0026#34;\\nStarting Decision Process...\u0026#34;) for output in app.stream(initial_state): step = output[\u0026#34;next_action\u0026#34;] if step == \u0026#34;EVALUATE\u0026#34;: print(\u0026#34;\\nRisk Assessment Results:\u0026#34;) print(\u0026#34;=======================\u0026#34;) for action, risks in output[\u0026#34;risk_assessments\u0026#34;].items(): print(f\u0026#34;\\nAction: {action}\u0026#34;) for risk_type, score in risks.items(): print(f\u0026#34;- {risk_type}: {score:.2f}\u0026#34;) elif step == \u0026#34;DECIDE\u0026#34;: print(\u0026#34;\\nEthical Evaluation Results:\u0026#34;) print(\u0026#34;=========================\u0026#34;) for action, scores in output[\u0026#34;ethical_scores\u0026#34;].items(): print(f\u0026#34;\\nAction: {action}\u0026#34;) for principle, score in scores.items(): print(f\u0026#34;- {principle}: {score:.2f}\u0026#34;) elif step == \u0026#34;END\u0026#34; and output[\u0026#34;decision\u0026#34;]: print(\u0026#34;\\nFinal Decision:\u0026#34;) print(\u0026#34;==============\u0026#34;) decision = output[\u0026#34;decision\u0026#34;] print(f\u0026#34;Chosen Action: {decision[\u0026#39;action\u0026#39;]}\u0026#34;) print(\u0026#34;\\nReasoning:\u0026#34;) for reason in decision[\u0026#34;reasoning\u0026#34;]: print(f\u0026#34;- {reason}\u0026#34;) print(f\u0026#34;\\nConfidence: {decision[\u0026#39;confidence\u0026#39;]:.2f}\u0026#34;) print(\u0026#34;\\nExpected Consequences:\u0026#34;) for consequence in decision[\u0026#34;consequences\u0026#34;]: print(f\u0026#34;- {consequence[\u0026#39;type\u0026#39;]}: {consequence[\u0026#39;description\u0026#39;]}\u0026#34;) The workflow will now execute with detailed outputs at each step\nExample Output Explanation:\n1. Risk Assessment Phase: - Analyzes collision risks for each possible action - Considers environmental factors (road conditions, weather) - Evaluates time pressure and response windows 2. Ethical Evaluation Phase: - Applies ethical principles to each action - Weighs protection of vulnerable entities - Considers fairness and harm minimization 3. Decision Making Phase: - Combines risk and ethical assessments - Selects action with best overall score - Provides detailed reasoning and expected outcomes The system prioritizes: - Protection of human life - Minimization of harm - Fairness in risk distribution - Consideration of vulnerable individuals - Practical feasibility of actions Key ethical principles like minimizing harm and protecting vulnerable individuals are given higher weights in the decision process, while still maintaining a balance with practical safety considerations. การนำ Agentic Design Patterns ไปใช้งาน การเลือกใช้รูปแบบการออกแบบที่เหมาะสมเป็นสิ่งสำคัญมาก เพราะแต่ละรูปแบบมีจุดแข็งและข้อจำกัดที่แตกต่างกัน ในการพัฒนาระบบ AI ควรพิจารณาปัจจัยต่างๆ ดังนี้:\nลักษณะของงาน: งานที่ต้องการการตอบสนองรวดเร็วอาจเหมาะกับ Reflexive Agent ในขณะที่งานที่ซับซ้อนอาจต้องใช้ Meta-Agent หรือ Collaborative Multi-Agent Systems\nทรัพยากรที่มี: บางรูปแบบต้องการทรัพยากรการประมวลผลมาก เช่น Self-Improvement หรือ Adaptive Workflow Orchestration ควรพิจารณาความพร้อมของระบบก่อนเลือกใช้\nความต้องการด้านความแม่นยำ: งานที่ต้องการความแม่นยำสูงอาจต้องใช้รูปแบบที่มีการตรวจสอบและยืนยันผลลัพธ์ เช่น ReACT หรือ Planner-Executor\nความต้องการด้านการปรับตัว: หากระบบต้องทำงานในสภาพแวดล้อมที่เปลี่ยนแปลงบ่อย ควรเลือกรูปแบบที่มีความยืดหยุ่นสูง เช่น Self-Improvement หรือ Interactive Learning\nบทสรุป Agentic Design Patterns เป็นแนวคิดที่น่าสนใจและมีประโยชน์มากในการพัฒนาระบบ AI ให้ทำงานได้อย่างชาญฉลาด การเข้าใจจุดแข็งและข้อจำกัดของแต่ละรูปแบบจะช่วยให้เราสามารถเลือกใช้และผสมผสานรูปแบบต่างๆ ได้อย่างเหมาะสม เพื่อสร้างระบบ AI ที่มีประสิทธิภาพและตอบโจทย์ความต้องการได้อย่างแท้จริง\nแหล่งข้อมูลเพิ่มเติม Agentic Design Patterns Cover image by AI Agentic Design Patterns with AutoGen\nปล. บทความนี้เขียนด้วย AI (^ . ^)\n","permalink":"http://localhost:1313/posts/agentic-ai/agentic-design-patterns/","summary":"\u003cp\u003eในยุคที่ AI กำลังเข้ามามีบทบาทสำคัญในชีวิตประจำวันของเรามากขึ้น การออกแบบระบบ AI ให้สามารถทำงานได้อย่างชาญฉลาดและมีประสิทธิภาพจึงเป็นเรื่องที่สำคัญมาก หนึ่งในแนวคิดที่น่าสนใจคือ \u0026ldquo;Agentic Design Patterns\u0026rdquo; หรือรูปแบบการออกแบบที่ช่วยให้ระบบ AI สามารถคิด ตัดสินใจ และทำงานได้อย่างอิสระ มาทำความรู้จักกับแนวคิดนี้กันให้ลึกซึ้งยิ่งขึ้น\u003c/p\u003e\n\u003ch2 id=\"agentic-design-patterns-คออะไร\"\u003eAgentic Design Patterns คืออะไร?\u003c/h2\u003e\n\u003cp\u003eAgentic Design Patterns เป็นแนวทางการออกแบบที่ใช้ในการสร้างระบบ AI ที่สามารถทำงานได้อย่างอิสระ (Autonomous) โดยไม่ต้องพึ่งพาการควบคุมจากมนุษย์ตลอดเวลา รูปแบบการออกแบบเหล่านี้ช่วยกำหนดวิธีการที่ระบบ AI จะคิด ตัดสินใจ และมีปฏิสัมพันธ์กับสภาพแวดล้อม รวมถึงระบบอื่นๆ เพื่อให้บรรลุเป้าหมายที่ต้องการ\u003c/p\u003e\n\u003ch2 id=\"รปแบบการออกแบบทนาสนใจ\"\u003eรูปแบบการออกแบบที่น่าสนใจ\u003c/h2\u003e\n\u003ch3 id=\"1-react---การผสมผสานระหวางการคดและการกระทำ\"\u003e1. ReACT - การผสมผสานระหว่างการคิดและการกระทำ\u003c/h3\u003e\n\u003cp\u003eReACT (Reasoning and Acting) เป็นรูปแบบที่น่าสนใจมาก เพราะจำลองการทำงานคล้ายกับวิธีที่มนุษย์เราคิดและตัดสินใจ โดยระบบจะ:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eวิเคราะห์สถานการณ์และคิดหาทางแก้ไข\u003c/li\u003e\n\u003cli\u003eลงมือทำตามแผนที่วางไว้\u003c/li\u003e\n\u003cli\u003eประเมินผลลัพธ์และปรับปรุงการตัดสินใจในรอบถัดไป\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eตัวอย่างที่เห็นได้ชัดคือ ระบบวางแผนการเดินทาง ที่จะสลับไปมาระหว่างการค้นหาเที่ยวบิน (การคิด) และการจองตั๋ว (การกระทำ) โดยปรับเปลี่ยนแผนตามราคาและความพร้อมของเที่ยวบินที่พบ\u003c/p\u003e\n\u003cblockquote\u003e\n\n\n\u003cp\u003e\u003cdetails \u003e\n  \u003csummary markdown=\"span\"\u003e\u003cem\u003e\u003cstrong\u003eตัวอย่าง ReACT\u003c/strong\u003e\u003c/em\u003e\u003c/summary\u003e\n  \u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etyping\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eDict\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eTuple\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eTypedDict\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eAnnotated\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edatetime\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edatetime\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etimedelta\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003elanggraph.graph\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eStateGraph\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eEND\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003elangchain_core.messages\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eHumanMessage\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eAIMessage\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003elangchain.chat_models\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eChatOpenRouter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eos\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Define our state structure\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eAgentState\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eTypedDict\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003emessages\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"nb\"\u003estr\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003ecurrent_plan\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eDict\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eflight_data\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eDict\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003ebooking_status\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003estr\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003enext_action\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003estr\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Mock flight database\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eMOCK_FLIGHTS\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;BKK-NRT\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;flight\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;TG676\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;departure\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;10:30\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;arrival\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;18:45\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;price\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e15000\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;flight\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;JL708\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;departure\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;08:00\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;arrival\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;15:30\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;price\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e18000\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e],\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;NRT-BKK\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;flight\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;TG677\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;departure\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;19:30\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;arrival\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;00:45\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;price\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e16000\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;flight\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;JL709\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;departure\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;16:30\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;arrival\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;22:00\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;price\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e17000\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Initialize OpenRouter LLM\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ellm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eChatOpenRouter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eapi_key\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eos\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eenviron\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;OPENROUTER_API_KEY\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;openai/gpt-4-turbo\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# หรือใช้โมเดลอื่นที่ OpenRouter รองรับ\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003etemperature\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eheaders\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;HTTP-Referer\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;http://localhost:8000\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# your website URL\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;X-Title\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Flight Booking Assistant\u0026#34;\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# your app name\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ereasoning_step\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eAgentState\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eAgentState\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    Analyze the current situation and plan next steps\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    \u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e# Create a prompt for the LLM to analyze the situation\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003emessages\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eHumanMessage\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003econtent\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        Current situation:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        - Planning status: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;current_plan\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        - Available flight data: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;flight_data\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        - Booking status: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;booking_status\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        What should be the next action? Choose from:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        1. SEARCH_FLIGHTS - If we need to look for flights\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        2. BOOK_FLIGHT - If we found a suitable flight and should book it\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        3. END - If we\u0026#39;ve completed the booking\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        Provide your reasoning and the next action.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        \u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e# Get LLM response\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ellm\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003einvoke\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emessages\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e# Extract next action from response\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;SEARCH_FLIGHTS\u0026#34;\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econtent\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;next_action\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;SEARCH_FLIGHTS\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;BOOK_FLIGHT\u0026#34;\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econtent\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;next_action\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;BOOK_FLIGHT\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;END\u0026#34;\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econtent\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;next_action\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;END\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;messages\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Reasoning: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econtent\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003estate\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003esearch_flights\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eAgentState\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eAgentState\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    Search for available flights based on the current plan\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    \u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eroute\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;current_plan\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;origin\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e-\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;current_plan\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;destination\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eroute\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eMOCK_FLIGHTS\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;flight_data\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eMOCK_FLIGHTS\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;messages\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Found \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"nb\"\u003elen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eMOCK_FLIGHTS\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e flights for \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;flight_data\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;messages\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;No flights found for \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003estate\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ebook_flight\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eAgentState\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eAgentState\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    Attempt to book the selected flight\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    \u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;flight_data\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"c1\"\u003e# Find the cheapest flight\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eselected_flight\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003emin\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;flight_data\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003ekey\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"k\"\u003elambda\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;price\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;booking_status\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;CONFIRMED\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;messages\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Booked flight \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_flight\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;flight\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e for \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_flight\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;price\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e THB\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;booking_status\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;FAILED\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;messages\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Booking failed - no flights available\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003estate\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erouter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eAgentState\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"nb\"\u003estr\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    Route to the next step based on the reasoning outcome\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    \u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003estate\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;next_action\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Create the graph\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eworkflow\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eStateGraph\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eAgentState\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Add nodes\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eworkflow\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd_node\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;reasoning\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ereasoning_step\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eworkflow\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd_node\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;search_flights\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esearch_flights\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eworkflow\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd_node\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;book_flight\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ebook_flight\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Add edges\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eworkflow\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd_edge\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;reasoning\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erouter\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eworkflow\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd_edge\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;search_flights\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;reasoning\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eworkflow\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd_edge\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;book_flight\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;reasoning\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Set entry point\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eworkflow\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eset_entry_point\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;reasoning\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Create conditional edges\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eworkflow\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd_conditional_edges\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;reasoning\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003erouter\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;SEARCH_FLIGHTS\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;search_flights\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;BOOK_FLIGHT\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;book_flight\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;END\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eEND\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# Example usage\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"vm\"\u003e__name__\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;__main__\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e# Initialize state\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003einitial_state\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;messages\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[],\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;current_plan\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"s2\"\u003e\u0026#34;origin\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;BKK\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"s2\"\u003e\u0026#34;destination\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;NRT\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"s2\"\u003e\u0026#34;date\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;2025-02-15\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;flight_data\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;booking_status\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;NOT_STARTED\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"s2\"\u003e\u0026#34;next_action\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;SEARCH_FLIGHTS\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e# Run the workflow\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eworkflow\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecompile\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eoutput\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estream\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003einitial_state\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003eStep Output:\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eindent\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003c/details\u003e\u003c/p\u003e","title":"ทำความรู้จักกับ Agentic Design Patterns: รูปแบบการออกแบบ AI ที่ช่วยให้ระบบทำงานได้อย่างชาญฉลาด"},{"content":"ในบทความนี้เราจะมาทดลองสร้าง AI Agent ที่สามารถโต้ตอบกับฐานข้อมูล SQLite โดยใช้ Deepseek-R1 ซึ่งเป็น Open Source Language Model ร่วมกับ Langgraph ซึ่งเป็นเครื่องมือสำหรับสร้าง AI workflows แบบใหม่จาก LangChain\nโครงสร้างของโปรเจค โปรเจคของเราประกอบด้วยไฟล์หลัก 2 ไฟล์:\nsetup.py - สำหรับสร้างและจัดการฐานข้อมูล SQLite agent.py - สำหรับสร้าง AI Agent ที่จะโต้ตอบกับฐานข้อมูล การสร้างฐานข้อมูล เริ่มต้นจาก setup.py ที่ใช้สร้างฐานข้อมูลสินค้าตัวอย่าง โดยมีตาราง products ที่เก็บข้อมูลต่างๆ เช่น:\nid (PRIMARY KEY) name price category stock description last_updated โค้ดส่วนนี้จะสร้างฐานข้อมูลพร้อมข้อมูลตัวอย่างกว่า 100 รายการ แบ่งเป็นหมวดหมู่ต่างๆ เช่น Smartphones, Laptops, TVs, Audio เป็นต้น\n# setup.py import sqlite3 import os from datetime import datetime def init_database(): try: db_path = os.path.join(os.path.dirname(__file__), \u0026#39;products.db\u0026#39;) conn = sqlite3.connect(db_path) cursor = conn.cursor() cursor.execute(\u0026#39;DROP TABLE IF EXISTS products\u0026#39;) cursor.execute(\u0026#39;\u0026#39;\u0026#39; CREATE TABLE IF NOT EXISTS products ( id INTEGER PRIMARY KEY, name TEXT NOT NULL, price REAL NOT NULL, category TEXT NOT NULL, stock INTEGER NOT NULL, description TEXT, last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP ) \u0026#39;\u0026#39;\u0026#39;) cursor.execute(\u0026#39;CREATE INDEX IF NOT EXISTS idx_products_category ON products(category)\u0026#39;) cursor.execute(\u0026#39;CREATE INDEX IF NOT EXISTS idx_products_price ON products(price)\u0026#39;) cursor.execute(\u0026#39;CREATE INDEX IF NOT EXISTS idx_products_stock ON products(stock)\u0026#39;) products_data = [ # Smartphones (1, \u0026#39;iPhone 15 Pro Max\u0026#39;, 48900.00, \u0026#39;Smartphones\u0026#39;, 45, \u0026#39;1TB storage, titanium finish\u0026#39;), (2, \u0026#39;iPhone 15 Pro\u0026#39;, 42900.00, \u0026#39;Smartphones\u0026#39;, 50, \u0026#39;256GB storage, A17 Pro chip\u0026#39;), (3, \u0026#39;iPhone 15\u0026#39;, 32900.00, \u0026#39;Smartphones\u0026#39;, 60, \u0026#39;128GB storage, A16 chip\u0026#39;), (4, \u0026#39;Samsung Galaxy S24 Ultra\u0026#39;, 45900.00, \u0026#39;Smartphones\u0026#39;, 40, \u0026#39;512GB storage, S Pen included\u0026#39;), (5, \u0026#39;Samsung Galaxy S24+\u0026#39;, 35900.00, \u0026#39;Smartphones\u0026#39;, 45, \u0026#39;256GB storage, AI features\u0026#39;), (6, \u0026#39;Samsung Galaxy S24\u0026#39;, 29900.00, \u0026#39;Smartphones\u0026#39;, 55, \u0026#39;128GB storage\u0026#39;), (7, \u0026#39;Google Pixel 8 Pro\u0026#39;, 35900.00, \u0026#39;Smartphones\u0026#39;, 35, \u0026#39;Advanced AI camera features\u0026#39;), (8, \u0026#39;Google Pixel 8\u0026#39;, 27900.00, \u0026#39;Smartphones\u0026#39;, 40, \u0026#39;Android flagship\u0026#39;), (9, \u0026#39;OnePlus 12\u0026#39;, 31900.00, \u0026#39;Smartphones\u0026#39;, 30, \u0026#39;Snapdragon 8 Gen 3\u0026#39;), (10, \u0026#39;Xiaomi 14 Pro\u0026#39;, 29900.00, \u0026#39;Smartphones\u0026#39;, 40, \u0026#39;Leica optics\u0026#39;), # Laptops (11, \u0026#39;MacBook Pro 16\u0026#34;\u0026#39;, 89900.00, \u0026#39;Laptops\u0026#39;, 25, \u0026#39;M3 Max chip, 32GB RAM\u0026#39;), ........ ] cursor.executemany(\u0026#39;\u0026#39;\u0026#39; INSERT OR REPLACE INTO products (id, name, price, category, stock, description) VALUES (?, ?, ?, ?, ?, ?) \u0026#39;\u0026#39;\u0026#39;, products_data) conn.commit() print(\u0026#34;Database initialized successfully!\u0026#34;) return conn except sqlite3.Error as e: print(f\u0026#34;SQLite error: {e}\u0026#34;) return None except Exception as e: print(f\u0026#34;Error: {e}\u0026#34;) return None def main(): conn = init_database() if not conn: print(\u0026#34;Failed to initialize database\u0026#34;) return if __name__ == \u0026#34;__main__\u0026#34;: main() เราสามารถสร้างฐานข้อมูลด้วยคำสั่ง:\npython setup.py การสร้าง AI Agent ส่วนที่น่าสนใจที่สุดคือการสร้าง AI Agent ใน agent.py โดยใช้ Langgraph ร่วมกับ Deepseek-R1 โดยมีองค์ประกอบหลักๆ ดังนี้:\nPre-requisites pip install langchain langgraph langchain_core langchain_ollama 1. SQLite Tools เราสร้างคลาส SQLiteTools เพื่อจัดการการทำงานกับฐานข้อมูล:\nclass SQLiteTools: def __init__(self, db_path: str): self.db_path = db_path def execute_query(self, query: str) -\u0026gt; List[Tuple]: \u0026#34;\u0026#34;\u0026#34; Function to execute SQL queries \u0026#34;\u0026#34;\u0026#34; try: with sqlite3.connect(self.db_path) as conn: cursor = conn.cursor() cursor.execute(query) return cursor.fetchall() except Exception as e: return f\u0026#34;Error execute_query occurred: {str(e)}\u0026#34; def get_table_schema(self, *args) -\u0026gt; Dict[str, List[str]]: \u0026#34;\u0026#34;\u0026#34;Get schema information for all tables\u0026#34;\u0026#34;\u0026#34; try: with sqlite3.connect(self.db_path) as conn: cursor = conn.cursor() cursor.execute(\u0026#34;SELECT name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39;;\u0026#34;) tables = cursor.fetchall() schema = {} for table in tables: table_name = table[0] cursor.execute(f\u0026#34;PRAGMA table_info({table_name})\u0026#34;) columns = cursor.fetchall() schema[table_name] = [ { \u0026#34;name\u0026#34;: col[1], \u0026#34;type\u0026#34;: col[2], \u0026#34;notnull\u0026#34;: col[3], \u0026#34;pk\u0026#34;: col[5] } for col in columns ] return schema except Exception as e: return f\u0026#34;Error get_table_schema occurred: {str(e)}\u0026#34; 2. สร้าง AI Agent class SQLiteAgent: def __init__(self, db_path: str, model_name: str = \u0026#34;deepseek-r1:8b\u0026#34;): self.db_tools = SQLiteTools(db_path) 2.1. การตั้งค่า LLM เราใช้ Deepseek-R1 ผ่าน Ollama โดยตั้งค่าดังนี้:\nself.llm = ChatOllama( model=model_name, temperature=0, # ความแปรปรวนในการสร้างข้อความ ใช้ 0 สำหรับความแม่นยำสูงสุด callbacks=[StreamingStdOutCallbackHandler()], base_url=\u0026#34;http://localhost:11434\u0026#34;, streaming=True ) 2.2. การสร้าง Tools Agent ของเราสามารถใช้งาน tools 2 อย่างคือ:\nexecute_query - สำหรับ execute SQL query get_schema - สำหรับดูโครงสร้างฐานข้อมูล self.tools = [ Tool( name=\u0026#34;execute_query\u0026#34;, func=self.db_tools.execute_query, description=\u0026#34;Execute a SQL query. Input should be a valid SQL query string.\u0026#34; ), Tool( name=\u0026#34;get_schema\u0026#34;, func=self.db_tools.get_table_schema, description=\u0026#34;Get the database schema. No input needed.\u0026#34; ) ] 2.3. การสร้าง Prompt Template เราสร้าง prompt template ที่กำหนดรูปแบบการคิดและตอบของ AI:\nself.prompt = ChatPromptTemplate.from_messages([ (\u0026#34;system\u0026#34;, \u0026#34;\u0026#34;\u0026#34;You are a SQL database assistant. Follow the format below EXACTLY, including EXACT spacing and punctuation: Thought: [your reasoning] Action: [tool name] Action Input: [tool input] Observation: [tool output] ... (this Thought/Action/Action Input/Observation can repeat if needed) Thought: [your conclusion] Final Answer: [your response] Available tools: {tool_names} {tools} Remember: 1. ALWAYS start with \u0026#34;Thought:\u0026#34; 2. ALWAYS include \u0026#34;Action:\u0026#34; after \u0026#34;Thought:\u0026#34; 3. ALWAYS follow the exact format above 4. NEVER include multiple actions without observations between them 5. NEVER skip steps in the format\u0026#34;\u0026#34;\u0026#34;), (\u0026#34;human\u0026#34;, \u0026#34;{input}\u0026#34;), (\u0026#34;ai\u0026#34;, \u0026#34;{agent_scratchpad}\u0026#34;) ]) 2.4. สร้าง Agent และ Workflow สร้าง state schema สำหรับ agent:\nclass AgentState(TypedDict): input: str output: Any messages: List[Any] Langgraph ช่วยให้เราสร้าง workflow แบบ state-based ได้ง่าย:\nself.agent = create_react_agent( llm=self.llm, tools=self.tools, prompt=self.prompt ) self.agent_executor = AgentExecutor( agent=self.agent, tools=self.tools, verbose=True, return_intermediate_steps=True, # สำหรับการแสดงข้อความระหว่างการทำงาน handle_parsing_errors=True, # จัดการข้อผิดพลาดในการแปลงข้อความ max_iterations=5 # จำกัดจำนวนรอบการทำงาน (เพื่อป้องกันการวนลูป) ) def run(self, query: str) -\u0026gt; Any: \u0026#34;\u0026#34;\u0026#34; Run Agent to process queries \u0026#34;\u0026#34;\u0026#34; try: def process_agent(state: Dict) -\u0026gt; Dict: # Call agent executor result = self.agent_executor.invoke({ \u0026#34;input\u0026#34;: state[\u0026#34;input\u0026#34;], \u0026#34;agent_scratchpad\u0026#34;: state.get(\u0026#34;messages\u0026#34;, []) }) # Create messages messages = [] if \u0026#34;intermediate_steps\u0026#34; in result: for step in result[\u0026#34;intermediate_steps\u0026#34;]: action, output = step messages.extend([ AIMessage(content=str(action)), HumanMessage(content=str(output)) ]) # Update state return { \u0026#34;input\u0026#34;: state[\u0026#34;input\u0026#34;], \u0026#34;output\u0026#34;: result.get(\u0026#34;output\u0026#34;, \u0026#34;\u0026#34;), \u0026#34;messages\u0026#34;: messages } workflow = StateGraph(state_schema=AgentState) workflow.add_node(\u0026#34;agent\u0026#34;, process_agent) workflow.set_entry_point(\u0026#34;agent\u0026#34;) workflow.add_edge(\u0026#34;agent\u0026#34;, END) app = workflow.compile() # Create initial state initial_state = { \u0026#34;input\u0026#34;: query, \u0026#34;output\u0026#34;: None, \u0026#34;messages\u0026#34;: [] } # Run workflow result = app.invoke(initial_state) # Get results return result[\u0026#34;output\u0026#34;] except ValueError as e: if \u0026#34;Could not parse LLM output\u0026#34; in str(e): return f\u0026#34;Error: The model response could not be parsed. Original query: {query}\u0026#34; raise except Exception as e: return f\u0026#34;An error occurred: {str(e)}\u0026#34; การใช้งาน สร้าง function สำหรับเรียกใช้งาน agent:\n# Usage example # Command line interface if __name__ == \u0026#34;__main__\u0026#34;: import argparse import sys # สร้าง argument parser parser = argparse.ArgumentParser(description=\u0026#39;SQLite AI Assistant\u0026#39;) parser.add_argument(\u0026#39;--db\u0026#39;, type=str, default=\u0026#34;products.db\u0026#34;, help=\u0026#39;Database file path\u0026#39;) parser.add_argument(\u0026#39;--model\u0026#39;, type=str, default=\u0026#34;deepseek-r1:8b\u0026#34;, help=\u0026#39;Ollama model name\u0026#39;) parser.add_argument(\u0026#39;prompt\u0026#39;, type=str, nargs=\u0026#39;+\u0026#39;, help=\u0026#39;Natural language prompt\u0026#39;) # Parse arguments args = parser.parse_args() # สร้าง Agent agent = SQLiteAgent(args.db, model_name=args.model) try: # รวมคำสั่งเป็น string เดียว prompt = \u0026#39; \u0026#39;.join(args.prompt) # ส่งคำสั่งไปให้ agent result = agent.run(prompt) print(result) except Exception as e: print(f\u0026#34;เกิดข้อผิดพลาด: {str(e)}\u0026#34;) เราสามารถใช้งาน AI Agent ผ่าน command line ได้ดังนี้:\npython agent.py \u0026#34;Show me 10 products under 20000\u0026#34; Result: Agent สามารถ:\nเข้าใจคำถามภาษาธรรมชาติ แปลงเป็น SQL query ส่ง query ไปยังฐานข้อมูล แปลงผลลัพธ์กลับมาเป็นภาษาธรรมชาติ สร้าง API สำหรับโต้ตอบกับ agent ผ่าน HTTP request ด้วย FastAPI Pre-requisites:\npip install fastapi uvicorn เพิ่มไฟล์ api.py สำหรับสร้าง API ที่ใช้งาน agent:\n# api.py from fastapi import FastAPI, HTTPException from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel import asyncio from typing import Optional import uvicorn from agent import SQLiteAgent class QueryRequest(BaseModel): query: str model_name: Optional[str] = \u0026#34;deepseek-r1:8b\u0026#34; db_path: Optional[str] = \u0026#34;products.db\u0026#34; class QueryResponse(BaseModel): result: str error: Optional[str] = None app = FastAPI(title=\u0026#34;SQLite AI Assistant\u0026#34;) app.add_middleware( CORSMiddleware, allow_origins=[\u0026#34;*\u0026#34;], allow_credentials=True, allow_methods=[\u0026#34;*\u0026#34;], allow_headers=[\u0026#34;*\u0026#34;], ) @app.post(\u0026#34;/query\u0026#34;, response_model=QueryResponse) async def process_query(request: QueryRequest): try: agent = SQLiteAgent(request.db_path, model_name=request.model_name) result = agent.run(request.query) return QueryResponse(result=str(result)) except Exception as e: raise HTTPException(status_code=500, detail=str(e)) def run_fastapi(): uvicorn.run(app, host=\u0026#34;0.0.0.0\u0026#34;, port=8000) if __name__ == \u0026#34;__main__\u0026#34;: run_fastapi() รัน API ด้วยคำสั่ง:\npython api.py เราสามารถใช้งาน agent ผ่าน API ได้ดังนี้:\nสร้าง web interface สำหรับโต้ตอบกับ agent Pre-requisites:\npip install streamlit เพิ่มไฟล์ app.py สำหรับสร้าง web interface ที่ใช้งาน agent:\n# app.py import streamlit as st import json from agent import SQLiteAgent def main(): st.set_page_config( page_title=\u0026#34;SQLite AI Assistant\u0026#34;, page_icon=\u0026#34;🤖\u0026#34;, layout=\u0026#34;wide\u0026#34; ) st.title(\u0026#34;🤖 SQLite AI Assistant\u0026#34;) # Sidebar configuration with st.sidebar: st.header(\u0026#34;⚙️ Configuration\u0026#34;) model_name = st.selectbox( \u0026#34;Select Model\u0026#34;, [\u0026#34;deepseek-r1:8b\u0026#34;], index=0 ) db_path = st.text_input( \u0026#34;Database Path\u0026#34;, value=\u0026#34;products.db\u0026#34; ) st.markdown(\u0026#34;---\u0026#34;) st.markdown(\u0026#34;\u0026#34;\u0026#34; ### Example Queries: - show database schema - show first 5 rows from products table - count total records in products table \u0026#34;\u0026#34;\u0026#34;) # Main content query = st.text_area(\u0026#34;Enter your query:\u0026#34;, height=100) if st.button(\u0026#34;🚀 Execute Query\u0026#34;, type=\u0026#34;primary\u0026#34;): if query: try: with st.spinner(\u0026#34;Processing...\u0026#34;): # Create agent and process query agent = SQLiteAgent(db_path, model_name=model_name) result = agent.run(query) # Show results st.success(\u0026#34;Query executed successfully!\u0026#34;) # Add to history if \u0026#39;history\u0026#39; not in st.session_state: st.session_state.history = [] st.session_state.history.append((query, result)) # Check if result is JSON try: if isinstance(result, str): json_result = json.loads(result) st.json(json_result) else: st.write(result) except: st.write(result) except Exception as e: st.error(f\u0026#34;Error: {str(e)}\u0026#34;) else: st.warning(\u0026#34;Please enter a query\u0026#34;) # History section with st.expander(\u0026#34;📜 Query History\u0026#34;, expanded=False): if \u0026#39;history\u0026#39; not in st.session_state: st.session_state.history = [] # Show query history for idx, (past_query, past_result) in enumerate(st.session_state.history): st.markdown(f\u0026#34;**Query {idx+1}:** {past_query}\u0026#34;) st.markdown(f\u0026#34;**Result:** {past_result}\u0026#34;) st.markdown(\u0026#34;---\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() รัน web interface ด้วยคำสั่ง:\nstreamlit run app.py เราสามารถใช้งาน agent ผ่าน web interface ได้ดังนี้:\nสรุป การใช้ Langgraph ร่วมกับ Deepseek-R1 ทำให้เราสามารถสร้าง AI Agent ที่ชาญฉลาดได้ง่ายขึ้น โดย:\nLanggraph ช่วยจัดการ workflow ของ agent Deepseek-R1 ให้ความสามารถในการเข้าใจภาษาธรรมชาติและแปลงเป็น SQL ระบบ tools ช่วยให้ agent มีความสามารถที่หลากหลาย นี่เป็นเพียงตัวอย่างเบื้องต้น เรายังสามารถพัฒนาต่อยอดได้อีกมาก เช่น:\nเพิ่ม tools ให้ทำงานอื่นๆ ได้ ปรับปรุง prompt template ให้ฉลาดขึ้น เพิ่มความสามารถในการจดจำบริบทการสนทนา อ้างอิง GitHub Repo Langgraph Documentation Deepseek-R1 Ollama ","permalink":"http://localhost:1313/posts/agent-example/","summary":"\u003cp\u003eในบทความนี้เราจะมาทดลองสร้าง AI Agent ที่สามารถโต้ตอบกับฐานข้อมูล SQLite โดยใช้ Deepseek-R1 ซึ่งเป็น Open Source Language Model ร่วมกับ Langgraph ซึ่งเป็นเครื่องมือสำหรับสร้าง AI workflows แบบใหม่จาก LangChain\u003c/p\u003e\n\u003ch2 id=\"โครงสรางของโปรเจค\"\u003eโครงสร้างของโปรเจค\u003c/h2\u003e\n\u003cp\u003eโปรเจคของเราประกอบด้วยไฟล์หลัก 2 ไฟล์:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ccode\u003esetup.py\u003c/code\u003e - สำหรับสร้างและจัดการฐานข้อมูล SQLite\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eagent.py\u003c/code\u003e - สำหรับสร้าง AI Agent ที่จะโต้ตอบกับฐานข้อมูล\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"การสรางฐานขอมล\"\u003eการสร้างฐานข้อมูล\u003c/h2\u003e\n\u003cp\u003eเริ่มต้นจาก \u003ccode\u003esetup.py\u003c/code\u003e ที่ใช้สร้างฐานข้อมูลสินค้าตัวอย่าง โดยมีตาราง products ที่เก็บข้อมูลต่างๆ เช่น:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eid (PRIMARY KEY)\u003c/li\u003e\n\u003cli\u003ename\u003c/li\u003e\n\u003cli\u003eprice\u003c/li\u003e\n\u003cli\u003ecategory\u003c/li\u003e\n\u003cli\u003estock\u003c/li\u003e\n\u003cli\u003edescription\u003c/li\u003e\n\u003cli\u003elast_updated\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eโค้ดส่วนนี้จะสร้างฐานข้อมูลพร้อมข้อมูลตัวอย่างกว่า 100 รายการ แบ่งเป็นหมวดหมู่ต่างๆ เช่น Smartphones, Laptops, TVs, Audio เป็นต้น\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# setup.py\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003esqlite3\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eos\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edatetime\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edatetime\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003einit_database\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003etry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003edb_path\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eos\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epath\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejoin\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eos\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epath\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edirname\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"vm\"\u003e__file__\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;products.db\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003econn\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esqlite3\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econnect\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edb_path\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ecursor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003econn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecursor\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ecursor\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eexecute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;DROP TABLE IF EXISTS products\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ecursor\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eexecute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;\u0026#39;\u0026#39;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e        CREATE TABLE IF NOT EXISTS products (\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e            id INTEGER PRIMARY KEY,\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e            name TEXT NOT NULL,\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e            price REAL NOT NULL,\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e            category TEXT NOT NULL,\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e            stock INTEGER NOT NULL,\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e            description TEXT,\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e        )\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e        \u0026#39;\u0026#39;\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ecursor\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eexecute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;CREATE INDEX IF NOT EXISTS idx_products_category ON products(category)\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ecursor\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eexecute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;CREATE INDEX IF NOT EXISTS idx_products_price ON products(price)\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ecursor\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eexecute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;CREATE INDEX IF NOT EXISTS idx_products_stock ON products(stock)\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eproducts_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"c1\"\u003e# Smartphones\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;iPhone 15 Pro Max\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e48900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Smartphones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e45\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;1TB storage, titanium finish\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;iPhone 15 Pro\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e42900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Smartphones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e50\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;256GB storage, A17 Pro chip\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;iPhone 15\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e32900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Smartphones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e60\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;128GB storage, A16 chip\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Samsung Galaxy S24 Ultra\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e45900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Smartphones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e40\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;512GB storage, S Pen included\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Samsung Galaxy S24+\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e35900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Smartphones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e45\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;256GB storage, AI features\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Samsung Galaxy S24\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e29900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Smartphones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e55\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;128GB storage\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Google Pixel 8 Pro\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e35900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Smartphones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e35\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Advanced AI camera features\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Google Pixel 8\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e27900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Smartphones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e40\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Android flagship\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e9\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;OnePlus 12\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e31900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Smartphones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e30\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Snapdragon 8 Gen 3\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Xiaomi 14 Pro\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e29900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Smartphones\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e40\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Leica optics\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"c1\"\u003e# Laptops\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;MacBook Pro 16\u0026#34;\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e89900.00\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;Laptops\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e25\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;M3 Max chip, 32GB RAM\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"o\"\u003e........\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ecursor\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eexecutemany\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;\u0026#39;\u0026#39;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e        INSERT OR REPLACE INTO products (id, name, price, category, stock, description)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e        VALUES (?, ?, ?, ?, ?, ?)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s1\"\u003e        \u0026#39;\u0026#39;\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eproducts_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003econn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecommit\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Database initialized successfully!\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003econn\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eexcept\u003c/span\u003e \u003cspan class=\"n\"\u003esqlite3\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eError\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;SQLite error: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eexcept\u003c/span\u003e \u003cspan class=\"ne\"\u003eException\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Error: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003econn\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einit_database\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"ow\"\u003enot\u003c/span\u003e \u003cspan class=\"n\"\u003econn\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Failed to initialize database\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"vm\"\u003e__name__\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;__main__\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eเราสามารถสร้างฐานข้อมูลด้วยคำสั่ง:\u003c/p\u003e","title":"ลองเล่น Deepseek-R1 และสร้าง AI Agent ด้วย Langgraph"},{"content":"ลองเล่น Local LLM ด้วย Ollama + Python บทความนี้จะพาทุกคนมาลองใช้งาน LLM บนเครื่องคอมพิวเตอร์ส่วนตัวผ่าน Ollama และ Python เหมาะสำหรับผู้ที่อยากทดลองเล่น AI แต่กังวลเรื่องความเป็นส่วนตัวของข้อมูล หรือต้องการระบบที่ทำงานได้แม้ไม่มีอินเทอร์เน็ต\nที่มาของ Large Language Model (LLM) ในช่วงไม่กี่ปีที่ผ่านมา เราได้เห็นการเติบโตอย่างก้าวกระโดดของ AI โดยเฉพาะในด้านการประมวลผลภาษาธรรมชาติ จุดเปลี่ยนสำคัญเกิดขึ้นเมื่อนักวิจัยพบว่า การสร้างโมเดลขนาดใหญ่และฝึกฝนด้วยข้อมูลมหาศาล ทำให้ AI สามารถเข้าใจและตอบโต้กับมนุษย์ได้อย่างน่าทึ่ง\nปัจจุบันมีบริการ LLM มากมายให้เลือกใช้ เช่น ChatGPT, Claude, Gemini แต่หลายคนอาจกังวลเรื่องความเป็นส่วนตัวของข้อมูล หรือต้องการระบบที่ทำงานได้แม้ไม่มีอินเทอร์เน็ต นั่นคือที่มาของ Local LLM\nรู้จักกับ Ollama Ollama เป็นเครื่องมือที่ช่วยให้เราสามารถรัน LLM บนเครื่องคอมพิวเตอร์ส่วนตัวได้อย่างง่ายดาย รองรับโมเดลหลากหลาย เช่น Llama 3, Mistral, CodeLlama โดยมีจุดเด่นคือ:\nติดตั้งง่าย รองรับทั้ง Windows, macOS และ Linux มี API ที่ใช้งานสะดวก ประสิทธิภาพดี ใช้ทรัพยากรเครื่องน้อย รองรับการปรับแต่งโมเดลได้ตามต้องการ การติดตั้ง 1. ติดตั้ง Ollama สำหรับ macOS:\nbrew install ollama สำหรับ Linux:\ncurl -fsSL https://ollama.com/install.sh | sh สำหรับ Windows สามารถดาวน์โหลดได้จาก เว็บไซต์ Ollama\n2. ติดตั้ง Python Package pip install ollama เริ่มต้นใช้งาน 1. ดาวน์โหลดโมเดล เริ่มจากเปิด Terminal แล้วรันคำสั่ง:\nollama pull llama3.1 2. ทดสอบด้วย Python สร้างไฟล์ test_ollama.py:\nimport ollama def simple_chat(): response = ollama.chat(model=\u0026#39;llama3.1\u0026#39;, messages=[ {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;สวัสดี คุณทำอะไรได้บ้าง?\u0026#39;} ]) print(response[\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;]) # ทดสอบเรียกใช้งาน if __name__ == \u0026#39;__main__\u0026#39;: simple_chat() ลองรันทดสอบ:\npython test_ollama.py Output:\nสวัสดีค่ะ ฉันสามารถตอบคำถามของคุณได้ เช่น การเรียนรู้ภาษา คำนวณเลขคณิต ช่วยหาข้อมูลเกี่ยวกับประเทศหรือเมือง ขอข้อมูลเกี่ยวกับต่างๆ อีกมากมายค่ะ การใช้งานขั้นสูงขึ้น การสร้าง Chat Assistant สร้างไฟล์ assistant.py:\nimport ollama from typing import List, Dict class ChatAssistant: def __init__(self, model_name: str = \u0026#39;llama3.1\u0026#39;): self.model = model_name self.conversation_history: List[Dict[str, str]] = [] def chat(self, message: str) -\u0026gt; str: self.conversation_history.append({ \u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: message }) response = ollama.chat( model=self.model, messages=self.conversation_history ) self.conversation_history.append({ \u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;content\u0026#39;: response[\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;] }) return response[\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;] def clear_history(self): self.conversation_history = [] ตัวอย่างการใช้งาน Chat Assistant สร้างไฟล์ chat.py:\nfrom assistant import ChatAssistant assistant = ChatAssistant() questions = [ \u0026#34;Python คืออะไร?\u0026#34;, \u0026#34;ยกตัวอย่างการใช้งาน list comprehension\u0026#34;, \u0026#34;แล้ว dictionary comprehension ล่ะ?\u0026#34; ] for question in questions: print(f\u0026#34;\\nคำถาม: {question}\u0026#34;) print(f\u0026#34;คำตอบ: {assistant.chat(question)}\u0026#34;) ลองรันทดสอบ:\npython chat.py Output:\nคำถาม: Python คืออะไร? คำตอบ: ภาษาเชิงสคริปต์ (Scripting language) ที่ใช้ในการเขียนโปรแกรมคอมพิวเตอร์ โดยมีลักษณะเฉพาะคือความสามารถในการนำโค้ดไปใช้งานได้ทันทีโดยไม่ต้องบันทึกลงไปในไฟล์ใดๆ คำถาม: ยกตัวอย่างการใช้งาน list comprehension คำตอบ: **List Comprehension ในภาษา Python** List comprehension เป็นฟังก์ชันพิเศษในภาษา Python ที่สามารถสร้างรายการ (list) ได้อย่างรวดเร็วและง่ายดาย โดยไม่ต้องใช้ loop หรือการเขียนโค้ดซ้ำๆ ตัวอย่างการใช้งาน list comprehension: **1. สร้างรายการที่มีขนาดเฉพาะ** `python numbers = [i for i in range(10)] print(numbers) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] ` **2. ฟิลเตอร์รายการ** `python numbers = [i for i in range(10) if i % 2 == 0] print(numbers) # [0, 2, 4, 6, 8] ` **3. ทำการปฏิบัติการบนรายการ** `python numbers = [i ** 2 for i in range(5)] print(numbers) # [0, 1, 4, 9, 16] ` **4. รวมสองรายการเข้าด้วยกัน** `python names = [\u0026#39;John\u0026#39;, \u0026#39;Alice\u0026#39;, \u0026#39;Bob\u0026#39;] ages = [25, 30, 35] people = [{name: age} for name, age in zip(names, ages)] print(people) # [{\u0026#39;John\u0026#39;: 25}, {\u0026#39;Alice\u0026#39;: 30}, {\u0026#39;Bob\u0026#39;: 35}] ` นี่คือตัวอย่างการใช้งาน list comprehension ในภาษา Python มีหลายกรณีที่สามารถใช้ได้ และมันช่วยให้คุณเขียนโค้ดที่กระชับและง่ายดายมากขึ้น! คำถาม: แล้ว dictionary comprehension ล่ะ? คำตอบ: **Dictionary Comprehension ในภาษา Python** Dictionary comprehension เป็นฟังก์ชันพิเศษในภาษา Python ที่สามารถสร้าง辞านวารี (dictionary) ได้อย่างรวดเร็วและง่ายดาย โดยไม่ต้องใช้ loop หรือการเขียนโค้ดซ้ำๆ ตัวอย่างการใช้งาน dictionary comprehension: **1. สร้าง辞านวารีที่มีขนาดเฉพาะ** `python numbers = {i: i * 2 for i in range(5)} print(numbers) # {0: 0, 1: 2, 2: 4, 3: 6, 4: 8} ` **2. ฟิลเตอร์รายการ** `python numbers = {i: i * 2 for i in range(10) if i % 2 == 0} print(numbers) # {0: 0, 2: 4, 4: 8, 6: 12, 8: 16} ` **3. ทำการปฏิบัติการบนรายการ** `python numbers = {i: i ** 2 for i in range(5)} print(numbers) # {0: 0, 1: 1, 2: 4, 3: 9, 4: 16} ` **4. รวมสองรายการเข้าด้วยกัน** `python names = [\u0026#39;John\u0026#39;, \u0026#39;Alice\u0026#39;, \u0026#39;Bob\u0026#39;] ages = [25, 30, 35] people = {name: age for name, age in zip(names, ages)} print(people) # {\u0026#39;John\u0026#39;: 25, \u0026#39;Alice\u0026#39;: 30, \u0026#39;Bob\u0026#39;: 35} ` นี่คือตัวอย่างการใช้งาน dictionary comprehension ในภาษา Python มีหลายกรณีที่สามารถใช้ได้ และมันช่วยให้คุณเขียนโค้ดที่กระชับและง่ายดายมากขึ้น! ความแตกต่างระหว่าง list comprehension และ dictionary comprehension คือ: * List comprehension สร้างรายการ (list) ขณะที่ dictionary comprehension สร้าง辞านวารี (dictionary) * ใน list comprehension เราสามารถใช้คำสั่ง `for` ได้ทั้งสองฝ่าย (left-hand side และ right-hand side) ในขณะที่ใน dictionary comprehension เราสามารถใช้คำสั่ง `for` ได้เพียงฝ่ายหนึ่งเท่านั้น การปรับแต่งพารามิเตอร์ เราสามารถปรับแต่งการทำงานของ LLM ได้ผ่านพารามิเตอร์ต่างๆ:\nสร้างไฟล์ advanced_chat.py:\nimport ollama def advanced_chat(prompt: str): response = ollama.chat( model=\u0026#39;llama3.1\u0026#39;, messages=[{\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: prompt}], options={ \u0026#39;temperature\u0026#39;: 0.7, # ควบคุมความสร้างสรรค์ (0.0 - 1.0) \u0026#39;top_p\u0026#39;: 0.9, # ควบคุมความหลากหลายของคำตอบ \u0026#39;top_k\u0026#39;: 40, # จำนวนโทเค็นที่พิจารณา \u0026#39;num_predict\u0026#39;: 4069 # ความยาวสูงสุดของคำตอบ } ) return response[\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;] # ทดสอบเรียกใช้งาน if __name__ == \u0026#39;__main__\u0026#39;: prompt = \u0026#34;เล่าเรื่องตลกให้ฟังหน่อยสิ\u0026#34; print(advanced_chat(prompt)) ลองรันทดสอบ:\npython advanced_chat.py Output:\nมีชายคนหนึ่งซื้อหมูจากตลาดกลับบ้านเพื่อให้ทานเย็น แต่เมื่อลูกสาวของเขาเห็นหมู เธอก็บอกพ่อว่า \u0026#34;พ่อ ฉันอยากจะเลี้ยงหมูตัวนั้นก่อน\u0026#34; ชายคนนั้นพยายามที่จะทำให้ลูกสาวตกใจและบอกเธอว่า \u0026#34;หมูนี้เป็นหมูที่มีชื่อเสียงมาก มันสามารถปรุงแต่งอาหารได้ทุกชนิด แต่สิ่งที่สำคัญที่สุดคือมันไม่ต้องการเงิน\u0026#34; หญิงสาวตอบว่า \u0026#34;นั่นก็ทำให้ฉันประหลาดใจจริงๆ ที่เราสามารถจ่ายค่าตอบแทนทางเงินให้มันได้!\u0026#34; การใช้งานกับ Stream Ollama รองรับการ stream ข้อความตอบกลับแบบ real-time:\nimport ollama def stream_chat(prompt: str): stream = ollama.chat( model=\u0026#39;llama3.1\u0026#39;, messages=[{\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: prompt}], stream=True ) # พิมพ์ข้อความทีละส่วนตามที่ได้รับ for chunk in stream: if chunk[\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;]: print(chunk[\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;], end=\u0026#39;\u0026#39;, flush=True) การจัดการกับข้อผิดพลาด import ollama def safe_chat(prompt: str) -\u0026gt; str: try: response = ollama.chat( model=\u0026#39;llama3.1\u0026#39;, messages=[{\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: prompt}] ) return response[\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;] except Exception as e: return f\u0026#34;เกิดข้อผิดพลาด: {str(e)}\u0026#34; ข้อควรระวังและข้อจำกัด ทรัพยากรเครื่อง\nต้องการ RAM อย่างน้อย 8GB ควรมี GPU สำหรับประสิทธิภาพที่ดี พื้นที่ดิสก์สำหรับเก็บโมเดล (ประมาณ 4-8GB ต่อโมเดล) ความแม่นยำ\nLocal LLM อาจมีความแม่นยำน้อยกว่าโมเดลออนไลน์ ควรตรวจสอบผลลัพธ์เสมอ โดยเฉพาะในงานสำคัญ การอัพเดท\nติดตามการอัพเดทของ Ollama และโมเดลอยู่เสมอ อาจต้อง pull โมเดลใหม่เมื่อมีเวอร์ชันอัพเดท สรุป การใช้ Local LLM ผ่าน Ollama เป็นทางเลือกที่น่าสนใจสำหรับผู้ที่ต้องการความเป็นส่วนตัวหรือต้องการระบบที่ทำงานได้แบบ offline ถึงแม้จะมีข้อจำกัดบางประการ แต่ก็สามารถนำไปประยุกต์ใช้ได้หลากหลาย ตั้งแต่การสร้าง chatbot ไปจนถึงการประมวลผลเอกสาร\nแหล่งข้อมูลเพิ่มเติม GitHub Repo Ollama Official Documentation Ollama GitHub Repository Python Package Documentation บทความนี้อัพเดทล่าสุด: กุมภาพันธ์ 2025\nNote: ตัวอย่างโค้ดทั้งหมดทดสอบบน Python 3.10+\nCover image by Ollama\nปล. บทความนี้เขียนด้วย AI (^ . ^)\n","permalink":"http://localhost:1313/posts/ollama-python/","summary":"\u003ch1 id=\"ลองเลน-local-llm-ดวย-ollama--python\"\u003eลองเล่น Local LLM ด้วย Ollama + Python\u003c/h1\u003e\n\u003cp\u003e\u003cem\u003eบทความนี้จะพาทุกคนมาลองใช้งาน LLM บนเครื่องคอมพิวเตอร์ส่วนตัวผ่าน Ollama และ Python เหมาะสำหรับผู้ที่อยากทดลองเล่น AI แต่กังวลเรื่องความเป็นส่วนตัวของข้อมูล หรือต้องการระบบที่ทำงานได้แม้ไม่มีอินเทอร์เน็ต\u003c/em\u003e\u003c/p\u003e\n\u003ch2 id=\"ทมาของ-large-language-model-llm\"\u003eที่มาของ Large Language Model (LLM)\u003c/h2\u003e\n\u003cp\u003eในช่วงไม่กี่ปีที่ผ่านมา เราได้เห็นการเติบโตอย่างก้าวกระโดดของ AI โดยเฉพาะในด้านการประมวลผลภาษาธรรมชาติ จุดเปลี่ยนสำคัญเกิดขึ้นเมื่อนักวิจัยพบว่า การสร้างโมเดลขนาดใหญ่และฝึกฝนด้วยข้อมูลมหาศาล ทำให้ AI สามารถเข้าใจและตอบโต้กับมนุษย์ได้อย่างน่าทึ่ง\u003c/p\u003e\n\u003cp\u003eปัจจุบันมีบริการ LLM มากมายให้เลือกใช้ เช่น ChatGPT, Claude, Gemini แต่หลายคนอาจกังวลเรื่องความเป็นส่วนตัวของข้อมูล หรือต้องการระบบที่ทำงานได้แม้ไม่มีอินเทอร์เน็ต นั่นคือที่มาของ Local LLM\u003c/p\u003e\n\u003ch2 id=\"รจกกบ-ollama\"\u003eรู้จักกับ Ollama\u003c/h2\u003e\n\u003cp\u003eOllama เป็นเครื่องมือที่ช่วยให้เราสามารถรัน LLM บนเครื่องคอมพิวเตอร์ส่วนตัวได้อย่างง่ายดาย รองรับโมเดลหลากหลาย เช่น Llama 3, Mistral, CodeLlama โดยมีจุดเด่นคือ:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eติดตั้งง่าย รองรับทั้ง Windows, macOS และ Linux\u003c/li\u003e\n\u003cli\u003eมี API ที่ใช้งานสะดวก\u003c/li\u003e\n\u003cli\u003eประสิทธิภาพดี ใช้ทรัพยากรเครื่องน้อย\u003c/li\u003e\n\u003cli\u003eรองรับการปรับแต่งโมเดลได้ตามต้องการ\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"การตดตง\"\u003eการติดตั้ง\u003c/h2\u003e\n\u003ch3 id=\"1-ตดตง-ollama\"\u003e1. ติดตั้ง Ollama\u003c/h3\u003e\n\u003cp\u003eสำหรับ macOS:\u003c/p\u003e","title":"ลองเล่น Local LLM ด้วย Ollama + Python"}]